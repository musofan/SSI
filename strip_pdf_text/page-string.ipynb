{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_path = \"/Users/damoncrockett/Dropbox/cogs220/proposal/lit/one/text/\"\n",
    "snippets = []\n",
    "for input_file in glob.glob(os.path.join(input_path,\"*.txt\")):\n",
    "    with open(input_file, \"r\") as input_file:\n",
    "        page_string = input_file.read().replace(\"\\n\",'')\n",
    "        page_string = page_string[:2500]\n",
    "        snippets.append(page_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data sonification: Do You See What I Hear? University of  Illinois ut Urbana-Champaign S TARA M . MADHYASTHA and DANIEL A. REED, onijiration, the mapping of data to sound parameters, is a  rich and relatively unexplored  technique  for understanding complex  data.  Sounds can  signal  state transitions,  identify particular  objects, and  describe evolu- tionary  behavior. Audio\\xe2\\x80\\x99s  novelty  in the computer interface indicates the nascent  state of  sonic tlata-presenta- tion  metaphors  and  the need  for  fur- ther sonification research. T h e  properties of aural cues are not yet as well understood as those of visu- al signals. Furthermore, we  know- that sound alone often cannot convey accu- rate information  without a visual con- text.  For example, merging the sound of a  hammer with  sounds commonly heard  in  a  gymnasium, such as  cheer- ing or a  referee\\xe2\\x80\\x99s whistle,  makes  it harder  to distinguish  the  harnmer\\xe2\\x80\\x99s sound from that of a bouncing basket- ball. In the gymnasium\\xe2\\x80\\x99s auditory con- text,  the  basketball  is  expected;  the hammer  is not.\\xe2\\x80\\x99 However, an accom- panying visual cue, such as a videotape of hammering, eliminates confusion. Hardware  limitations  have  also kept  sound  from  playing  a  more important part in  current interfaces. Because  there  is  neither  a  standard platform  for  sound  hardware  nor  a standard scftware application, it is extremely  difficult to create sounds that retain their salient perceptual fea- tures across  a  range  of  sound-hard- ware platforms. In many respects, this is  a  bootstrap problem  - technical obstacles make  it  difficult  to conduct the kinds of psychological experiments ~ . _ _ _ _ _ _ .  ~- The authors assert that, despite great strides in deveioping the gr-aphical dimension of user inteTfaces, the auditofy dimen- sion has been neglected. They ofer a tool for using sound to complement visual cues when working with complex data. I E E E   S O F T W A R E  07407459/95/$04  03 0 1995 IEEE 45 \\x0c',\n",
       " \"Multisensory Data Sensualization Based on Human Perception Tetsuro Ogi Advanced Technologies Department Mitsubishi Research Institute, Inc. Michitaka Hirose Faculty of Engineering University of Tokyo 2-3-6 Otemachi, Chiyoda-ku, Tokyo 100, Japan 7-3-1 Hongo, Bunkyo-ku, Tokyo 113, Japan E-mail: tetsu@mri.co.jp hirosaih1.t.u-tokyo.ac.jp Abstract A  multisensory  data  sensualization  environment  was developed  in which visual, acoustic, and  touch sensation information  could  be  used  to  display  scientific  data applying  virtual  reality  technology.  Specifically,  a  wind sensation  display prototype  using  air flow pressure  was developed  to generate  touch  sensation.  In scientific visualization, it is necessary to consider the characteristic of  human perception in order  to transmit  data from the computer to the user accurately.  This paper describes the scaling  method  of the  sense  displays  based  on psychological  magnitude.  Based  on the  experiment on sensory  interference  in perceiving  data, this paper  also proposes  guidelines for the  usage  of  multisensory informution. 1. Introduction Scientific  visualization  is  one  of  the  promising application  fields  of  virtual  reality  interface  techniques [ 1][2][3]. Scientific visualization that utilizes virtual reality technology  permits  the use  of  several human  sensations (e.g. visual,  acoustic,  and  touch  sensation) to  display scientific data. The purpose of scientific visualization is not to  create  a beautiful  picture.  It is rather  to  accurately transmit data from the computer to the user so that we can enhance the  human  ability  to  understand  the  physical phenomena.  Though the effective use of human sensations increases the computer ability to express data, inappropriate use of these sensations may be counterproductive.  Thus, it is necessary to take into consideration the characteristics of human  perception  in  order  to  utilize  human  sensations effectively [4]. In  this  study,  a  multisensory  data  sensualization environment was developed in which several kinds of sense displays were used to represent scientific data.  This paper 0-8186-7295-1196 $5.00 0 1996 IEEE Proceedings of VRAIS '96 66 describes  the  calibration  method  of  the  scales of  sense displays and  the  guidelines for the  effective usage  of multisensory information based on human perception. 2.  Multisensory scientific data sensualization environment Figure 1 shows the ove\",\n",
       " '~ n v i r o n ~ ~ n ~  for Visualization and Sonification of Br tivr rogress and availability of multimedia and  virtual  reality  (VR)  technology make possible  a new treiid of perceptual data  presentation.  As  computer  perfor- mance  increases,  the  major  bottleneck could  be the human-computer  interface. The bandwidth  of  this interface  will  be bound  by  characteristics  of  human  per- ception, and hence the quest for a new pre- sentation  paradigm  has  commenced  in different scientific fields. Techniques de- veloped  in  VR  facilitate  multiple data-stream  presentation  and  navigation through  huge  data sets. New iminersive environments are particularly appropriate to improve insight into complex biomedi- cal phenomena, which are naturally multi- dimensional. As  an  extension  to  visualization, which gives predominantly  spatial distri- bution,  acoustic  rendering  may improve temporal cues. The technique of data pre- sentation using variable sound features is called  sonification  [ 1-41. In  this  article, we  present  early  efforts  toward perceptualization  of biomedical  data and introduce  a novel method of  multimodal data  presentation  with  possible  clinical and  research  applications.  In  particular, this  environment  for  monitoring  brain electrical  activity  consists  of  3D visual- ization  synchronized  with  data sonification of electroencephalogram and magnetoencephalogram  (EEG/MEG) data.  Visualization  is  based  on  topo- graphic maps projected  on the scalp of  a 3D head model. Sonification implements inodulations  of  natural  sound patterns  to reflect  certain features  of processed  data and helps create a pleasant acoustic envi- ronment.  This feature is particularly  im- portant for prolonged system use. ~ v e r ~ i e w  Efficient  perceptualization  of  bio- medical data requires a multidisciplinary approach,  including the  fields  of  com- puter  science,  computer  engineering, psychology,  and  neurophysiology.  The inherent nature  and complexity  of  bio- medical  data  presents  a  fertile  field where multimodal presentation finds its Emil Jovanov1,2, Dusan Starcevic3, Vlada Radivojevic4, Aleksandar Samardzic5, Vladimir Simeunovic2 of Alnbam~ nt ~untsville \\'The  ~ n i v e r s i ~  \\'Institute  \"Mihailo Pupin\",  3el~rade \\'Fucul~ of ~~gan~za~ional S~ien~es, Eelg~Qde ~lns~itute of  Mental Health, ~elgrQd~ \\'School  of Electrical E ~ ~ i n e e r i ~ g ,  Universi~ of 3el~ra~e place naturally. A',\n",
       " \"Evaluating  the  Importance  of  Multi-sensory  Input  on  Memory  and  theSense  of  Presence  in  Virtual  EnvironmentsHuong Q. Dinh, Neff Walker, Chang Song, Akira Kobayashi, and Larry F. HodgesGraphics, Visualization & Usability CenterGeorgia Institute of Technology (Georgia  Tech)Atlanta, Georgia 30332 USA+1  404  894-8787hodges@cc.gatech.eduAbstract322 subjects participated in an experimental studyto investigate the effects of tactile, olfactory, audio andvisual sensory cues on a participant's sense of presencein a virtual environment and on their memory for theenvironment  and  the  objects  in  that  environment.Results strongly indicate that increasing the modalitiesof sensory input in a virtual environment can increaseboth the sense of presence and memory for objects inthe environment.  In particular, the addition of tactile,olfactory  and  auditory  cues  to  a  virtual  environmentincreased the user's sense of presence and memory ofthe environment.  Surprisingly, increasing the level ofvisual detail did not result in an increase in the user'ssense of presence or memory of the environment.1.    IntroductionIn  the  early  sixties,  Morton  Heilig  built  andpatented the Sensorama Simulator.  Now acknowledgedas  one  of  the  first  virtual  environments,  Sensoramaprovided the user with a multi-sensory experience.  Asimulated motorcycle ride through New York includedcolor  3D  visual  stimuli,  stereo  sound,  aromas,  andtactile (wind from fans, and a seat that vibrated) cues[6].Thirty-five  years  later,  most  virtual  environmentsfall short of the prototype created by Heilig.  Sensorycues for virtual environments usually consist primarilyof  visual  stimuli,  often  but  not  always,  accompaniedwith  audio  stimuli,  and,  even  less  often,  hapticstimuli.  Other sensory cues are usually not present orare present in contradiction to the virtual environmentbeing presented.  For example, a participant in a virtualenvironment  may  visually  see  himself  in  an  open,sunny  outdoor  setting  while  the  temperature  andolfactory cues he perceives are consistent with being inan air conditioned, enclosed computer lab.In  this  work  we  created  a  multimodal  virtualenvironment  that  can  provide  the  user  with  visual,auditory, tactile and olfactory sensory cues.  Motivatedby a suggestion by Fontaine [4] that access to a broaderrange  of  sensory  cues  promotes  a  greater  sense  ofpresence, we have experimentally investigated the useof\",\n",
       " 'G  ModelGAIPOS-4184;  No.  of  Pages  9Gait  &  Posture  xxx  (2014)  xxx\\xe2\\x80\\x93xxxContents  lists  available  at  ScienceDirectGait  &  Posturej o  u  r n  a l  h  o m  e p  a g e :  w w  w . e l s  e v i e r . c  o  m / l o  c  a t e / g  a i t p  o s  tReviewQuanti\\xef\\xac\\x81ed  self  and  human  movement:  A  review  on  the  clinical  impactof  wearable  sensing  and  feedback  for  gait  analysis  and  interventionPete  B.  Shull a,*,  Wisit  Jirattigalachote b,  Michael  A.  Hunt c,  Mark  R.  Cutkosky b,Scott  L.  Delp b,da State  Key  Laboratory  of  Mechanical  System  and  Vibration,  School  of  Mechanical  Engineering,  Shanghai  Jiao  Tong  University,  Shanghai  200240,  Chinab Department  of  Mechanical  Engineering,  Stanford  University,  Stanford,  CA,  USAc Department  of  Physical  Therapy,  University  of  British  Columbia,  Vancouver,  BC,  Canadad Department  of  Bioengineering,  Stanford  University,  Stanford,  CA,  USAA  R  T  I  C  L  E I  N  F  OA  B  S  T  R  A  C  TArticle  history:Received  28  October  2013Received  in  revised  form  10  March  2014Accepted  30  March  2014Keywords:Gait  retrainingBiofeedbackHapticReal-time  feedbackMotion  analysisThe  proliferation  of  miniaturized  electronics  has  fueled  a  shift  toward  wearable  sensors  and  feedbackdevices  for  the  mass  population.  Quanti\\xef\\xac\\x81ed  self  and  other  similar  movements  involving  wearablesystems  have  gained  recent  interest.  However,  it  is  unclear  what  the  clinical  impact  of  these  enablingtechnologies  is  on  human  gait.  The  purpose  of  this  review  is  to  assess  clinical  applications  of  wearablesensing  and  feedback  for  human  gait  and  to  identify  areas  of  future  research.  Four  electronic  databaseswere  searched  to  \\xef\\xac\\x81nd  articles  employing  wearable  sensing  or  feedback  for  movements  of  the  foot,  ankle,shank,  thigh,  hip,  pelvis,  and  trunk  during  gait.  We  retrieved  76  articles  that  met  the  inclusion  criteriaand  identi\\xef\\xac\\x81ed  four  common  clinical  applications:  (1)  identifying  movement  disorders,  (2)  assessingsurgical  outcomes,  (3)  improving  walking  stability,  and  (4)  reducing  joint  loading.  Characteristics  of  kneeand  trunk  motion  were  the  most  frequent  gait  parameters  for  both  wearable  sensing  and  wearablefeedback.  Most  articles  performed  testing  on  healthy  subjects,  and  the  most  prevalent  patientpopulations  were  osteoarthritis,  vestibular  ',\n",
       " 'Controller Design for a Wearable, Near-Field Haptic DisplayRobert W. LindemanJustin R. CutlerDepartment of Computer ScienceThe George Washington University801 22nd St NWWashington, DC 20052{gogo | jrcutler}@gwu.eduAbstractIn this paper, we address the problem of providingnear-field haptic feedback in a wearable,scalablemanner. Our solution, called the TactaBoard, supportsthe independent control of 16 outputs on a singlecontroller board using a standard serial port. We havetested the system with several types of output devices,including low-cost pager motors and fans. Based onPulse-Width Modulation,the system can generate anoutput frequency from 0.3Hz to 316Hz. We provide adetailed description of the characteristics of our system,and present early results from empirical studies we haveconducted with one possible configuration oftactors.Future enhancements to the TactaBoard system includethe ability to daisy chain multiple boards on one controlbus, and support for other classes of output devices suchas those requiring an H-Bridge. Finally, we present somepossible applications where this type of system might beuseful.1. IntroductionThe goal of our current work is to develop a scalablesystem for providing multiple kinds of touch feedbackcues for use in simulation environments (e.g., virtualreality simulations). Several key problems need to beaddressed in order to produce a solution that is usable,including unit size, weight, power consumption, and easeof donning/doffing. In addition, it is desirable that such asystem also be low-cost, easy to integrate into existingsystems, easily reconfigurable, and user extensible. Withthese goals in mind, we have developed the TactaBoardsystem. This paper introduces the problems we are tryingto solve, describes our system in detail, and discussessome empirical studies we have conducted using oneconfiguration of the TactaBoard system.In order to best frame the problem space we areexploring, we present an illustration of one possibleapplication. The main underlying driving application areathat has helped us outline and design the requirements ofthe TactaBoard system is the area of using virtual realityfor dismounted infantry training. Setting out to provide athissortofvehiclesimulators,foot-soldier with a simulated environment containing theright type and amount of fidelity to acquire new skills, oris an ambitious undertaking.improve existing ones,Unliketrainingenvironment has the user in close proximity to manypossible types',\n",
       " '72IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 10, NO. 1, JANUARY/FEBRUARY 2004Human Factors in Visualization ResearchMelanie Tory and Torsten Mo\\xc2\\xa8 llerAbstract\\xe2\\x80\\x94Visualization can provide valuable assistance for data analysis and decision making tasks. However, how people perceiveand interact with a visualization tool can strongly influence their understanding of the data as well as the system\\xe2\\x80\\x99s usefulness. Humanfactors therefore contribute significantly to the visualization process and should play an important role in the design and evaluation ofvisualization tools. Several research initiatives have begun to explore human factors in visualization, particularly in perception-baseddesign. Nonetheless, visualization work involving human factors is in its infancy, and many potentially promising areas have yet to beexplored. Therefore, this paper aims to 1) review known methodology for doing human factors research, with specific emphasis onvisualization, 2) review current human factors research in visualization to provide a basis for future investigation, and 3) identifypromising areas for future research.Index Terms\\xe2\\x80\\x94Human factors, visualization, perception, cognitive support, methodology.\\xc3\\xa61 INTRODUCTIONMODERN technology provides access to large quantitiesof data in many application domains, such as medicalimaging, fluid flow simulation, and geographic informationsystems (GIS). The complexity of the data can make analysisa challenging cognitive activity. Ware defines visualizationas \\xe2\\x80\\x9ca graphical representation of data or concepts,\\xe2\\x80\\x9d which iseither an \\xe2\\x80\\x9cinternal construct of the mind\\xe2\\x80\\x9d or an \\xe2\\x80\\x9cexternalartifact supporting decision making.\\xe2\\x80\\x9d1 In other words,visualizations assist humans with data analysis by repre-senting information visually. This assistance may be calledcognitive support. Visualizations can provide cognitivesupport through a number of mechanisms, as summarizedin Table 1. These mechanisms can exploit advantages ofhuman perception, such as parallel visual processing, andcompensate for cognitive deficiencies, such as limitedworking memory.1.1 Terminology: Continuous and Discrete ModelVisualizationVisualization can be valuable in a wide variety of applica-tion domains. Visualization techniques have been tradition-ally categorized into two major areas:..\\xe2\\x80\\x9cscientific visualization,\\xe2\\x80\\x9d which involves scientificdata with an inherent physical component, and\\xe2\\x80\\x9cinformation visualization,\\xe2\\x80\\x9d which involves abstract,nonspatial',\n",
       " 'Multi-Modal Perceptualization of Volumetric Data and Its Application toMolecular DockingRoss Maciejewski Seungmoon Choi David S. Ebert Hong Z. TanSchool of ECE, Purdue University, USAE-mail: {rmacieje, chois, ebertd, hongtan}@purdue.eduAbstractIn this paper, we present a multi-modal data perceptual-ization system used to analyze the bene\\xef\\xac\\x81ts of augmenting avolume docking problem with other perceptual cues, par-ticularly stereoscopic vision and haptic rendering. Thiswork focuses on the problem of matching complex three-dimensional shapes in order to reproduce known con\\xef\\xac\\x81gu-rations. Speci\\xef\\xac\\x81cally, we focus on the docking of two pro-teins, actin and co\\xef\\xac\\x81lin, responsible for cellular locomotion.Users were shown examples of co\\xef\\xac\\x81lin combining with actinand asked to reproduce this match. Accuracy of the matchand completion time were measured and analyzed in orderto quantify the bene\\xef\\xac\\x81ts of augmenting tools for such a task.1. IntroductionStarting in the early nineties, a push for data perceptu-alization resulted in the development of many haptic ren-dering systems. Early systems [1, 5] used the local gra-dient as the surface normal and force transfer functions1.Newer systems have incorporated proxy-based haptic ren-dering techniques for volumetric data rendering [4, 6]. Apioneering work where both visual and haptic perceptualcues were used was Project GROPE [3] developed at theUniversity of North Carolina, Chapel Hill. While recently,one of the most popular molecular visualization packages,Visual Molecular Dynamics (VMD), has also been aug-mented with force feedback [10].Despite the signi\\xef\\xac\\x81cant progress in computational mod-els and techniques for data perceptualization, much workremains for the quantitative evaluation of data perceptual-ization systems in terms of their effectiveness in transmit-ting information to the user. Moreover, researchers and sci-entists have been slow in adopting the new technologies. Inlight of this, there is a pressing need to quantify the useful-ness of data visualization systems in order to demonstratetheir applicability to scientists.Our research group recently developed an InteractiveVolume Illustration System (IVIS) [9] to create illustra-tions of three-dimensional datasets. IVIS provides a graph-ical user interface in which the user can easily control the(a) Actin.(b) Co\\xef\\xac\\x81lin.(c) Combined.Figure 1: Volumetric datasets for actin and co\\xef\\xac\\x81lin.shape of a transfer function. By applying the user-de\\xef\\xac\\x81nedtransfer function to the ',\n",
       " 'Portable Haptic Display for Large Immersive Virtual Environments\\xe2\\x88\\x97Enkhtuvshin DorjgotovEnvision Center for DataPerceptualizationPurdue University, USASeungmoon Choi\\xe2\\x80\\xa0Virtual Reality andPerceptive Media LaboratoryDepartment of ComputerScience and EngineeringPOSTECH, KoreaSteven R. Dunlop\\xe2\\x80\\xa1Envision Center for DataPerceptualizationPurdue University, USAGary R. Bertoline\\xc2\\xa7Envision Center for DataPerceptualizationPurdue University, USAABSTRACTThis paper introduces Portable Haptic Display (PHD), a novelplatform-independent haptic rendering system that can be conve-niently integrated into a large immersive virtual environment whilemaximizing the individual reusability of haptic interfaces and vi-sual displays. The PHD has an architecture of distributed renderingwhere two computers (or clusters of computers) are in charge ofall computations needed for rendering with corresponding displaysand share necessary information via network. We report the archi-tecture, implementation details, and performance evaluation resultsof the PHD in this paper. The PHD is especially useful in placesthat have multiple haptic interfaces and large immersive visual dis-plays and that need to use them together as well as individually,such as research laboratories, companies, and hospitals.CR Categories: H.5.1 [Information Interfaces and Presentation]:Multimedia Information Systems\\xe2\\x80\\x94Arti\\xef\\xac\\x81cial, Augmented, and Vir-tual Realities; H.5.2 [Information Interfaces and Presentation]:User Interfaces\\xe2\\x80\\x94Haptic I/O; H.5.3 [Information Interfaces andPresentation]: Group and Organization Interfaces\\xe2\\x80\\x94CollaborativeComputing, Synchronous Interaction;Keywords:portable haptic display, distributed renderinglarge immersive virtual environment,Haptics,1INTRODUCTIONThe recent advent of haptics technology enables us to create muchmore convincing virtual environments by providing a user with thecapability of touching the environments as well as seeing and hear-ing them. Diverse high-performance haptic interfaces have beendeveloped for a variety of purposes and applications in the past oneand half decade (see [3][13] for reviews). A few of them, includ-ing the PHANToM family (Sensable Technologies; Woburn, MA,USA) and the Delta and Omega Devices (Force Dimension; Lau-sanne, Switzerland), have been successfully commercialized andwidely used for various desktop applications. However, integratingforce-feedback haptic interfaces into large immersive virtual envi-ronments such as those displayed using a CAVETM-l',\n",
       " 'Proceedings of the IEEE ITSC 20062006 IEEE Intelligent Transportation Systems ConferenceToronto, Canada, September 17-20, 2006Vibrotactile Display for Driving Safety Information MC5.4Hyunho Kim, Changhoon Seo, Junhun Lee, Jeha Ryu, Sibok Yu and Sooyoung Lee  Abstract\\xe2\\x80\\x94Vehicle driving support systems such as navigation systems  and  dead-angle  warning  systems  make  us  safer  and more  comfortable.  These  kinds  of  systems  provide  only  visual and  auditory  information.  However,  visual  driving  support systems  are  restricted  in  driver\\xe2\\x80\\x99s  field-of-view  and  auditory warning  signals  can  lose  in  radio  music,  engine  noise,  or conversation noise. Tactile displays using vibration motors can provide useful information in spite of restricted field-of-view and noisy  environment.  It  may  quickly  draw  the  attention  of  the driver  when  important  events  occur:  for  instance,  collision warning  and  directional  cues.  These  intuitive  and  quick  cues may be combined together with the visual and auditory display to  give  multimodal  feedback  to  the  driver.  In  this  paper,  we present  a  vibrotactile  display  device  for  providing  safety information to drivers. User studies with the vibrotactile device on the top of the foot show 86.7% recognition rate for alphabet characters after some training and 83.9% for providing driving safety information.I.INTRODUCTIONNOWADAYS, there are very good applications to support to drivers for providing useful information, for example navigation system to find the shortest way to destination with respect to traffic condition, lane assist system using camera, backward detection system using ultrasonic sensor and so on. However, these driving assistance systems give us only visual and auditory information or combined. In many cases, a driver cannot  recognize  these  kinds  of  information  from  the assistance system. Navigation map, that is visual information, can restrict in driver\\xe2\\x80\\x99s visual field and auditory information may not transfer to driver because of radio music and noise from vehicle.  However, tactile display can transmit useful information to parts  of  the  human  body  as  a  new  delivering  method. Especially, tactile display has an advantage about transmitting intuitive  information  such  as  direction  cue.  It  can  be  also supplement visual or auditory display in potentially hazardous situations in driving situation. Tactile display devices may be classified into',\n",
       " 'Constructive Perception: A Metacognitive Skill for Coordinating Perceptionand ConceptionMasaki Suwa (suwa@sccs.chukyo-u.ac.jp)PRESTO, JST & School of Computer and Cognitive Sciences, Chukyo University,101 Tokodachi, Kaizu, Toyota, 470-0348 JapanBarbara Tversky (bt@psych.stanford.edu)Department of Psychology, Stanford University,Stanford, CA 94305-2130 USAin theinterprets them. This implies that experts are able todifferentiate and perceive meaning in some features andrelationsexternal world that would bemeaningless to novices or misinterpreted by novices.For example, the move history and options on a mid-game chessboard are not apparentto chess novices.Similarly, a statistical graph with two data lines thatform an X may perplex a novice, but greeted withexcitement by the expert, who sees in it an interaction.The ability to infer conceptual features from perceptualones is often taken for granted by experts. Therefore,acquisition of expertise can be regarded as a process ofbecoming able to perceive what was not evidentpreviously. Gibson and Gibson (1955) described asimilar process, also in relation to expertise, in theircase, wine-tasting: \\xe2\\x80\\x9cPerceptual learning, then, consistsof responding to variables of physical stimulation notpreviously responded to\\xe2\\x80\\x9d (p. 34). Recent studies on theroles of external representations (e.g. Chandrasekaran,Glasgow & Narayanan, 1995) suggest that the interplayof perception and conception is a major driving-force ofhuman problem solving and inferenceIn the realm of design, expertise in perceiving plansand sketches is of particular significance. Sketches onpaper are not simply instructions to engineers andcontractors. Sketches also serve the designer as anexternal tool for checking the coherence and appearanceof ideas as well as for generating new ideas andinterpretations. Sketches are a revelation of a set ofideas as well as a stimulus for new ones (e. g.,Goldschmidt, 1994; Schon, 1983). Arnheim (1969)called this \\xe2\\x80\\x9cvisual thinking\\xe2\\x80\\x9d, providing many examplesin art and architecture.Reinterpreting sketches and generating new ideaswork in a productive cycle. A detailed study of thecognitive processes of an expert architect revealed thatwhen he made new perceptual discoveries in his ownsketches, he was more likely to come up with new ideas.Similarly, new design ideas led him to see new featuresand relations in his sketches (Suwa, Gero and Purcell,2000).significantcomponents of expertise. One is perception of subtlefeatures and re',\n",
       " 'Experimenting with Haptic Attributes for Display of Abstract DataDepartment of Computer Science and Software Engineering,University of Sydney, Sydney, NSW. 2006. AustraliaKeith V. Nesbittknesbitt@cs.newcastle.edu.auAbstractInformation  perceptualization  has  been  defined  toinclude  the  three  domains  of  Information  Visualization,Information  Sonification  and  Information  Tactilisation[1]. While Information Visualization is a developing fieldand Sonification is an emerging field of study, very littlework  has  been  done  to  experiment  with  haptics  for  thedisplay  of  abstract  information.  This  paper  describessome pilot studies designed to test the feasibility of usingthree  different  attributes  of  touch  to  display  nominal  orordinal  data.  These  attributes  are  surface  hardness,surface  roughness  and  object  inertia.  The  results  areapplied to the display of stock market data on the HapticWorkbench.1. IntroductionInformation  Visualisation  is  a  developing  field  ofstudy  that  aims  to  display  abstract  information  to  thehuman  visual  sense.  The  emphasis is  on  allowingperceptual cues in the visualisation to convey informationabout  structure,  patterns  or  rules  in  the  data  [1].  Manyexamples  of information  visualisation  have  beendeveloped  over  the  years  in  a  wide  range  of  fieldsincluding  the  display  of  stock  market  data  [2],  networkmaps  of forunderstanding complex software systems [4].telecommunication  systems [3]  and By  contrast  Information  Sonification  is  only  a  newlyemerging  field  and  while  examples  of  using  sound  forinformation  display  have  been  used  in  some  traditionalfields such as sonar tracking in submarines and as alarmsystems  in  aircraft  the  attempt  to  map  abstract  dataattributes  to  the  attributes  of  sound  is  a  relatively  newendeavor  [5].  Still  a  number  of  interesting  applicationshave  been  developed  which  include  a  simple  soundenhanced  interface  for  the  Macintosh  Finder  calledSonicFinder  [6],  use  of  sound  to  help  understand  anddebug  parallel  computer  programs  [7],  and  auditoryversions of 2D statistical scatter plots [8].Information  Tactilisation,  as  the  display  of  abstractinformation to the sense of touch has been termed [1] hasthe potential to also emerge as a new field of study. Someexamples  exist,  force  feedback  has  been  used  to  displayflow  fields  in  blast  furnace  data  [9],  to ',\n",
       " '588IEEE TRANSACTIONS ON SIGNAL PROCESSING, VOL. 56, NO. 2, FEBRUARY 2008Perception-Based Data Reduction and Transmissionof Haptic Data in Telepresence andTeleaction SystemsPeter Hinterseer, Member, IEEE, Sandra Hirche, Member, IEEE, Subhasis Chaudhuri, Senior Member, IEEE,Eckehard Steinbach, Member, IEEE, and Martin Buss, Member, IEEEAbstract\\xe2\\x80\\x94We present a novel approach for the transmission ofhaptic data in telepresence and teleaction systems. The goal of thiswork is to reduce the packet rate between an operator and a tele-operator without impairing the immersiveness of the system. Ourapproach exploits the properties of human haptic perception andis, more speci\\xef\\xac\\x81cally, based on the concept of just noticeable differ-ences. In our scheme, updates of the haptic amplitude values aresignaled across the network only if the change of a haptic stimulusis detectable by the human operator. We investigate haptic datacommunication for a 1 degree-of-freedom (DoF) and a 3 DoF tele-action system. Our experimental results show that the presentedapproach is able to reduce the packet rate between the operatorand teleoperator by up to 90% of the original rate without affectingthe performance of the system.Index Terms\\xe2\\x80\\x94Compression, deadband, haptics, psychophysics,teleaction, telepresence.I. INTRODUCTIONTELEPRESENCE AND TELEACTION (TPTA) systemshave been and still are the subject of extensive inter-disciplinary research covering the areas of communications,computer science, robotics, system theory, and psychology.TPTA systems allow the operator to be present and active inremote environments that can be distant, scaled to macro- ornanoworlds, or hazardous for the human using multiple humansensing modalities. Example applications are telemaintenance,telesurgery, and tele-edutainment.Manuscript received March 23, 2006; revised May 3, 2007. The associate ed-itor coordinating the review of this manuscript and approving it for publicationwas Dr. Manuel Davy. This work was supported by the Collaborative ResearchCenter SFB 453 of the German Research Foundation (DFG). The work of S.Chaudhuri was supported by the Alexander von Humboldt Foundation. Part ofthis work was presented at the ICASSP\\xe2\\x80\\x9905, ICCE\\xe2\\x80\\x9906, Haptics Symposium\\xe2\\x80\\x9906,and ICASSP\\xe2\\x80\\x9906.P. Hinterseer and E. Steinbach are with the Institute of Communica-tion Networks (LKN), Media Technology Group, Technische UniversitaetMuenchen, 80290 Muenchen, Germany (e-mail: ph@tum.de; eckehard.stein-bach@tum.de).S. Hirche is with the ',\n",
       " 'Haptizing Surface Topography with Varying StiffnessBased on Force Constancy: Extended AlgorithmJaeyoung Cheon\\xe2\\x88\\x97Inwook Hwang\\xe2\\x80\\xa0Gabjong Han\\xe2\\x80\\xa1Seungmoon Choi \\xc2\\xa7Haptics and Virtual Reality LaboratoryDepartment of Computer Science and EngineeringPOSTECH, Republic of KoreaABSTRACTThis article introduces a novel haptization method for renderingsurface topography with varying stiffness via a force-feedback hap-tic interface. Previously, we showed that when surface topographywith varying stiffness is rendered with the conventional penalty-based method, topography information perceived by the user canbe distorted from its model. This phenomenon was explained bythe theory of force constancy which states that the user maintainsan invariant contact force level when s/he strokes a surface to per-ceive its topography. To resolve the problem, we then developeda basic topography compensation algorithm (TCA) based on theforce constancy, for a single height-change region with nonuniformstiffness perceived via lateral stroking. The basic TCA was mainlyto test the applicability of force constancy to haptic rendering. Inthis article, we present an extended TCA that adequately deliverssurface topography that may contain a number of height-changingregions with varying stiffness for any user exploratory patterns. Wealso measured the human detection thresholds of surface slope me-diated with a force-feedback device and used these data for design-ing the extended TCA. The performance of the extended TCA wasextensively examined in terms of proximal stimuli it creates and ac-tual percepts induced from the stimuli. The extended TCA bringsa one-step advance from the current practice of haptic renderingwhich requires constant surface stiffness for an adequate deliveryof surface shape.Index Terms: H.5.1 [Information Interfaces and Presentation]:Multimedia Information Systems\\xe2\\x80\\x94Arti\\xef\\xac\\x81cial, Augmented, and Vir-tual Realities; H.5.2 [Information Interfaces and Presentation]:User Interfaces\\xe2\\x80\\x94Haptic I/O1 INTRODUCTIONData perceptualization aims at delivering the properties of a data setto the user through multi-modal sensory channels and is a promis-ing application area of haptics. Extended from traditional data vi-sualization, other sensory modalities such as sound (data soni\\xef\\xac\\x81ca-tion) and touch (data haptization) are actively involved in data per-ceptualization, so that the user can see, hear, and touch the datawith increased information transfer bandwidth. By perceptualiza-tion techniques',\n",
       " '12th International Conference Information Visualisation   Beyond the Tyranny of the Pixel:  Exploring the Physicality of Information Visualization    Andrew Vande Moere Faculty of Architecture, Design and Planning, The University of Sydney  andrew@arch.usyd.edu.au   Abstract This  paper  consists  of  a  review  of  contemporary methods  that  map  and  materialize  abstract  data  as physical  artifacts.  With  computing  technology  and  the access  of  information  influencing  every  aspect  of  our everyday  lives,  one  can  question  the  current  habit  of information displays to \\xe2\\x80\\x98simulate\\xe2\\x80\\x99 real world metaphors, and  whether  information  could  instead  be  conveyed  by approximating the analogue and tangible characteristics of  our  daily  experiences.  This  paper  introduces  five different degrees of \\xe2\\x80\\x98data physicality\\xe2\\x80\\x99, which differ in the level of abstraction of how data is mapped and perceived by  human  senses:  ambient  display,  pixel  sculptures, object  augmentation,  data  sculptures  and  alternative modality. This categorization demonstrates the potential of information visualization as a communication medium in its own right, which proliferates beyond the ubiquitous pixel-based, light-emitting surfaces of today.   Keywords    info-aesthetics,  data  sculpture,  pixel sculpture, multi-modal visualization, ambient display  1. Introduction challenge Since its conception about 15 years ago, the field of information  visualization  has  mainly  focused  on  the representation  of  data  on  screen-based  output  media. Information  visualization  methods  are  specifically designed to augment the perception of abstract data, data that  possesses  no  inherent  spatial  layout  or  presence  in the physical world. Because abstract data has no natural counterpart  that  can  be  graphically  reproduced,  the visualization the  design, development  and  evaluation  of  novel  data  mapping metaphors  for  presenting in  an  easily perceivable  and  understandable  way.  The  use  of  digital computer  screens  and  projections  for  this  purpose possesses  several  obvious  strengths,  including  their quick,  dynamic  frame-rate,  their  huge  and  detailed resolutions,  and  their  capability  to  immerse  people within  a  virtual  representation  that  almost  cannot  be distinguished  from  that  of  reality.  However,  as  we observe the implications of computing penetrating every consists  of information 1550-6037/08 $25.00 ',\n",
       " 'IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, VOL. 17, NO. 12, DECEMBER 20112203Quality Metrics in High-Dimensional Data Visualization:An Overview and SystematizationEnrico Bertini, Member, IEEE, Andrada Tatu, and Daniel Keim, Member, IEEEAbstract\\xe2\\x80\\x94In this paper, we present a systematization of techniques that use quality metrics to help in the visual exploration ofmeaningful patterns in high-dimensional data.In a number of recent papers, different quality metrics are proposed to automatethe demanding search through large spaces of alternative visualizations (e.g., alternative projections or ordering), allowing the userto concentrate on the most promising visualizations suggested by the quality metrics. Over the last decade, this approach haswitnessed a remarkable development but few re\\xef\\xac\\x82ections exist on how these methods are related to each other and how the approachcan be developed further. For this purpose, we provide an overview of approaches that use quality metrics in high-dimensional datavisualization and propose a systematization based on a thorough literature review. We carefully analyze the papers and derive a setof factors for discriminating the quality metrics, visualization techniques, and the process itself. The process is described through areworked version of the well-known information visualization pipeline. We demonstrate the usefulness of our model by applying it toseveral existing approaches that use quality metrics, and we provide re\\xef\\xac\\x82ections on implications of our model for future research.Index Terms\\xe2\\x80\\x94Quality Metrics, High-Dimensional Data Visualization.1 INTRODUCTIONThe extraction of relevant and meaningful information out of high-dimensional data is notoriously complex and cumbersome. The curseof dimensionality is a popular way of stigmatizing the whole set oftroubles encountered in high-dimensional data analysis; \\xef\\xac\\x81nding rele-vant projections, selecting meaningful dimensions, and getting rid ofnoise, being only a few of them. Multi-dimensional data visualiza-tion also carries its own set of challenges like, above all, the limitedcapability of any technique to scale to more than an handful of datadimensions.Researchers have been trying to solve these problems through anumber of automatic data analysis and visualization approaches thatcover the whole spectrum of possibilities: from fully automatic tofully interactive. Visualization researchers have discovered early onthat searching for interesting patterns in this k',\n",
       " 'Perception-Based Visual Quality MeasuresGeorgia Albuquerque\\xe2\\x88\\x97TU BraunschweigGermanyMartin Eisemann\\xe2\\x80\\xa0TU BraunschweigGermanyMarcus Magnor\\xe2\\x80\\xa1TU BraunschweigGermanyABSTRACTIn recent years diverse quality measures to support the explorationof high-dimensional data sets have been proposed. Such measurescan be very useful to rank and select information-bearing projec-tions of very high dimensional data, when the visual explorationof all possible projections becomes unfeasible. But even though aranking of the low dimensional projections may support the user inthe visual exploration task, different measures deliver different dis-tances between the views that do not necessarily match the expec-tations of human perception. As an alternative solution, we proposea perception-based approach that, similar to the existing measures,can be used to select information bearing projections of the data.Speci\\xef\\xac\\x81cally, we construct a perceptual embedding for the differ-ent projections based on the data from a psychophysics study andmulti-dimensional scaling. This embedding together with a rankingfunction is then used to estimate the value of the projections for aspeci\\xef\\xac\\x81c user task in a perceptual sense.Index Terms: H.3.3 [Information Storage and Retrieval]: Infor-mation Search and Retrieval\\xe2\\x80\\x94; Clustering; I.3.3 [Computer Graph-ics]: Picture/Image Generation;1 INTRODUCTIONInnovative approaches in visual analytics for high-dimensional datasets have presented quality measures that can be used to automati-cally select promising projections of the data [13, 14]. The visualanalysis of such data sets usually requires projecting the data intolower-dimensional representations. However, with the increasingamount of dimensions in scienti\\xef\\xac\\x81c data sets the exhaustive analysisof all possible projections requires prohibitive time. So-called qual-ity measures have been used in a pre-processing phase to the visualexploration. They can be effectively used to rank the possible pro-jections of the data according to one or more user tasks and reducethe number of views to be examined by sorting them or selectingthe best ones.Usually de\\xef\\xac\\x81ned with respect to an exploration task, the qualitymeasures can be de\\xef\\xac\\x81ned as ranking functions for the projections.However, an open issue of these methods is that the range and dis-tribution of ranking values depends on the algorithm of each indi-vidual measure and it is not possible to directly compare the resultsof the different measures. Speci\\xef\\xac\\x81cally, the p',\n",
       " 'Distinct Brain Systems for Processing Concreteand Abstract ConceptsJ. R. Binder1, C. F. Westbury2, K. A. McKiernan1,E. T. Possing1, and D. A. Medler1Abstract& Behavioral and neurophysiological effects of word image-ability and concreteness remain a topic of central interest incognitive neuroscience and could provide essential clues forunderstanding how the brain processes conceptual knowledge.We examined these effects using event-related functionalmagnetic resonance imaging while participants identifiedconcrete and abstract words. Relative to nonwords, concreteand abstract words both activated a left-lateralized network ofmultimodal association areas previously linked with verbalsemantic processing. Areas in the left lateral temporal lobewere equally activated by both word types, whereas bilateralregions including the angular gyrus and the dorsal prefrontalcortex were more strongly engaged by concrete words. Relativeto concrete words, abstract words activated left inferior fron-tal regions previously linked with phonological and verbalworking memory processes. The results show overlapping butpartly distinct neural systems for processing concrete and abs-tract concepts, with greater involvement of bilateral associa-tion areas during concrete word processing, and processing ofabstract concepts almost exclusively by the left hemisphere. &INTRODUCTIONA still-unresolved issue in cognitive science concerns thenature of semantic representations. How are wordmeanings represented in the mind? One general ap-proach focuses on the associative relationships betweenwords. Just as a word can be verbally defined in adictionary, determining the meaning of a word seemspartly to involve retrieval of other words with which it isclosely associated (Deese, 1965; Noble, 1952). Anotherlong tradition views knowledge about word meaning aslargely separate from language, involving sensory andmotor \\xe2\\x80\\x98\\xe2\\x80\\x98images\\xe2\\x80\\x99\\xe2\\x80\\x99 learned through perceptual experience(James, 1890; Wernicke, 1874).One type of evidence on this topic comes fromstudies showing a processing advantage for words rep-resenting concrete, imageable concepts over those rep-resenting abstract concepts. Concrete words are morequickly recognized (Strain, Patterson, & Seidenberg,1995; Kroll & Merves, 1986; James, 1975), better re-membered (Paivio, 1971), and more resilient to braindamage (Katz & Goodglass, 1990; Roeltgen, Sevush, &Heilman, 1983; Coltheart, Patterson, & Marshall, 1980;Goodglass, Hyde, & Blumstein, 1969) than abst',\n",
       " 'Information Technologies in Medicine, Volume I: Medical Simulation and Education.Edited by Metin Akay, Andy MarshCopyright ( 2001 John Wiley & Sons, Inc.ISBNs: 0-471-38863-7 (Paper); 0-471-21669-0 (Electronic)INFORMATIONTECHNOLOGIESIN MEDICINE\\x0c',\n",
       " 'FACE CHARTS: A BETTER METHOD FOR VISUALIZING COMPLICATED DATA Ray Wyatt School of Resource Management and Geography, University of Melbourne, Australia ABSTRACT This  paper  develops  earlier  work  by  Chernoff  (1973)  and  others,  all  of  whom  used  face  diagrams  to  visualize multi-faceted data in a fast, holistic and understandable way.  Their face diagrams took advantage of humans\\xe2\\x80\\x99 impressive face-recognition  and  face-interpretation  capabilities.    As  such,  face  diagrams  should  be  superior  communicators  of complicated information compared to the more common forms of diagramming.  However, it is argued here that face diagrams are frequently misinterpreted due to humankind\\xe2\\x80\\x99s emotional relationship with realistic-looking faces and the consequent cultural, racial, and sex-, age- and emotions-based interpretations of them which inhibit accurate perception of the data\\xe2\\x80\\x99s true relativities.  Accordingly, we here develop here a modification of face diagrams, called face charts, which are less reminiscent of actual human faces yet still realistic against those of two traditional diagramming methods \\xe2\\x80\\x93 the bar chart and the star plot.  Although our sample of test respondents was small it still generated strongly suggestive evidence that using face charts enables respondents to understand ten-dimensional data better than if they were using star plots or bar charts.  Understanding is measured here by the speed with which a respondent can both successfully rank the sizes  of  a  randomly  chosen  variable  within  four  charts  and  successfully  determine  which  pair  of  charts  is  the  most \\xe2\\x80\\x9csimilar\\xe2\\x80\\x9d.  As such, face charts constitute a very promising data-visualization method for showing the intrinsic nature of multi-dimensional places or entities with speed and accuracy.  KEYWORDS Data, communication, visualization, face diagrams, face charts. 1.  INTRODUCTION The  problem  addressed  by  this  paper  is  how  to  more  effectively  communicate  the  intrinsic  nature  of complicated entities that are characterized by many variables.  All too often one reads textbooks in which the narrative simply talks about the relative sizes of attributes pertaining to several complex places or things and so  the  unfortunate  reader  quickly  loses  track  of  what  has  been  said  about  which  variables,  compared  to comparable  variables  within  other  entities.    Moreover,  tediously  long  tables  of  data  tend  to  be  only marginal',\n",
       " 'Journal of Biomedical Informatics 37 (2004) 380\\xe2\\x80\\x93391Methodological Reviewwww.elsevier.com/locate/yjbinMultivariate image analysis in biomedicineTim W. Nattkemper*Applied Neuroinformatics Group, Faculty of Technology, Bielefeld University, P.O. Box 100131, D-33501 Bielefeld, GermanyReceived 27 May 2004Available online 25 September 2004AbstractIn recent years, multivariate imaging techniques are developed and applied in biomedical research in an increasing degree. Inresearch projets and in clinical studies as well m-dimensional multivariate images (MVI) are recorded and stored to databasesfor a subsequent analysis. The complexity of the m-dimensional data and the growing number of high throughput applications callfor new strategies for the application of image processing and data mining to support the direct interactive analysis by humanexperts. This article provides an overview of proposed approaches for MVI analysis in biomedicine. After summarizing the biomed-ical MVI techniques the two level framework for MVI analysis is illustrated. Following this framework, the state-of-the-art solutionsfrom the \\xef\\xac\\x81elds of image processing and data mining are reviewed and discussed. Motivations for MVI data mining in biology andmedicine are characterized, followed by an overview of graphical and auditory approaches for interactive data exploration. Thepaper concludes with summarizing open problems in MVI analysis and remarks upon the future development of biomedicalMVI analysis.\\xc3\\x93 2004 Elsevier Inc. All rights reserved.Keywords: Multimodalimaging; Optical microscopy; Medicalimaging; Data Mining; Explorative data analysis; Arti\\xef\\xac\\x81cial neural networks;Man\\xe2\\x80\\x93machine interaction; Multimodal display1. Introductionvoxelvaluesto pixel orIn recent years we observe an increasing number of bio-medical imaging applications that associate a number ofm signalcoordinatesp in a two- or three-dimensional array (i.e., p = (x, y) or= (x, y, z), respectively). In the result stack of m intensityimages, m locally corresponding signal values s1, . . ., smare associated to a pixel (or voxel) p and can be interpretedas a point s (p) = (s1, . . ., sm) in an m-dimensional space.Without loss of generality, we assume that the signalsare subject to a post-imaging normalization step andmapped to an appropriate scale si 2 [0;1]. This mappingprocedure often includes the application of a log functionto enhance weak signals and/or a rescaling of the vectorcomponents si to have zero mean and unit varia',\n",
       " 'Data Sonification and Sound VisualizationHans G. Kaper, Sever Tipei, and Elizabeth Wiebel  Citation: Computing in Science & Engineering 1, 48 (1999); doi: 10.1109/5992.774840 View online: http://dx.doi.org/10.1109/5992.774840 View Table of Contents: http://scitation.aip.org/content/aip/journal/cise/1/4?ver=pdfcov Published by the AIP Publishing  Articles you may be interested in Fast recognition of musical sounds based on timbre J. Acoust. Soc. Am. 131, 4124 (2012); 10.1121/1.3701865  Spectral envelope sensitivity of musical instrument sounds J. Acoust. Soc. Am. 123, 500 (2008); 10.1121/1.2817339  Perception of acoustic scale and size in musical instrument sounds J. Acoust. Soc. Am. 120, 2158 (2006); 10.1121/1.2338295  Could Olfactory Displays Improve Data Visualization? Comput. Sci. Eng. 6, 80 (2004); 10.1109/MCSE.2004.66  Audibility of the timbral effects of inharmonicity in stringed instrument tones ARLO 2, 79 (2001); 10.1121/1.1374756   This article is copyrighted as indicated in the article. Reuse of AIP content is subject to the terms at: http://scitationnew.aip.org/termsconditions. Downloaded to IP:137.110.84.4 On: Mon, 08 Jun 2015 20:24:10\\x0c',\n",
       " 'Hanoi,Vietnam,pp.\\x01\\x05\\x05{\\x01\\x06\\x02,May\\x01\\t\\t\\x08.SynergisticVisual/HapticComputerInterfaces\\x01LucyY.PaoDaleA.LawrenceElectrical&ComputerEngineeringAerospaceEngineeringSciencesUniversityofColoradoUniversityofColoradoBoulder,Colorado\\x08\\x00\\x03\\x00\\t-\\x00\\x04\\x02\\x05Boulder,Colorado\\x08\\x00\\x03\\x00\\t-\\x00\\x04\\x02\\tpao@colorado.edudale.lawrence@colorado.eduAbstractWhilegraphicalvisualizationhasadvancedourabil-itytounderstandlargemulti-dimensionaldatasets,sometypesofdataarestilldi(cid:14)culttoconveyvi-sually.Combinedvisual/hapticcomputerinterfacesmayallowuserstoexploremulti-dimensionaldatasetsmorenaturally,wherethehumanhapticsenseinvolv-ingtouch,limbposition,andmuscletensionprovidesacomplementaryinformationchanneltoconveycer-taindataproperties.Wediscussthedevelopmentofhapticrenderingmodesandcombinedvisual/hapticrenderingmodeswhichcanconveycomplex,multi-dimensionaldata.Teststobetterunderstandhumanhapticandvisual/hapticperceptionofthenewdatarenderingelementsarealsooutlinedandinitialresultsarepresented.\\x01.IntroductionHumanvisioniswell-suitedfor\\x02-dimensional(\\x02D)patternunderstanding,andforidentifyingsolidob-jectsin\\x03-dimensional(\\x03D)spaces.Itis,however,lessadeptatunderstandingthefollowingtypesofdata:(cid:15)scalar(cid:12)eldson\\x03Ddomains,e.g.,temperatureinavolume,(cid:15)vector(cid:12)elds,e.g.,(cid:13)uid(cid:13)owvelocitythroughoutavolume,and(cid:15)tensor(cid:12)elds,e.g.,stresstensorsinelasticsolids.Traditionalvisualizationtechniquesattempttoreducetheseproblemstothedisplayof\\x02Dpatternsthroughtechniquessuchasslicing,coloring,contouring,iso-surfacing,andstreamlining.Incaseswherethesedimension-reductiontechniquesfail,suchasinten-sor(cid:12)eldrenderingwherethepropertiesofmatricesateachpointareofinterest,symbolicrepresentations(glyphs)areoftenused.Figure\\x01showsanexampleofthetypeofvisualizationdi(cid:14)cultiesthatareoftenencountered.Here,conesareplottedtoindicatethemagnitudeanddirectionoftheelectromagnetic(cid:12)eldonandaroundalargegapLorentzforceactuator.Vi-sualclutterseverelylimitsunderstandingofthevari-ationofthe(cid:12)eldinthevolume.Hapticperception,incontrast,isratherpooratde-terminingglobalshapeorspatialpatterns.However,ithascomplementarycapabilitiesindiscerninglocal\\x01ThisworkwassupportedinpartbytheNationalScienceFoundation(NSF)(GrantIRI-\\t\\x07\\x01\\x01\\t\\x03\\x06),theO(cid:14)ceofNavalRe-searchDefenseUniversityResearchInstrumentationProgram(GrantN\\x00\\x00\\x00\\x01\\x04-\\t\\x07-\\x01-\\x00\\x03\\x05\\x04),andtheNSFEngineeringResearchCenteronOptoelectronicComputingSystemsattheUniversityofColoradoatBoulder(GrantEEC-\\t\\x00\\x01\\x05\\x01\\x02\\x08).The(cid:12)rstauthorwasalsosupportedbyanNSFCAREERAward(GrantCMS-\\t',\n",
       " 'Monographs of the Society for Research in Child Development, Vol. 52, No. 1, Perceiving Similarity and Comprehending Metaphor Author(s): Lawrence E. Marks, Robin J. Hammeal, Marc H. Bornstein and Linda B. Smith Source: Perceiving Similarity and Comprehending Metaphor (1987), pp. i+iii+v+1-100Published by: Stable URL: Accessed: 10-06-2015 08:17 UTCSociety for Research in Child DevelopmentWiley on behalf of the http://www.jstor.org/stable/1166084    Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at http://www.jstor.org/page/info/about/policies/terms.jsp JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.Wiley and Society for Research in Child Development are collaborating with JSTOR to digitize, preserve and extend access toMonographs of the Society for Research in Child Development.  http://www.jstor.orgThis content downloaded from 132.239.1.231 on Wed, 10 Jun 2015 08:17:16 UTCAll use subject to JSTOR Terms and Conditions\\x0c',\n",
       " 'Journal of the American Medical Informatics Association Volume 13 Number 2 Mar / Apr 2006121The Practice of InformaticsJAMIAWhite Paper nPersonal Health Records: De\\xef\\xac\\x81nitions, Bene\\xef\\xac\\x81ts, and Strategies forOvercoming Barriers to AdoptionPAUL C. TANG, MD, MS, JOAN S. ASH, PHD, DAVID W. BATES, MD, J. MARC OVERHAGE, MD, PHD,DANIEL Z. SANDS, MD, MPHA b s t r a c t Recently there has been a remarkable upsurge in activity surrounding the adoption of personalhealth record (PHR) systems for patients and consumers. The biomedical literature does not yet adequately describethe potential capabilities and utility of PHR systems. In addition, the lack of a proven business case for widespreaddeployment hinders PHR adoption. In a 2005 working symposium, the American Medical Informatics Association\\xe2\\x80\\x99sCollege of Medical Informatics discussed the issues surrounding personal health record systems and developedrecommendations for PHR-promoting activities. Personal health record systems are more than just static repositoriesfor patient data; they combine data, knowledge, and software tools, which help patients to become active participantsin their own care. When PHRs are integrated with electronic health record systems, they provide greater bene\\xef\\xac\\x81ts thanwould stand-alone systems for consumers. This paper summarizes the College Symposium discussions on PHRsystems and provides de\\xef\\xac\\x81nitions, system characteristics, technical architectures, bene\\xef\\xac\\x81ts, barriers to adoption, andstrategies for increasing adoption.j J Am Med Inform Assoc. 2006;13:121\\xe2\\x80\\x93126. DOI 10.1197/jamia.M2025.The 2005 Hurricane Katrina disaster exposed the fragilityof America\\xe2\\x80\\x99s health information infrastructure. When con-fronted by a hurricane, an avian \\xef\\xac\\x82u pandemic, or a bioterror-ism attack, the public needs to be able to depend on reliableaccess to their health information. Lack of a robust health infor-mation infrastructure undermines any attempt to establish acoherent and reliable plan to deal with natural or other disas-ters affecting the public\\xe2\\x80\\x99s health. Fortunately, large-scale cata-strophic disasters are rare, but that does not diminish the needfor a robust health information infrastructure that signi\\xef\\xac\\x81cantlyimproves both personal and public health care delivery.Over the past several years, there has been a remarkable up-surge in activity promoting the adoption of electronic healthAf\\xef\\xac\\x81liations of the authors: Palo Alto Medical Foundation, Palo Alto,CA (PCT); Oregon Health & Science University, Po',\n",
       " \"An Experimental Analysisof the Effectiveness ofFeatures in ChernoffFacesChristopher J. Morris, David S. Ebert, PennyRheingansUniversity of Maryland Baltimore County1ABSTRACTChernoff faces have been proposed as a tool forscientificandinformationvisualization.However, the effectiveness of this form ofvisualizationisstill open to speculation.Chernoff faces, it is suggested, make use ofhumans' apparently inherent ability to recognizefaces and small changes in facial characteristics.Limited research has been conducted to assesshow well Chernoff faces make use of this ability.So far, it is still unclear how humans recognizefaces and whether or not a specific set of rulesgoverns the process. A particular area of interestis whether or not certain features are pre-attentive. Furthermore, what effect a certainnumber of distracters (i.e. more faces) have onthe attentiveness of various features is also ofconcern. This information could be used tomaximize the effectiveness of Chernoff faces byproviding an indication of which applicationswould be best served by the use of Chernofffaces. In order to address this issue, we haveconducted a user study, which tested theeffectiveness and pre-attentiveness of severalfeatures of Chernoff faces.Our user studyindicated that the perception of eye size, aspecific face, eyebrow slant, and the combinationeyebrow slant with eye size is a serial process(not pre-attentive). Our study also indicated thatfor longer viewing times (two seconds), eye sizeand eyebrow slant were the most accuratefeatures. These initial results indicate thatChernoff faces may not have a significantadvantage over other iconic visualizationtechniques for multidimensional informationvisualization.1CSEE Department, U. of Maryland BaltimoreCounty, 1000 Hilltop CircleBaltimore, MD 21250, {cmorris, ebert,rheingan} @csee.umbc.eduINTRODUCTIONIn scientific and information visualization, thegoal is to find a balance between the volume ofdata presented and the effective display of thatdata. One novel approach that has been proposedis the use of Chernoff faces to representscientific or information data [Ch73].Chernoff faces were first proposed by HermanChernoff {Ch73] in 1973, as a way to representmultivariate data in a manner that is easilydiscernible by the human viewer. The facesconsist of two-dimensional line drawings thatcontain a variety of facial features. Five exampleChernoff faces are shown in Figure 1 .Thesefacial features can be mapped to differentdimensions in a\",\n",
       " 'Sketchy Rendering\\rfor Information VisualizationIEEE TVCG 2013!Jo Wood\\rPetra Isenberg\\rTobias Isenberg\\rJason Dykes \\rNadia Boukhelifa\\rAidan Slingsby\\r\\x0c',\n",
       " 'Human-Data Interaction:The Human Face of the Data-Driven SocietyRICHARD MORTIER, UNIVERSITY OF NOTTINGHAMHAMED HADDADI, QUEEN MARY UNIVERSITY OF LONDONTRISTAN HENDERSON, UNIVERSITY OF ST. ANDREWSDEREK MCAULEY, UNIVERSITY OF NOTTINGHAMJON CROWCROFT, UNIVERSITY OF CAMBRIDGE5102 naJ 6  ]YC.sc[  2v9516.2141:viXraABSTRACTThe increasing generation and collection of personal data has created a complex ecosystem, often collaborative but sometimescombative, around companies and individuals engaging in the use of these data. We propose that the interactions betweenthese agents warrants a new topic of study: Human-Data Interaction (HDI). In this paper we discuss how HDI sits at theintersection of various disciplines, including computer science, statistics, sociology, psychology and behavioural economics.We expose the challenges that HDI raises, organised into three core themes of legibility, agency and negotiability, and wepresent the HDI agenda to open up a dialogue amongst interested parties in the personal and big data ecosystems.1.INTRODUCTIONThe process of moving from a world where computing is siloed and specialised, to a world where computing is ubiquitousand everyday, continues. In many parts of the world, networked computing is now mundane, both as a foreground technology(e.g., smartphones, tablets) and in the background (e.g., road traf\\xef\\xac\\x81c management, \\xef\\xac\\x81nancial systems). This has permitted, andcontinues to permit, new gloss on existing interactions as well as fundamentally new interactions (e.g., online banking,massively scalable distributed real-time gaming).We observe that human-computer interaction (HCI) research has traditionally focused on the interactions between humansand computers-as-artefacts, i.e., devices to be interacted with. As described by Grudin (Grudin, 1990b,a), the focus ofwork in HCI varies from psychology (Card et al., 1983) hardware to software to interface, and subsequently deeper intothe organisation. This trend, of the focus to move outward from the relative simple view of an operator using a pieceof hardware, continued with e.g., Bowers and Rodden (Bowers and Rodden, 1993) considering the richness of the inter-relationships between users and computer systems as those systems have pervaded organisations and become networked,and thus the need to \\xe2\\x80\\x9cexplode the interface\\xe2\\x80\\x9d. However in this paper we will not focus on the HCI history and the widespectrum of research interests and approaches.We believe that a broad range of existing w',\n",
       " 'Review Author(s): Richard E. Mayer and Piraye Bayman Review by: Richard E. Mayer and Piraye Bayman Source: Published by: Stable URL: Accessed: 11-06-2015 22:32 UTChttp://www.jstor.org/stable/1422536University of Illinois Press  The American Journal of Psychology, Vol. 97, No. 3 (Autumn, 1984), pp. 467-469  Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at http://www.jstor.org/page/info/about/policies/terms.jsp JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.University of Illinois Press is collaborating with JSTOR to digitize, preserve and extend access to The American Journal of Psychology.  http://www.jstor.orgThis content downloaded from 132.239.1.231 on Thu, 11 Jun 2015 22:32:59 UTCAll use subject to JSTOR Terms and Conditions\\x0c',\n",
       " 'M\\xc3\\xbcller et al. BMC Bioinformatics 2014, 15(Suppl 6):S5http://www.biomedcentral.com/1471-2105/15/S6/S5RESEARCHAnalysis of biomedical data with multilevelglyphsHeimo M\\xc3\\xbcller1*, Robert Reihs1, Kurt Zatloukal1, Andreas Holzinger2,3Open AccessAbstractBackground: This paper presents multilevel data glyphs optimized for the interactive knowledge discovery andvisualization of large biomedical data sets. Data glyphs are three- dimensional objects defined by multiple levels ofgeometric descriptions (levels of detail) combined with a mapping of data attributes to graphical elements andmethods, which specify their spatial position.Methods: In the data mapping phase, which is done by a biomedical expert, meta information about the dataattributes (scale, number of distinct values) are compared with the visual capabilities of the graphical elements inorder to give a feedback to the user about the correctness of the variable mapping. The spatial arrangement ofglyphs is done in a dimetric view, which leads to high data density, a simplified 3D navigation and avoidsperspective distortion.Results: We show the usage of data glyphs in the disease analyser a visual analytics application for personalizedmedicine and provide an outlook to a biomedical web visualization scenario.Conclusions: Data glyphs can be successfully applied in the disease analyser for the analysis of big medical datasets. Especially the automatic validation of the data mapping, selection of subgroups within histograms and thevisual comparison of the value distributions were seen by experts as an important functionality.BackgroundProfessionals in the biomedical domain are confrontedwith increasing masses of data, which require efficientand user-friendly solutions and the development ofmethods to assist them in knowledge discovery to iden-tify, extract, visualize and understand useful informationfrom these large amounts of data [1]. The trend towardspersonalized medicine has resulted in a mass of clinical,laboratory and genome-scale data and moreover, mostdata models are characterized by complexity, whichmakes manual analysis very time-consuming and fre-quently practically impossible [2]. The major challengeis: How can an expert find knowledge in these terabytesof complex data? For example, to successfully search fornovel hypotheses in large datasets, we must look forunexpected patterns and interpret evidence in ways thatframe new questions and suggest further explorations* Correspondence: heimo.muellere@medu',\n",
       " 'PROCEEDINGS of the HUMAN FACTORS and ERGONOMICS SOCIETY 56th ANNUAL MEETING - 20121659Human Factors Principles Underlying Glyph Design:  A Review of the Literature and an Agenda for Future Research Navaneethan Siva, Alex Chaparro, Ph.D., and Evan Palmer, Ph.D.   Human Factors Program Department of Psychology Wichita State University Glyphs are graphical icons that depict multivariate data and are used by a number of disparate fields. Their designs are  varied,  reflecting  both  the  diversity  of  applications  and  the  absence  of  design  standards.    In  the  absence  of guidelines,  glyph  designers  have  relied  on  their  intuition  and  expert  opinion  to  develop  a  diverse  collection  of idiosyncratic  techniques  for  representing  complex  data  sets.  Importantly,  it  is  not  clear  whether  glyph  design schemes are in any way optimal for efficient perceptual interpretation and usage. We note several findings in the perception and cognition literature that may serve as an initial basis for guidelines, we discuss how they might be used and the importance of doing so. Additionally, the dynamic updating of information in glyphs is a new trend that makes this kind of optimization necessary now more than has been in the past.    INTRODUCTION Human information processing is widely recognized as resource limited (e.g., Miller, 1956), yet individuals are often asked to perform safety critical tasks using displays that communicate large amounts of data (e.g., air traffic control). Graphical data visualizations allow for the consolidation of large amounts of information into symbolic visual representations so that emergent properties in the data may be revealed (Wickens & Hollands, 2000). Data visualization is used by a host of disciplines, including statistics, engineering, computer science, psychology, meteorology, and medicine.  Glyphs are one popular approach to data visualization for large, complex, multidimensional data sets (e.g., Prohaska, Aigner, & Miksch, 2007). A glyph is a visually distinct graphical entity that represents values on more than one data dimension via physical attributes such as shape, size, or color (Ward, 2002). For example, a glyph representing driving performance data from a simulator study might display each individual driver\\xe2\\x80\\x99s collision count, lane deviations, and time spent speeding as a single, complex icon. Figure 1 depicts several glyph types that are in common use. Evident in these examples is the fact tha',\n",
       " 'Home Search CollectionsJournals About Contact us My IOPscienceDataHigh: graphical user interface for visualizing and interacting with high-dimensional neuralactivityThis content has been downloaded from IOPscience. Please scroll down to see the full text.2013 J. Neural Eng. 10 066012(http://iopscience.iop.org/1741-2552/10/6/066012)View the table of contents for this issue, or go to the journal homepage for moreDownload details:IP Address: 132.239.1.231This content was downloaded on 09/06/2015 at 02:29Please note that terms and conditions apply.\\x0c',\n",
       " 'Use of Natural Sounds and Metaphors forData PerceptualizationSuresh K. Lodha, Ellen Venable, David Marsh, Doanna Meads,Nguyet Manh, Casey Robinson, Krishna RoskinComputer ScienceUniversity of CaliforniaSanta Cruz, CA 95064{ lodha\\xc2\\xa9cse.ucsc.edu,venable\\xc2\\xa9cats.ucsc.edu}ABSTRACTWe describe three systems that use natural or event-based sounds as means of data delivery. In these systemswe have mapped data to natural sounds using metaphors. In the first system we evaluate the use of sounds ofair, horn, and train to convey ordered numeric values between 1 to 6. An example of the metaphor used hereis the association of speed values to the sound of a moving train at different speeds. In the second system, weuse sounds of ocean waves to convey whether the exposure in a protein structural alignment is buried, partiallyexposed or fully exposed. The metaphor used here is the association of sound with how exposed the user is withrespect to the ocean. In the third system, we map animal sounds such as the sound of a roaring lion or a chirpingbird to certain stocks based on user preferences. The behavior of the stocks are then sounded by the use ofwhistles (up or down) and car crash to signify the movement in prices of the stocks. An up whistling sound canbe clearly associated with an uptrend. We present and discuss the results of user evaluation studies for all thethree systems.Keywords: sonification, perceptualization, metaphors, natural sounds, data mapping, protein alignment,stocks.1 INTRODUCTIONVision is the dominant paradigm for presenting information and scientific data. Haptics and audio is steadilygaining attention for data perceptualization in recent years aided by advances in technology.31\\'42\\'17 This workfocuses on the use of non-speech sound, referred to as sonification, for data perceptualization.Roughly speaking, one can categorize all the efforts in non-speech sound mapping into one of the threecategories \\xe2\\x80\\x94musicalsounds, natural or event-based sounds, and \"artificial\" sounds. By artificial sounds, we meanthose sounds that are not generated by using some physical object or instrument and the user cannot associatethem with some musical instrument or an event. Although musical sounds and event-based sounds are also beingincreasingly synthesized with the use of computers,32\\'2\\xc2\\xb0 artificial sounds are always synthesized. Sinusoidal soundsVisual Data Exploration and Analysis VIII, Robert F. Erbacher, Philip C. Chen,Jonathan C. Roberts, Craig M. Wittenbrink, Matti ',\n",
       " 'The perceptualization of scientific dataGeorges GrinsteinComputer Science DepartmentUniversity of LowellLowell, MA 01854grinstein@ulowell.eduStuart SmithComputer Science DepartmentUniversity of LowellLowell, MA 01854stu\\xc2\\xa9ulowell.eduABSTRACTIn this paper we discuss data exploration as a particularly difficult case within the general problem of datavisualization. We describe (1) a novel graphic technique for displaying multidimensional data visually and(2) an auditory display integrated with the visual display that allows us to represent multidimensionaldata in sound. The visual/auditory display employs an \"iconographic\" technique that seeks to exploitthe spontaneous perceptual capacity to sense and discriminate texture. Structures in data to be analyzedcan appear, both visually and aurally, as distinct textural regions and contours when the data arerepresented iconographically. Sound can be used to reinforce the visual presentation or to augment thedimensionality of the visual display. The immediate focus of the work reported here is to investigate howbest to transform data into perceptible visual and auditory textures, that is, how best to \"perceptualize\"the data. A key problem we discuss is deciding which fields of a multidimensional data set should berepresented in the visual domain and which in the auditory domain. This activity is part of the Universityof Lowell\\'s Exploratory Visualization (Exvis) project, a multidisciplinary effort to develop new paradigmsfor the exploration and analysis of data with high dimensionality.1. INTRODUCTIONThe Exploratory Visualization (Exvis) project at the University of Lowell is a multidisciplinary effort todevelop new paradigms for the exploration and analysis of data with high dimensionality. The fundamen-tal philosophy behind Exvis is that data presentation tools should be driven by the perceptual powers ofthe human and that our ability to interpret data of high dimensionality will be maximized only when welearn how to capitalize on human perceptual capabilities in multiple domains simultaneously. We havealready begun experimentation with the visual presentation of data using line texture (see [6,12]) andsimultaneous auditory presentation based on one-dimensional probing of two-dimensional visual space(see [14]).2. ICONOGRAPHIC DISPLAY OF DATAThe critical requirement of an effective data display is that it stimulate spontaneous perceptions ofstructure in data. The scatterplot, for example, is effective because it sti',\n",
       " \"UNIVERSITY  OF  COLORADO,  BOULDER Department  of Computer  Science The Enhancement of Understanding through  Visual Representations Heinz-Dieter  Boecker,  Gerhard Fischer  and  Helga  Nieper Department of Computer Science and Institute  of Cognitive  Science University  of Colorado,  Boulder 'In the  Proceedings  of the  CH1'86 Conference on  Human  Factors  in Computing  Systems April 13-11,  1986, Boston Abstract It  has  been  argued  for  a  long  time  that  the  representation  of  a  problem  is  of  crucial  impor(cid:173)tance  to  understanding  and  solving  it.  Equally  accepted  is  the  fact  that  the  human  visual system  is  a  powerful  system  to  be  used  in  information  processing  tasks.  However,  there  exist few  systems  which  try  to  take  advantage  of these  insights.  We  have  constructed  a  variety  of system  components  which  automatically  generate  graphical  representations  of  complex  struc(cid:173)tures.  We  are  pursuing  the  long-range  goal  of  constructing  a  software  oscilloscope  which makes  the  invisible  visible.  Our  tools  are  used  in  a  variety  of  contexts:  in  programming  en(cid:173)vironments,  in  intelligent  tutoring  systems,  and  in  human-computer  interaction  in  general  by offering  aesthetically  pleasing interfaces. ECOT 7-7  Engineering  Center. Campus Box 430  \\xe2\\x80\\xa2  Boulder,  Colorado  80309  \\xe2\\x80\\xa2  (303)  492-1502 \\x0c\",\n",
       " 'The Role of Hubness in ClusteringHigh-Dimensional DataNenad Toma\\xcb\\x87sev1, Milo\\xcb\\x87s Radovanovi\\xc2\\xb4c2, Dunja Mladeni\\xc2\\xb4c1, and Mirjana Ivanovi\\xc2\\xb4c21 Institute Jo\\xcb\\x87zef StefanDepartment of Knowledge TechnologiesJamova 39, 1000 Ljubljana, Slovenianenad.tomasev@ijs.si, dunja.mladenic@ijs.si2 University of Novi SadDepartment of Mathematics and InformaticsTrg D. Obradovi\\xc2\\xb4ca 4, 21000 Novi Sad, Serbiaradacha@dmi.uns.ac.rs, mira@dmi.uns.ac.rsAbstract. High-dimensional data arise naturally in many domains, and have reg-ularly presented a great challenge for traditional data-mining techniques, bothin terms of effectiveness and ef\\xef\\xac\\x81ciency. Clustering becomes dif\\xef\\xac\\x81cult due to theincreasing sparsity of such data, as well as the increasing dif\\xef\\xac\\x81culty in distin-guishing distances between data points. In this paper we take a novel perspec-tive on the problem of clustering high-dimensional data. Instead of attemptingto avoid the curse of dimensionality by observing a lower-dimensional featuresubspace, we embrace dimensionality by taking advantage of some inherentlyhigh-dimensional phenomena. More speci\\xef\\xac\\x81cally, we show that hubness, i.e., thetendency of high-dimensional data to contain points (hubs) that frequently occurin k-nearest neighbor lists of other points, can be successfully exploited in clus-tering. We validate our hypothesis by proposing several hubness-based cluster-ing algorithms and testing them on high-dimensional data. Experimental resultsdemonstrate good performance of our algorithms in multiple settings, particularlyin the presence of large quantities of noise.1 IntroductionClustering in general is an unsupervised process of grouping elements together, so thatelements assigned to the same cluster are more similar to each other than to the remain-ing data points [1]. This goal is often dif\\xef\\xac\\x81cult to achieve in practice. Over the years, var-ious clustering algorithms have been proposed, which can be roughly divided into fourgroups: partitional, hierarchical, density-based, and subspace algorithms. Algorithmsfrom the fourth group search for clusters in some lower-dimensional projection of theoriginal data, and have been generally preferred when dealing with data that is high-dimensional [2\\xe2\\x80\\x935]. The motivation for this preference lies in the observation that hav-ing more dimensions usually leads to the so-called curse of dimensionality, where theperformance of many standard machine-learning algorithms becomes impaired. This ismostly due to two pervasive effects: t',\n",
       " 'Journal of Philosophy, Inc.The Journal of Philosophy, Vol. 78, No. 2 (Feb., 1981), pp. 67-90  Eliminative Materialism and the Propositional Attitudes Author(s): Paul M. Churchland Source: Published by: Stable URL: Accessed: 11-06-2015 06:15 UTChttp://www.jstor.org/stable/2025900Journal of Philosophy, Inc.   REFERENCESLinked references are available on JSTOR for this article: http://www.jstor.org/stable/2025900?seq=1&cid=pdf-reference#references_tab_contents You may need to log in to JSTOR to access the linked references.Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at http://www.jstor.org/page/info/about/policies/terms.jsp JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.Journal of Philosophy, Inc. is collaborating with JSTOR to digitize, preserve and extend access to The Journal of Philosophy.  http://www.jstor.orgThis content downloaded from 137.110.83.143 on Thu, 11 Jun 2015 06:15:56 UTCAll use subject to JSTOR Terms and Conditions\\x0c',\n",
       " 'Data Visualizat ion Using Automat ic, Percept ually.-MotivatedShapesChristopher D. ShawDavid S. Ebert, James M. Kukia, Amen Zwa, Ian SoboroffUniversity of ReginaU. of Maryland Baltimore County tD.Aaron RobertsNASA Goddard Space Flight CenterABSTRACTThis paper describes a new technique for the multi-dimensional visualization of data through automatic procedural generationof glyph shapes based on mathematical functions. Our glyph-based Stereoscopic Field Analyzer (SFA) system allows thevisualization of both regular and irregular grids of volumetric data. SFA uses a glyph\\'s location, 3D size, color and opacityto encode up to 8 attributes of scalar data per glyph. We have extended SFA\\'s capabilities to explore shape variation asa visualization attribute. We opted for a procedural approach, which allows flexibility, data abstraction, and freedom fromspecification of detailed shapes. Superquadrics are a natural choice to satisfy our goal of automatic and comprehensiblemapping of data to shape. For our initial implementation we have chosen superellipses. We parameterize superquadrics toallow continuous control over the \"roundness\" or \"pointiness\" of the shape in the two major planes which intersect to form theshape, allowing a very simple, intuitive, abstract schema of shape specification.Keywords: Glyphs, Volume Visualization, Information Visualization, Superquadrics, Two-Handed Input1 .INTRODUCTIONThe simultaneous visualization ofmulti-dimensionaldata is a difficult task. The goal is not only the display of multi-dimensionaldata, but the comprehensible display of multi-dimensional data. Glyph, or iconic, visualization is an attempt to encode moreinformation in a comprehensible format, allowing multiple values to be encoded in the parameters of the glyphs.\\' The shape,color, transparency, orientation, etc., of the glyph can be used to visualize data values. Glyph2 is an extension tothe use of glyphs and icons in numerous fields, including cartography, logic, and pictorial information systems.In previous work, we explored the usefulness of stereo-viewing and two-handed interaction to increase the perceptual cuesin glyph-based visualization. The Stereoscopic Field Analyzer (SFA)3 allows the visualization of both regular and irregulargrids of volumetric data. SFA combines glyph-based volume rendering with a two-handed minimally-immersive interactionmetaphor to provide interactive visualization, manipulation, and exploration of multivariate, volumetric data. SFA uses',\n",
       " 'International Journal of Communication 8 (2014), 1784\\xe2\\x80\\x931794 1932\\xe2\\x80\\x938036/20140005   The Quantified Self Movement as an Alternative Big Data Practice This One Does Not Go Up to 11:   DAWN NAFUS1 JAMIE SHERMAN Intel Labs, USA    Big  data  is  often  seen  in  terms  of  powerful  institutions  managing  the  actions  of populations  through  data.  This  ethnography  of  the  Quantified  Self  movement,  where participants  collect  extensive  data  about  their  own  bodies,  identifies  practices  that  go beyond  simply  internalizing  predetermined  frameworks. The  QS  movement  attracts  the most  hungrily  panoptical  of  the  data  aggregation  businesses  in  addition  to  people  who have developed their own notions of analytics that are separate from, and in relation to, dominant  practices  of  firms  and  institutionalized  scientific  production.  Their  practices constitute an important modality of resistance to dominant modes of living with data, an approach  that  we  call  \\xe2\\x80\\x9csoft  resistance.\\xe2\\x80\\x9d  Soft  resistance  happens  when  participants assume  multiple  roles  as  project  designers,  data  collectors,  and  critical  sense-makers who rapidly  shift  priorities.  This  constant  shifting keeps  data  sets fragmented  and  thus creates material resistance to traditional modes of data aggregation. It also breaks the categories  that  make  traditional  aggregations  appear  authoritative.  This  enables participants to partially yet significantly escape the frames created by the biopolitics  of the health technology industry. Introduction In the summer of 2012, as part of our ongoing research, we attended a local Quantified Self (or QS) \\xe2\\x80\\x9cmeetup.\\xe2\\x80\\x9d Held in the offices of an Internet startup company, the evening featured speakers sharing data  visualizations  and  people  talking  about  their  experiments  with  data.  One  speaker,  Angela,  told  the story  of  how  she  had  been  working  in  a  job  she  thought  she  loved.  Around  the  same  time,  she                                                  1 The authors would like to thank Michael, the \\xe2\\x80\\x9cglucose tracker,\\xe2\\x80\\x9d and the many self-trackers who provided insight  and  comments  on  earlier  drafts.  Gina  Neff,  Brittany  Fiore-Silfvast,  Ken  Anderson,  Suzanne Thomas, and two anonymous reviewers provided generous input without which this work would have been impossible.  Dawn Nafus: dawn.nafus@intel.com Jamie Sherman: jamie.sherman@intel.com Date submitted: 2013\\xe2\\x80\\x9304\\xe2\\x80',\n",
       " 'Graphical Representation of Multivariate Data by Means of Asymmetrical Faces Author(s): Bernhard Flury and Hans Riedwyl Source: Journal of the American Statistical Association, Vol. 76, No. 376 (Dec., 1981), pp. 757-765 Taylor & Francis, Ltd.Published by: Stable URL: Accessed: 10-06-2015 11:36 UTC on behalf of the American Statistical Association http://www.jstor.org/stable/2287565 Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at http://www.jstor.org/page/info/about/policies/terms.jsp JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org.Taylor & Francis, Ltd. and American Statistical Association are collaborating with JSTOR to digitize, preserve and extend access to Journal of the American Statistical Association.  http://www.jstor.orgThis content downloaded from 132.239.1.231 on Wed, 10 Jun 2015 11:36:21 UTCAll use subject to JSTOR Terms and Conditions\\x0c',\n",
       " 'Glyph-Based Generic Network VisualizationRobert F. Erbacher Department of Computer Science, LI 67A University at Albany-SUNY 1400 Washington Avenue Albany, NY 12222, USA erbacher@cs.albany.eduAbstract Network managers and system administrators have an enormous task set before them in this day of growing networkusage. This is particularly true of e-commerce companies and others dependent on a computer network for theirlivelihood. Network managers and system administrators must monitor activity for intrusions and misuse while at thesame time monitoring performance of the network. In this paper, we describe our visualization techniques for assisting inthe monitoring of networks for both of these tasks. The goal of these visualization techniques is to integrate the visualrepresentation of both network performance/usage as well as data relevant to intrusion detection. The main difficultiesarise from the difference in the intrinsic data and layout needs of each of these tasks. Glyph based techniques areadditionally used to indicate the representative values of the necessary data parameters over time. Additionally, ourtechniques are geared towards providing an environment that can be used continuously for constant real-time monitoringof the network environment.Keywords: Information Visualization, Computer Networks, Traffic Monitoring, Intrusion Detection1.INTRODUCTIONLarge scale telecommunication infrastructures provide the foundation on which e-commerce and other computingapplications are based. However, monitoring such large scale systems to determine the effectiveness of the currentinfrastructure is a daunting task given the complexity of current infrastructures and interactions between the systems anduser based traffic. There is a need to monitor activity on many levels simultaneously; all of which are considered criticalto today\\xe2\\x80\\x99s commercial needs. The most obvious requirement is that of intrusion detection. We have been applyingvisualization techniques towards the identification of intrusions and misuse through the identification of behavioralpatterns. In this way, the system administrator can monitor activity on an entire network through a visual interface, whichis much less tedious than the typical textual based interface commonly used. All network accesses by users arerepresented visually such that the temporal and system based relationships are shown instantly with the more importantattributes highlighted to attract the attention of the system adminis',\n",
       " \"Information Visualization (2006) 5, 260 -- 270\\xc2\\xa9 2006 Palgrave Macmillan Ltd. All rights reserved 1473-8716 $30.00www.palgrave-journals.com/ivsNature-inspired visualisation of similarityand relationships in human systems andbehavioursRussell Beale1Robert J Hendley1Andy Pryke1Barry Wilkins11Advanced Interaction Group, School ofComputer Science, University of Birmingham,Edgbaston, Brimingham, U.K.Correspondence:Russell Beale, Advanced Interaction Group,School of Computer Science, Universityof Birmingham, Edgbaston,BirminghamB15 2TT, U.K.E-mail: R.Beale@cs.bham.ac.ukReceived: 19 April 2005Revised: 16 August 2006Accepted: 16 September 2006AbstractVisualisations of complex interrelationships have the potential to be complexand require a lot of cognitive input. We have drawn analogues from naturalsystems to create new visualisation approaches that are more intutive and eas-ier to work with. We use nature-inspired concepts to provide cognitive ampli-fication, moving the load from the user's cognitive to their perceptual systemsand thus allowing them to focus their cognitive resources where they are mostappropriate. Two systems are presented: one uses a physical-based model toconstruct the visualisation, while the other uses a biological inspiration. Theirapplication to four visualisation tasks is discussed: the structure of informationbrowsing on the internet; the structure of parts of the web itself; to aid the re-finement of queries to a digital library; and to compare different documentsfor similar content.Information Visualization (2006) 5, 260--270.doi:10.1057/palgrave.ivs.9500135Keywords: visualisation; cognitive amplification; physical; biological; web; digital li-brary; document analysisIntroductionIn the world today, our behaviours are usually mediated by technology:whether we are having telephone conversations, researching on theInternet, writing documents, going shopping or watching television,our actions can be recorded and analysed. These data reflect the patternsand interests of our lives, and can yield insights into our behaviour, desiresand goals, providing marketing companies with identified opportunities tosell new products into, or medical companies with information on appro-priate healthcare, or governments with information on their citizens andenemies. This sort of data forms a network: connections between one nodeand another, sometimes cyclical, sometimes purely tree-like. Similar pat-terns of activity can be observed in other scientific and\",\n",
       " '\\xc2\\xa9 1992 Nature  Publishing Group\\x0c',\n",
       " 'Article  Gaming the Quantified Self           Jennifer R. Whitson  Concordia University, Canada. j.whitson@concordia.ca  Abstract  Gamification  combines  the  playful  design  and  feedback  mechanisms  from  games  with  users\\xe2\\x80\\x99  social  profiles  (e.g.  Facebook, twitter,  and  LinkedIn)  in  non-game  applications.  Successful  gamification  practices  are  reliant  on  encouraging  playful subjectivities so that users voluntarily expose their personal information, which is then used to drive behavioural change (e.g. weight loss, workplace productivity, educational advancement, consumer loyalty, etc.). The pleasures of play, the promise of a \\xe2\\x80\\x98game\\xe2\\x80\\x99, and the desire to level up and win are used to inculcate desirable skill sets and behaviours. Gamification is rooted in surveillance; providing real-time feedback about users\\xe2\\x80\\x99 actions by amassing large quantities of data and then simplifying this data into modes that easily understandable, such as progress bars, graphs and charts.  This article provides an introduction to gamification for surveillance scholars. I first provide brief definitions of gamification, games  and  play,  linking  the  effectiveness  of  gamification  to  the  quantification  of  everyday  life.  I  then  explain  how  the quantification in gamification is different from the quantification in both analog spaces and digital non-game spaces. Next, I draw from  governmentality  studies  to  show  how  quantification  is  leveraged  in  terms  of  surveillance.  I  employ  three  examples  to demonstrate the social effects and impacts of gamified behaviour. These examples range from using self-surveillance to gamify everyday  life,  to  the  participatory  surveillance  evoked  by  social  networking  services,  to  the  hierarchical  surveillance  of  the gamified call-centre. Importantly, the call-centre example becomes a limit case, emphasizing the inability to gamify all spaces, especially those framed by work and not play. This leads to my conclusion, arguing that without knowing first what games and play are, we cannot accurately respond to and critique the playful surveillant technologies leveraged by gamification.    Introduction Every  weekday  morning,  I  sit  at  my  computer.  After  checking  my  emails,  I  head  to  a  gamification website,  750words.com,  that  promises  to  make  writing  a  daily  habit  by  rewarding  me  with  badges, positive feedback, and semantic and statistical analysis about my written t',\n",
       " 'Multimodal Presentation of Biomedical Data \\xc5\\xbdeljko Obrenovic, Du\\xc5\\xa1an Starcevic, Emil Jovanov  1. INTRODUCTION ...............................................................................................................................................2 2. DEFINING TERMS ............................................................................................................................................2 3. PRESENTATION OF BIOMEDICAL DATA..................................................................................................3 3.1. EARLY BIOMEDICAL SIGNAL DETECTION AND PRESENTATION ..................................................................3 3.2. COMPUTER-BASED SIGNAL DETECTION AND PRESENTATION ....................................................................3 3.3. TYPES OF BIOMEDICAL DATA .......................................................................................................................4 4. MULTIMODAL PRESENTATION ..................................................................................................................6 4.1. COMPUTING PRESENTATION MODALITIES ...................................................................................................6 4.1.1. Visualization..........................................................................................................................................7 4.1.2. Audio Presentation................................................................................................................................9 4.1.3. Haptic Rendering................................................................................................................................ 11 4.1.4. Olfactory Presentation....................................................................................................................... 12 4.2. MULTIMODAL INTEGRATION...................................................................................................................... 12 4.2.1. Integration Mechanisms..................................................................................................................... 12 4.2.2. Common Multimodal Combinations.................................................................................................. 13 4.3. HUMAN INFORMATION PROCESSING.......................................................................................................... 14 5. TOOLS AND PLATFORMS............................................',\n",
       " 'Multi-sensory Data Representation in Virtual Worlds: abstraction or pragmatism? Ifan D H Shepherd1, Iestyn D Bleasdale-Shepherd21. Middlesex University, London, UK 2. Valve Corporation, Seattle, USA Abstract Contemporary data visualisation and GIS software continue to make almost exclusive use of the visual sensory modality  in  representing  data  to  the  human  analyst.  The  potential  roles  of  other  sensory  modalities  in  virtual geographical  environments  (VGEs),  and  especially  those  designed  to  support  interactive  data  exploration,  are identified. A trans-sensory model of sensory variables is proposed, built on Bertin\\xe2\\x80\\x99s original graphical sign system, as a basis for the fusion of multiple sensory representations of data in multi-sensory data representation systems (MSDRSs).  This  is  followed  by  a  detailed  evaluation  of the  (largely intuitive) adoption  of  sensory  variables in contemporary videogame technology, in order to identify lessons which may be used to embed this model in future VGEs that aim to provide facilities for multi-sensory data representation. Keywords: Multi-sensory  data  representation,  multi-sensory  data  visualization,  multi-sensory  data  perceptualization,  multi-sensory geo-visualization, multi-sensory GIS, multimodal data display, multimodal interfaces. 1.  INTRODUCTION  \\xe2\\x80\\x9cIf the task of the display is to serve as the looking glass into the mathematical wonderland constructed in a computer memory, it should serve as many senses as possible.\\xe2\\x80\\x9d (Sutherland, 1965)  \\xe2\\x80\\x9cA standard GUI is a mirror that reflects back a severely misshapen human being with large hands, huge forefinger, one immense eye, and moderate sized ears. The rest of the body is simply the location of backaches, neck strain, and repetitive strain injuries.\\xe2\\x80\\x9d (Rokeby, 1998, p.38)  If  we  take  as  our  starting  point  the  human  sensory  system,  then  the  most  fundamental  feature characterising that system is the way in which the senses operate together in providing perceptual clues to the individual in pursuit of survival and fulfilment. How odd, then, that the overwhelming majority of  currently  available  exploratory  and  analytical  tools  available  for  geographical  analysis  are  uni-sensory,  addressing  primarily  the  human  visual  sense.  It  is  over  forty  years  since  Sutherland  (1965) proposed that computer graphics research look beyond \\xe2\\x80\\x9cthe picture in the window\\xe2\\x80\\x9d, and attempt to create virtual en',\n",
       " 'Why Do Biologists Use So Many Diagrams?Author(s): Benjamin Sheredos, Daniel Burnston, Adele Abrahamsen, and William BechtelSource: Philosophy of Science, Vol. 80, No. 5 (December 2013), pp. 931-944Published by: The University of Chicago Press on behalf of the Philosophy of Science AssociationStable URL: http://www.jstor.org/stable/10.1086/674047 .Accessed: 07/06/2015 20:18Your use of the JSTOR archive indicates your acceptance of the Terms & Conditions of Use, available at .http://www.jstor.org/page/info/about/policies/terms.jsp .JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range ofcontent in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new formsof scholarship. For more information about JSTOR, please contact support@jstor.org. .The University of Chicago Press and Philosophy of Science Association are collaborating with JSTOR todigitize, preserve and extend access to Philosophy of Science.http://www.jstor.org This content downloaded from 137.110.84.4 on Sun, 7 Jun 2015 20:18:11 PMAll use subject to JSTOR Terms and Conditions\\x0c',\n",
       " 'Visualization and Data Analysis 2011, edited by Pak Chung Wong, Jinah Park, Ming C. Hao, Chaomei Chen,Katy B\\xc3\\xb6rner, David L. Kao, Jonathan C. Roberts, Proc. of SPIE-IS&T Electronic Imaging, SPIE Vol. 7868, 78680X \\xc2\\xb7 \\xc2\\xa9 2011 SPIE-IS&T \\xc2\\xb7 CCC code: 0277-786X/11/$18 \\xc2\\xb7 doi: 10.1117/12.872661SPIE-IS&T/ Vol. 7868  78680X-1MultivariateDataVisualizationviaOutdoorScenesBenjaminA.HilleryandRobertP.BurtonBrighamYoungUniversity,2266TMCB,Provo,UT,USA84602ABSTRACTVisualizationofmultivariatedatapresentsachallengeduetothesheerdimensionalityanddensityofinformation.Whenpresentingthedatasymbolically,thishighinformationdimensionalityanddensitymakesitdif\\xef\\xac\\x81culttodevelopasymbol-ogycapableofdisplayingitinasinglepresentation.Oneapproachtomultivariatevisualizationinvolvescreatingsymbolswithhigherdimensionality.Higherdimensionalsymbolscanbeproblematic,sincetheytypicallyrequiresigni\\xef\\xac\\x81canthumanattentiveprocessingtointerpret,offsettingtheirgreaterinformationalcapacity.Althoughattemptshavebeenmadetode-velophigher-dimensionalsymbolsthatareprocessedinapreattentivefashion,successhasprovenelusive.Recentcognitiveresearchindicatesthatoutdoorscenesareprocessedinapreattentivemanner.Weevaluateoutdoorscenesasacandidatefordevelopinganeffectivehigher-dimensionalsymbologybygeneratingproof-of-conceptimagesandcomparingthemtorelatedmethods.1.INTRODUCTIONInformation,asstoredinitsnativeformatinsideacomputerisrarelycomprehensible.Commondigitalstorageformatsincludechargestoredatthegatesoftransistors,magneticdomainsonspinningplatters,andpitsandgroovesonthesurfaceofre\\xef\\xac\\x82ectiveplasticdisks.Humansarenotknowntobecapabledetectorsofelectricormagnetic\\xef\\xac\\x81eldsandtheopticalformatsdefythesensesasaconsequenceoftheirmicroscopicscale.Eveniftheinformationwasstoredinaformatthatcouldbeperceivedbycommonsenses,thesheervolumeofdatasurelywouldoverwhelmourabilitiestocomprehenditall.Howevertheinformationisstored,itisalmostalwaysreadablebymachinesonly.Astheultimateconsumersofinformationaredecidedlynotmechanical,ithasbeenachallengetothecomputerscientistsincethedawnofthecomputingagetopresentinformationcontainedinthemachineinaconsumableform.Ifthesynergisticvalueoftheman-computerrelationshipistobeexploited,itisessentialtodisplaydatainahigherlevelformatforhumanconsumptionandcomprehension.Multivariatedatapresentsasigni\\xef\\xac\\x81cantchallengeinthisregard,inpartduetothelimitsofhumanperception.Ignoringcolorconsiderations,animagefallingonahumanretinacanbethoughtofasatrivariaterelationship,withtwoindependentvariables(heightandwidth)andonedepende',\n",
       " 'Visualization and Data Analysis 2014, edited by Pak Chung Wong, David L. Kao, Ming C. Hao, Chaomei Chen, Proc. of SPIE-IS&T Electronic Imaging, SPIE Vol. 9017, 90170I \\xc2\\xa9 2014 SPIE-IS&T CCC code: 0277-786X/14/$18 \\xc2\\xb7 doi: 10.1117/12.2042427SPIE-IS&T/ Vol. 9017  90170I-1   Visualization of multidimensional data with collocated paired coordinates and general line coordinates Boris Kovalerchuk*  Dept. of Computer Science, Central Washington University,  400 E. University Way, Ellensburg, WA, 98926-7520, USA ABSTRACT  Often multidimensional data are visualized by splitting n-D data to a set of low dimensional data. While it is useful it destroys integrity of n-D data, and leads to a shallow understanding complex n-D data. To mitigate this challenge a difficult perceptual task of assembling low-dimensional visualized pieces to the whole n-D vectors must be solved.  Another way is a lossy dimension reduction by mapping n-D vectors to 2-D vectors (e.g., Principal Component Analysis). Such 2-D vectors carry only a part of information from n-D vectors, without a way to restore n-D vectors exactly from it. An alternative way for deeper understanding of n-D data is visual representations in 2-D that fully preserve n-D data. Methods of Parallel and Radial coordinates are such methods. Developing new methods that preserve dimensions is a long standing and challenging task that we address by proposing Paired Coordinates that is a new type of n-D data visual representation and by generalizing Parallel and Radial coordinates as a General Line coordinates. The important novelty of the concept of the Paired Coordinates is that it uses a single 2-D plot to represent n-D data as an oriented graph based on the idea of collocation of pairs of attributes. The advantage of the General Line Coordinates and Paired Coordinates is in providing a common framework that includes Parallel and Radial coordinates and generating a large number of new visual representations of multidimensional data without lossy dimension reduction.   Keywords:  Visualization, multidimensional data, dimension preserving, oriented graph, paired coordinates, collocated coordinates, parallel coordinates, radial coordinates.    1. INTRODUCTION The Big Data studies revealed that now every few days more data are created than for all previous centuries. This leads to tremendous challenges to process and manage these data.  Visual analytics is a promising approach to deal with this challenge.  Information management a',\n",
       " 'Keynote  AddressLeveraging  Human  Capabilities  in  Information  PerceptualizationGeorge  RobertsonMicrosoft  ResearchThe term \\xe2\\x80\\x9cinformation visualization\\xe2\\x80\\x9d was coined in 1989, inspired by the idea of applying scientific visualizationtechniques  to  abstract  information  spaces.  The  fundamental  insight  was  that  humans  are  very  good  at  recognizingpatterns,  and  this  can  help  us  make  sense  out  of  complex  information. Much  of  the  research  in  informationvisualization during the last ten years has leveraged human visual perception. But if we take a broader look at naturalhuman  capabilities,  there  are  other  cognitive  and  perceptual  capabilities  that  we  are  not  leveraging  as  well.  Forexample,  when  we  perceive  patterns  in  the  real  world,  we  use  our  other  senses,  particularly  hearing  and  haptics,  inaddition  to  vision.  Perhaps  we  should  rename  this  field  \\xe2\\x80\\x9cinformation perceptualization,\\xe2\\x80\\x9d  and  focus  on  using  multiplechannels of human information processing to facilitate pattern recognition.BiographyGeorge  Robertson  is  a  senior  researcher  and  manager  of  the  User  Interface  Research  group  at  MicrosoftResearch.  Before  coming  to  Microsoft,  he  was  a  principal  scientist  at  Xerox  PARC,  working  primarily  on  3Dinteractive  animation  interfaces  for  intelligent  information  access  applications.  He  was  the  architect  of  theInformation  Visualizer.  He  has  also  been  a  senior  scientist  at  Thinking  Machines,  a  senior  scientist  at  Bolt  Beranekand Newman, and a faculty member of the Computer Science Department at Carnegie Mellon University. In the past,he  has  made  significant  contributions  to  machine  learning,  multimedia  message  systems,  hypertext  systems,operating systems, and programming languages.xi\\x0c',\n",
       " 'Int. J. Human-Computer Studies (2002) 57, 247\\xe2\\x80\\x93262doi:10.1006/ijhc.1017Available online at http://www.idealibrary.com.onAnimation: can it facilitate?Barbara Tversky and Julie Bauer MorrisonyDepartment of Psychology, Jordan Hall; Bldg. #420 Stanford, CA 94305-2130 USA.email: bt{julie}@psych.stanford.edu.Mireille BetrancourtI.N.R.I.A. Rhone-Alpes, 655, Av. de l\\xe2\\x80\\x99Europe, 38330 Montbonnot St-Martin, France.email: mireille.betrancourt@inria.fr.(Received 1 March 2001 and accepted in revised form 4 April 2002)Graphics have been used since ancient times to portray things that are inherentlyspatiovisual, like maps and building plans. More recently, graphics have been used toportray things that are metaphorically spatiovisual, like graphs and organizationalcharts. The assumption is that graphics can facilitate comprehension, learning, memory,communication and inference. Assumptions aside, research on static graphics hasshown that only carefully designed and appropriate graphics prove to be bene\\xef\\xac\\x81cial forconveying complex systems. Effective graphics conform to the Congruence Principleaccording to which the content and format of the graphic should correspond to thecontent and format of the concepts to be conveyed. From this, it follows that animatedgraphics should be effective in portraying change over time. Yet the research on theef\\xef\\xac\\x81cacy of animated over static graphics is not encouraging. In cases where animatedgraphics seem superior to static ones, scrutiny reveals lack of equivalence betweenanimated and static graphics in content or procedures; the animated graphics conveymore information or involve interactivity. Animations of events may be ineffectivebecause animations violate the second principle of good graphics, the ApprehensionPrinciple, according to which graphics should be accurately perceived and appropriatelyconceived. Animations are often too complex or too fast to be accurately perceived.Moreover, many continuous events are conceived of as sequences of discrete steps.Judicious use of interactivity may overcome both these disadvantages. Animations maybe more effective than comparable static graphics in situations other than conveyingcomplex systems, for example, for real time reorientations in time and space.# 2002 Published by Elsevier Science Ltd.1. Graphics: The Congruence Principle1.1. SOME FUNCTIONS OF GRAPHICSThe enthusiasm for graphics of all kinds rests on the belief that they bene\\xef\\xac\\x81tcomprehension and learning, and foster insight (their pr',\n",
       " 'Data Soni\\xef\\xac\\x81cation for Users with VisualImpairment: A Case Study withGeoreferenced DataHAIXIA ZHAO, CATHERINE PLAISANT, and BEN SHNEIDERMANUniversity of MarylandandJONATHAN LAZARTowson University4We describe the development and evaluation of a tool, iSonic, to assist users with visual impair-ment in exploring georeferenced data using coordinated maps and tables, augmented with nontex-tual sounds and speech output. Our in-depth case studies with 7 blind users during 42 hours ofdata collection, showed that iSonic enabled them to \\xef\\xac\\x81nd facts and discover trends in georeferenceddata, even in unfamiliar geographical contexts, without special devices. Our design was guidedby an Action-by-Design-Component (ADC) framework, which was also applied to scatterplots todemonstrate its generalizability. Video and download is available at www.cs.umd.edu/hcil/iSonic/.Categories and Subject Descriptors: H.5.2 [Information Interfaces and Presentation]: UserInterfaces\\xe2\\x80\\x94Auditory (non-speech) feedback, Evaluation/methodology, User\\xe2\\x80\\x93centered designGeneral Terms: Human FactorsAdditional Key Words and Phrases: Interactive soni\\xef\\xac\\x81cation, auditory user interfaces, informationseeking, users with visual impairment, universal usabilityACM Reference Format:Zhao, H., Plaisant, C., Shneiderman, B., and Lazar, J. 2008. Data soni\\xef\\xac\\x81cation for users withvisual impairment: A case study with georeferenced data. ACM Trans. Comput.-Hum. Interact.15, 1, Article 4 (May 2008), 28 pages. DOI = 10.1145/1352782.1352786. http://doi.acm.org/10.1145/1352782.1352786.This work is supported by the National Science Foundation under Grant No. EIA 0129978 andITR/AITS 0205271.Authors\\xe2\\x80\\x99 addresses: H. Zhao, Google, Inc., 1600 Ampitheatre Parkway, Mountain View, CA 94043;email: haixia@google.com; C. Plaisant, B. Shneiderman, Department of Computer Science, Uni-versity of Maryland, College Park, Maryland 20740; J. Lazar, Department of Computer and Infor-mation Sciences, Towson University, Towson, Maryland 21252.Permission to make digital or hard copies of part or all of this work for personal or classroom useis granted without fee provided that copies are not made or distributed for pro\\xef\\xac\\x81t or commercialadvantage and that copies show this notice on the \\xef\\xac\\x81rst page or initial screen of display alongwith the full citation. Copyrights for components of this work owned by others than ACM mustbe honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post onservers, to redistribute to lists',\n",
       " 'Two gesture recognition systems for immersive math education of the DeafNicoletta Adamo-Villani Purdue University Department of Computer Graphics Technology                                     West Lafayette, IN, USA 001.765.496.1297 nadamovi@purdue.eduJustin Heisler Vicarious Visions 185 Van Renssalaer Blvd #13-1a Menands, New York 12204 001.765.418.1609 heisler.justin@gmail.comLaura Arns Purdue University Envision Center for Data Perceptualization West Lafayette, IN, USA 001.765.496.7888 larns@purdue.edu   for navigation, interface interaction, ABSTRACT The general goal of our research is the creation of a natural and intuitive and input/recognition  of  American  Sign  Language  (ASL)  math  signs in  immersive  Virtual  Environments  (VE)  for  the  Deaf.  The speci\\xef\\xac\\x81c  objective  of  this  work  is  the  development  of  two  new gesture recognition systems for SMILE\\xe2\\x84\\xa2, an immersive learning game  that  employs  a  fantasy  3D  virtual  environment  to  engage deaf children in math-based educational tasks. Presently, SMILE includes standard VR interaction devices such as a 6DOF wand, a pair of pinch gloves, and a dance platform. In this paper we show a  signi\\xef\\xac\\x81cant  improvement  of  the  application  by  proposing  two new gesture control mechanisms: system (1) is based entirely on hand  gestures  and  makes  use  of  a  pair  of  18-sensor data gloves, system (2) is based on hand and body gestures and makes use of a pair of data gloves and a motion tracking system. Both interfaces support first-person  motion  control,  object  selection  and manipulation,  and  real-time  input/  recognition  of  ASL  numbers zero to twenty. Although the systems described in the paper rely on  high-end,  expensive  hardware,  they  can  be  considered  a  first step  toward  the  realization  of  an  effective  immersive  sign language interface. Categories and Subject Descriptors K.  Computing  Milieux  -  K.3  [Computers  and  Education]: K.3.1  Computer  Uses  in  Education  -  Collaborative  learning, (CAI),  Computer-managed Computer-assisted instruction (CMI). instruction General Terms Design, Human Factors. Keywords Sign  language  recognition,  HCI,  Virtual  Environments,  Deaf education 1.  INTRODUCTION Deaf  education,  and  speci\\xef\\xac\\x81cally  math/science  education,  is  a pressing national problem [1, 2]. To address the need to increase the  abilities  of  young  deaf  children  in  math,  we  have  recently created an immersive application (SMILE\\xe2\\x84\\xa2) f',\n",
       " 'Bespoke physics for living technology\\xe2\\x88\\x97David H. AckleyDepartment of Computer ScienceThe University of New MexicoAlbuquerque, NM 87131AbstractIn the physics of the natural world, basic tasks of life, such as homeostasis and re-production, are extremely complex operations, requiring the coordination of billionsof atoms even in simple cases. By contrast, arti\\xef\\xac\\x81cial living organisms can be imple-mented in computers using relatively few bits, and copying a data structure is trivial.Of course, the physical overheads of the computers themselves are huge, but since theirprogrammability allows digital \\xe2\\x80\\x9claws of physics\\xe2\\x80\\x9d to be tailored like a custom suit, de-ploying living technology atop an engineered computational substrate might be as ormore e\\xef\\xac\\x80ective than building directly on the natural laws of physics, for a substantialrange of desirable purposes. This paper suggests basic criteria and metrics for \\xe2\\x80\\x9cbespokephysics\\xe2\\x80\\x9d computing architectures, describes one such architecture, and o\\xef\\xac\\x80ers data andillustrations of custom living technology competing to reproduce while collaboratingon an externally useful computation.1 Living technology and big computingIn some ways, indeed, life is hard. Certainly, in the natural world, making a self-sustainingand reproducing creature is a messy and complex a\\xef\\xac\\x80air. Even the tiny Pelagibacter ubiquebacterium [30], for example, known as one the smallest of free-living creatures, involveshundreds of millions of atoms, and its reproduction involves intricate choreography, for overa day, of that many more. Natural life is an amazing, obstinate process, but\\xe2\\x80\\x94at least fromthe viewpoint of an atom, say\\xe2\\x80\\x94it isn\\xe2\\x80\\x99t easy.In exploring life as it could be, arti\\xef\\xac\\x81cial life researchers deploy technologies\\xe2\\x80\\x94from robotichardware, to pure software, to biochemical preparations\\xe2\\x80\\x94that implement the organisms andoperations of life in many ways, sometimes quite di\\xef\\xac\\x80erently from traditional life as we knowit. The primary purpose of such research has often been scienti\\xef\\xac\\x81c, but\\xe2\\x80\\x94as introduced anddiscussed in [5]\\xe2\\x80\\x94there is also growing interest in living technology: engineered systems thatmake essential use of life-like components or principles. A recent focus (see, e.g., manyof the papers in [31]) is \\xe2\\x80\\x9cwet\\xe2\\x80\\x9d living technology, which uses atoms and small moleculesas basic units and builds from there towards basic living mechanisms like metabolism and\\xe2\\x88\\x97This is an uncorrected author preprint of a paper accepted for publication in Arti\\xef\\xac\\x81ci',\n",
       " 'REPORT DOCUMEr^TATlON PAGE Fotm Approved 0MB No. 074-0188 p. Mir r.\\xc2\\xbbv,rtino h, irHgn fnr ihis collectjon Of Infoftnation is esamaled to average 1 hour per response, including the time for reviewing Instructions, searehlnfl existing da^ sources, gathering and rraintaining PubHc reporting burdenfwm^cc*e\\xc2\\xabonw^^^^ a|     corn^nts>eflarding this burden estimate or any other aspect of this collection of infomiation, including suggestions for the data needed, and \\xc2\\xab\\xc2\\xbbJ3J^5|;^\\xe2\\x80\\x9e;-^;j;\\xc2\\xab *\\'^^^ 1215 Jefferson DaJ^s Highway, Suite 1204, Arlington, VA 22202^302, and to the Office of Management and Budget,Tape\\'nwri( Reduction Project (0704-0188), Washington, DC 20SO3 2. REPORT DATE 1. AGENCY USE ONLY *\" April  2004 (Leave blank) 3. REPORT TYPE AND DATES COVERED Final Proceedings (22 Mar 2004 - 25 Mar 2004) 4. TITLE AND SUBTITLE HPSAA II (Human Performance, Situation Awareness Automation) Technology Conference iAA. 6. AUTHOR(S) Dennis A,  Vincenzi,   Ph.D. 7. PERFORMING ORGANIZATION NAME(S) AND ADDRESS(ES) Erabry-Riddle Aeronautical  University Daytona  Beach,   Florida    32114 E-Mail: 9. SPONSORING / MONITORING AGENCY NAME(S) AND ADDRESS(ES) U.S.   Army  Medical Research and Materiel Command Fort Detrick,   Maryland    21702-5012 11. SUPPLEMENTARY NOTES Report published as Volume  I and Volume 2 and S. FUNDING NUMBERS W81XWH-04-C-0080 8. PERFORMING ORGANIZATION REPORT NUMBER 10. SPONSORING / MONITORING AGENCY REPORT NUMBER 12a. DISTRIBUTION / AVAILABILITY STATEMENT Approved  for Public Release;  Distribution Unlimited 12b. DISTRIBUTION CODE 13. ABSTRACT (Maximum 200 Words) None provided 14. SUBJECT TERMS None provided 17. SECURITY CLASSIFICATION OF REPORT Unclassified NSN 7540-01-280-5500 18. SECURITY CLASSIFICATION OF THIS PAGE Unclassified BEST AVAILABLE COPY 20040909 m 15. NUMBER OF PAGES 637 16. PRICE CODE 19. SECURITY CLASSIFICATION 20. LIMITATION OF ABSTRACT OF ABSTRACT Unclassified Unlimited standard Form 298 (Rev. 2-89) PfMcribed by ANSI Std. Z39-18 298-102 \\x0c',\n",
       " 'Quality-Based Visualization MatricesGeorgia Albuquerque1, Martin Eisemann1, Dirk J. Lehmann2, Holger Theisel2 and Marcus Magnor11Computer Graphics Lab, TU Braunschweig, Germany2Visual Computing, University of Magdeburg, GermanyEmail: 1{georgia, eisemann, magnor}@cg.tu-bs.de, 2{dirk, theisel}@tu-bs.deAbstractParallel coordinates and scatterplot matrices arewidely used to visualize multi-dimensional datasets. But these visualization techniques are in-suf\\xef\\xac\\x81cient when the number of dimensions grows.To solve this problem, different approaches to pre-select the best views or dimensions have been pro-posed in the last years. However, there are still sev-eral shortcomings to these methods. In this paperwe present three new methods to explore multivari-ate data sets: a parallel coordinates matrix, in anal-ogy to the well-known scatterplot matrix, a class-based scatterplot matrix that aims at \\xef\\xac\\x81nding goodprojections for each class pair, and an importanceaware algorithm to sort the dimensions of scatter-plot and parallel coordinates matrices.1IntroductionWith the exponentially increasing amount of ac-quired multivariate data, several multi-dimensionalvisualization techniques have been proposed dur-ing the last decades [10]. Based on the factthat human perception cannot deal well with morethan three continuous dimensions simultaneously,such techniques usually project the data in low-dimensional embeddings and combine these repre-sentations in a single plot or present them to theuser in an interactive way. Some well-known exam-ples of multi-dimensional visualization techniquesare glyph techniques [17], parallel coordinates [9],scatterplot matrices [7] and pixel level visualiza-tions [11]. But even these techniques do not scalewell to high-dimensional data sets. In this work wefocus on parallel coordinates plots (PCP) and scat-terplot matrices (SPLOM), and propose extensionsto these well-known visualization techniques.Scatterplots are one of the oldest and widely usedvisualization methods.We can de\\xef\\xac\\x81ne them as graphswhere the values of two variables for a sample in adata set are used to plot a point in 2-dimensionalspace, resulting in a scattering of points. Scatter-plots are very useful for visually determining thecorrelation between two variables. A SPLOM isa symmetric matrix of adjacent scatterplots and al-lows the user to analyze the diverse dimensions atonce. If there are n variables, the SPLOM has di-mension n \\xc3\\x97 n and the element at the i-th row andj-th column',\n",
       " 'Perception-based Visual Quality MeasuresGeorgia Albuquerque\\xe2\\x88\\x97TU BraunschweigGermanyMartin Eisemann\\xe2\\x80\\xa0TU BraunschweigGermanyMarcus Magnor\\xe2\\x80\\xa1TU BraunschweigGermanyABSTRACTIn recent years diverse quality measures to support the explorationof high-dimensional data sets have been proposed. Such measurescan be very useful to rank and select information-bearing projec-tions of very high dimensional data, when the visual explorationof all possible projections becomes unfeasible. But even though aranking of the low dimensional projections may support the user inthe visual exploration task, different measures deliver different dis-tances between the views that do not necessarily match the expec-tations of human perception. As an alternative solution, we proposea perception-based approach that, similar to the existing measures,can be used to select information bearing projections of the data.Speci\\xef\\xac\\x81cally, we construct a perceptual embedding for the differ-ent projections based on the data from a psychophysics study andmulti-dimensional scaling. This embedding together with a rankingfunction is then used to estimate the value of the projections for aspeci\\xef\\xac\\x81c user task in a perceptual sense.Index Terms: H.3.3 [Information Storage and Retrieval]: Infor-mation Search and Retrieval\\xe2\\x80\\x94; Clustering; I.3.3 [Computer Graph-ics]: Picture/Image Generation;1 INTRODUCTIONInnovative approaches in visual analytics for high-dimensional datasets have presented quality measures that can be used to automati-cally select promising projections of the data [13, 14]. The visualanalysis of such data sets usually requires projecting the data intolower-dimensional representations. However, with the increasingamount of dimensions in scienti\\xef\\xac\\x81c data sets the exhaustive analysisof all possible projections requires prohibitive time. So-called qual-ity measures have been used in a pre-processing phase to the visualexploration. They can be effectively used to rank the possible pro-jections of the data according to one or more user tasks and reducethe number of views to be examined by sorting them or selectingthe best ones.Usually de\\xef\\xac\\x81ned with respect to an exploration task, the qualitymeasures can be de\\xef\\xac\\x81ned as ranking functions for the projections.However, an open issue of these methods is that the range and dis-tribution of ranking values depends on the algorithm of each indi-vidual measure and it is not possible to directly compare the resultsof the different measures. Speci\\xef\\xac\\x81cally, the p',\n",
       " '479363 ABSXXX10.1177/0002764213479363American Behavioral ScientistVerbert et al.research-article2013Learning Analytics  Dashboard ApplicationsAmerican Behavioral ScientistXX(X) 1 \\xe2\\x80\\x9310\\xc2\\xa9 2013 SAGE PublicationsReprints and permissions:sagepub.com/journalsPermissions.nav DOI: 10.1177/0002764213479363abs.sagepub.comKatrien Verbert1,2, Erik Duval1, Joris Klerkx1,  Sten Govaerts1,3, and Jos\\xc3\\xa9 Luis Santos1AbstractThis article introduces learning analytics dashboards that visualize learning traces for learners  and  teachers.  We  present  a  conceptual  framework  that  helps  to  analyze learning analytics applications for these kinds of users. We then present our own work in this area and compare with 15 related dashboard applications for learning. Most evaluations evaluate only part of our conceptual framework and do not assess whether dashboards contribute to behavior change or new understanding, probably also because such assessment requires longitudinal studies.Keywordslearning analytics, information visualization, learning dashboardsIncreasing motivation, autonomy, effectiveness, and efficiency of learners and teachers is an  important  driver  for  learning  analytics  research  (Buckingham  Shum,  Ga\\xc5\\xa1evi\\xc4\\x87,  & Ferguson, 2012). In our work, we focus on the microlevel of individual learners and teach-ers as well as on learning communities that form around courses, mostly in an open learn-ing context (Govaerts et al., 2011). We do not consider the mesolevel of the organization (school, university, training department) or the macrolevel of society at large.More  specifically,  we  deploy  information  visualization  techniques  in  dashboard applications  for  learners,  on  both  mobile  devices  and  desktop  as  well  as  tabletop devices.  Adopting  a  \\xe2\\x80\\x9cmodest  computing\\xe2\\x80\\x9d  approach  that  tries  to  empower  people, rather than automating decisions on their behalf (Dillenbourg et al., 2011), we focus on approaches that rely on visualization of these traces to assist users.1Department of Computer Science, KU Leuven, Leuven, Belgium2Department of Computer Science, Eindhoven University of Technology, Eindhoven, the Netherlands3Department of Computer Science, EPFL, Lausanne, SwitzerlandCorresponding author:Erik Duval, Departement Computerwetenschappen, KU Leuven, Celestijnenlaan 200A, B-3001 Leuven, Belgium. Email: erik.duval@cs.kuleuven.beDownloaded from abs.sagepub.com at UNIV CALIFORNIA SAN DIEGO on June 8, 2015Article\\x0c',\n",
       " 'A CASE HISTORY IN SCIENTIFIC METHOD1B. F. SKINNERHarvard UniversityIT has been said that college teaching is the onlyprofession for which there is no professionaltraining, and it is commonly argued that this isbecause our graduate schools train scholars andscientists rather than teachers. We are more con-cerned with the discovery of knowledge than withits dissemination. But can we justify ourselvesquite so easily? It is a bold thing to say that weknow how to train a man to be a scientist. Scien-tific thinking is the most complex and probably themost subtle of all human activities. Do we actuallyknow how to shape up such behavior, or do wesimply mean that some of the people who attendour graduate schools eventually become scientists?Except for a laboratory course which acquaintsthe student with standard apparatus and stand-ard procedures, the only explicit training in scien-tific method generally received by a young psy-chologist is a course in statistics\\xe2\\x80\\x94not the intro-ductory course, which is often required of so manykinds of students that it is scarcely scientific atall, but an advanced course which includes \"modelbuilding,\" \"theory construction,\" and \"experimen-tal design.\" But it is a mistake to identifyscientific practice with the formalized construc-tions of statistics and scientific method. Thesedisciplines have their place, but it does not coin-cide with the place of scientific research. Theyoffer a method of science but not, as is so oftenimplied, the method. As formal disciplines theyarose very late in the history of science, and moslof the facts of science have been discovered withouttheir aid. It takes a great deal of skill to fit Fara-day with his wires and magnets into the picturewhich statistics gives us of scientific thinking. Andmost current scientific practice would be equallyrefractory, especially in the important initial stages.It is no wonder that the laboratory scientist ispuzzled and often dismayed when he discovers howhis behavior has been reconstructed in the formalanalyses of scientific method. He is likely to pro-1 Address of the President at the Eastern PsychologicalAssociation meetings in Philadelphia, April 1955.test that this is not at all a fair representation ofwhat he does.But his protest is not likely to be heard. Forthe prestige of statistics and scientific methodologyis enormous. Much of it is borrowed from the highrepute of mathematics and logic, but much of itderives from the flourishing state of the art itself.Some ',\n",
       " 'Visual Data Mining with Pixel-oriented Visualization TechniquesMihael AnkerstThe Boeing CompanyP.O. Box 3707 MC 7L-70, Seattle, WA 98124mihael.ankerst@boeing.comAbstractPixel-oriented visualization techniques map each attribute value ofthe data to a single colored pixel, yielding the display of the mostpossible  information  at  a  time.  Thus  pixel-oriented  techniquesmaintain  the  global  view  of  large  amounts  of  data  while  stillpreserving the perception of small regions of interest. This propertymakes them suitable for a variety of data mining tasks. First we present pixel-oriented visualization techniques which canbe used as stand-alone exploration tools. Then we show how theycan  be  tightly  integrated  into  data  mining  methods  unifying  thestrength of existing algorithms and human involvement. Finally, wepoint out the idea of similarity clustering of attributes to enhancemultidimensional visualization techniques. Keywords:  Visual  data  mining,  pixel-oriented  visualizationtechniques,  cluster  analysis,  classification, integratedvisualization.tightly 1   VISUAL DATA MINING AND PIXEL-ORIENTED VISUALIZATION TECHNIQUESthe tasks from resulting  knowledge  satisfies The task of the knowledge discovery and data mining process [7] isto extract knowledge from data such that the resulting knowledge isuseful  in  a  given  application.  Obviously,  only  the  user  candetermine  whether thisrequirement.  Moreover,  what  one  user  may  find  useful  is  notnecessarily  useful  to  another  user.  Visual  data  mining  tackles  thedata  mining this  perspective  enabling  humaninvolvement and incorporating the perceptivity of humans. Datasetsto  be  mined  entail  several  requirements  limiting  or  disqualifyingmost  of  the existing  techniques  known from  the  area informationvisualization. include  handling  high-dimensional data, handling large datasets, intuitive selection of a setof attributes or a set of objects.Pixel-oriented  techniques  have  been  pioneered  by  Keim  for  theVisDB  system,  e.g.  [9],  representing  large  amounts  of  high-dimensional data with respect to a given query. As a result the userof  the  system  is able  to  refine  his  query based on  the knowledgegathered from the visual representation of the data. The basic ideaof pixel-oriented techniques is to represent each attribute value as asingle colored pixel, mapping the range of possible attribute valuesto a fixed color map and displaying different att',\n",
       " 'Atten Percept Psychophys (2011) 73:971\\xe2\\x80\\x93995DOI 10.3758/s13414-010-0073-7Crossmodal correspondences: A tutorial reviewCharles SpencePublished online: 19 January 2011# Psychonomic Society, Inc. 2011though, does the brain \\xe2\\x80\\x9cknow\\xe2\\x80\\x9d which stimuliAbstract In many everyday situations, our senses arebombarded by many different unisensory signals at anygiven time. To gain the most veridical, and least variable,estimate of environmental stimuli/properties, we need tocombine the individual noisy unisensory perceptual esti-mates that refer to the same object, while keeping thoseestimates belonging to different objects or events separate.How,tocombine? Traditionally, researchers interested in the cross-modal binding problem have focused on the roles thatspatial and temporal factors play in modulating multisen-sory integration. However, crossmodal correspondencesbetween various unisensory features (such as betweenauditory pitch and visual size) may provide yet anotherimportant means of constraining the crossmodal bindingproblem. A large body of research now shows that peopleexhibit consistent crossmodal correspondences betweenmany stimulus features in different sensory modalities.For example, people consistently match high-pitchedsounds with small, bright objects that are located high upin space. The literature reviewed here supports the view thatcrossmodal correspondences need to be considered along-side semantic and spatiotemporal congruency, among thekey constraints that help our brains solve the crossmodalbinding problem.Keywords Multisensory integration . Crossmodalcorrespondence . Synaesthesia . Bayesian integrationtheory . Crossmodal binding problemC. Spence (*)Crossmodal Research Laboratory,Department of Experimental Psychology, University of Oxford,South Parks Road,Oxford OX1 3UD, UKe-mail: charles.spence@psy.ox.ac.uk\\xe2\\x80\\x9cWhat is essential in the sensuous-perceptible is not thatwhich separates the senses from one another, but that whichunites them; unites them among themselves; unites themwith the entire (even with the non-sensuous) experience inourselves; and with all the external world that there is to beexperienced.\\xe2\\x80\\x9d (Von Hornbostel, The Unity of the Senses,1927/1950, p. 214)For many years now,the majority of cognitiveneuroscience research on the topic of multisensoryperception has tended to focus on trying to understand,and increasingly to model (Alais & Burr, 2004; Ernst &B\\xc3\\xbclthoff, 2004; Roach, Heron, & McGraw, 2006),thespatial and temporalfactors modu',\n",
       " ' Institute of Software Technology  & Interactive Systems (ISIS) Favoritenstrasse 9-11/188, A-1040 Vienna, Austria T: +43 (1) 58801-18801, F: +43 (1) 58801-18899 http://www.isis.tuwien.ac.at        Technical Report User-Centered Development of Information Visualization Methods   Asgaard-TR-2004-3         Margit Pohl, Silvia Miksch, and Monika Lanzenberger Vienna University of Technology Favoritenstrasse 9-11/187+188, A-1040  Vienna martig@igw.tuwien.ac.at, {silvia, lanzenberger}@ifs.tuwien.ac.at         Vienna Sept. 2004 \\x0c',\n",
       " 'REVIEWBIG DATAAND DISEASEPREVENTION:From Quanti\\xef\\xac\\x81ed Self to Quanti\\xef\\xac\\x81edCommunitiesMeredith A. Barrett,1,2* Olivier Humblet,1,2*Robert A. Hiatt,3 and Nancy E. Adler1AbstractBig data is often discussed in the context of improving medical care, but it also has a less appreciated but equallyimportant role to play in preventing disease. Big data can facilitate action on the modi\\xef\\xac\\x81able risk factors thatcontribute to a large fraction of the chronic disease burden, such as physical activity, diet, tobacco use, andexposure to pollution. It can do so by facilitating the discovery of risk factors for disease at population, subpop-ulation, and individual levels, and by improving the effectiveness of interventions to help people achieve healthierbehaviors in healthier environments. In this article, we describe new sources of big data in population health,explore their applications, and present two case studies illustrating how big data can be leveraged for prevention.We also discuss the many implementation obstacles that must be overcome before this vision can become a reality.IntroductionThe United States faces major health challenges.Despite spending more on healthcare per person than doesany other nation, the United States scores poorly on keyhealth indicators.1 Up to half of all deaths can be attributed tobehavioral factors such as tobacco, diet, physical activity, al-cohol and drug use, as well as the physical and social envi-ronment.2,3 Preventable chronic diseases are now the mostcommon causes of premature death. Currently, 10% ofAmericans rate their health as fair or poor, and 36% of adultsare considered obese.4 Over the next 20 years, Americans areprojected to suffer from as many as 8.5 million new cases ofdiabetes, 7.3 million cases of heart disease and stroke, andover 660,000 cases of cancer, potentially costing up to $66billion per year.5 New approaches to research and interven-tions aimed at the preventable causes of these diseases will beneeded to reduce the disease burden and the resulting cost.6Discussions of how the accumulation of new digital infor-mation\\xe2\\x80\\x94commonly referred to as big data\\xe2\\x80\\x94will affecthealth have primarily revolved around the potential impacton healthcare,7,8 and on discoveries at the molecular levelfor the treatment of disease.9 Less attention has been paid tohow big data could contribute to more effective diseaseprevention, speci\\xef\\xac\\x81cally by facilitating action on the pre-ventable risk factors that contribute to a large fraction o',\n",
       " 'EUROGRAPHICS 2013/ M. Sbert, L. Szirmay-KalosSTAR \\xe2\\x80\\x93 State of The Art ReportGlyph-based Visualization: Foundations, Design Guidelines,Techniques and ApplicationsR. Borgo1, J. Kehrer2, D. H. S. Chung1, E. Maguire3, R. S. Laramee1, H. Hauser4, M. Ward5 and M. Chen31 Swansea University, UK; 2 University of Bergen and Vienna University of Technology, Austria; 3 University of Oxford, UK;4 University of Bergen, Norway; 5 Worcester Polytechnic Institute, USAAbstractThis state of the art report focuses on glyph-based visualization, a common form of visual design where a data setis depicted by a collection of visual objects referred to as glyphs. Its major strength is that patterns of multivariatedata involving more than two attribute dimensions can often be more readily perceived in the context of a spatialrelationship, whereas many techniques for spatial data such as direct volume rendering \\xef\\xac\\x81nd dif\\xef\\xac\\x81cult to depictwith multivariate or multi-\\xef\\xac\\x81eld data, and many techniques for non-spatial data such as parallel coordinates areless able to convey spatial relationships encoded in the data. This report \\xef\\xac\\x81lls several major gaps in the literature,drawing the link between the fundamental concepts in semiotics and the broad spectrum of glyph-based visualiza-tion, reviewing existing design guidelines and implementation techniques, and surveying the use of glyph-basedvisualization in many applications.1. IntroductionGlyph-based visualization is a common form of visual de-sign where a data set is depicted by a collection of visualobjects referred to as glyphs. In a narrow interpretation,(a.1) a glyph is a small independent visual object that de-picts attributes of a data record;(a.2) glyphs are discretely placed in a display space; and(a.3) glyphs are a type of visual sign but differ from othertypes of signs such as icons, indices and symbols.In a broad interpretation,(b.1) a glyph is a small visual object that can be used inde-pendently and constructively to depict attributes of a datarecord or the composition of a set of data records;(b.2) each glyph can be placed independently from others,while in some cases, glyphs can be spatially connected toconvey the topological relationships between data recordsor geometric continuity of the underlying data space; and(b.3) glyphs are a type of visual sign that can make use ofvisual features of other types of signs such as icons, in-dices and symbols.In many applications, the spatial location of each glyph ispre-determined by th',\n",
       " 'Psychological Review2005, Vol. 112, No. 1, 193-216Copyright 2005 by the American Psychological Association0033-295X/05/$12.00 DOI: 10.1037/0033-295X.112.1.193The Career of MetaphorBrian F. BowdleIndiana UniversityDedre GentnerNorthwestern UniversityA central question in metaphor research is how metaphors establish mappings between concepts fromdifferent domains. The authors propose an evolutionary path based on structure-mapping theory. Thishypothesis-the career of metaphor-postulates a shift in mode of mapping from comparison tocategorization as metaphors are conventionalized. Moreover, as demonstrated by 3 experiments, thisprocessing shift is reflected in the very language that people use to make figurative assertions. The careerof metaphor hypothesis offers a unified theoretical framework that can resolve the debate betweencomparison and categorization models of metaphor. This account further suggests that whether meta-phors are processed directly or indirectly, and whether they operate at the level of individual concepts orentire conceptual domains, will depend both on their degree of conventionality and on their linguisticform.Over the past two decades, the cognitive perspective on meta-phor has undergone a radical shift. Traditionally, metaphors havebeen treated as both rare in comparison to literal language andlargely ornamental in nature. Current research suggests preciselythe opposite. Rather than being restricted to poetic uses, metaphoris common in everyday communication (e.g., Graesser, Long, &Mio, 1989; Pollio, Barlow, Fine, & Pollio, 1977; Smith, Pollio, &Pitts, 1981). For example, in an analysis of television programs,Graesser et al. (1989) found that speakers used approximately oneunique metaphor for every 25 words. A growing body of linguisticevidence further suggests that metaphors are important for com-municating about, and perhaps even reasoning with, abstract con-cepts such as time and emotion (e.g., Kovecses, 1988; Lakoff &Johnson, 1980; Quinn, 1987; Reddy, 1979; Sweetser, 1990). In-deed, studies of scientific writing support the notion that far frombeing mere rhetorical flourishes, metaphors are often used toinvent, organize, and illuminate theoretical constructs (e.g., Boyd,1979; Gentner & Grudin, 1985; Hoffman, 1980; Kuhn, 1979;Roediger, 1980; Sternberg, 1995). For example, Gentner and Gru-Brian F. Bowdle, Department of Psychology, Indiana University; DedreGentner, Department of Psychology, Northwestern University.This research was',\n",
       " 'Psychological  Bulletin1992. Vol.  112, No. 1,24-38Copyright  !^>2  by the American Psychological Association  inc0033-2909/92/53.00Primacy of Wholistic Processing and Global/Local Paradigm:A Critical  ReviewRuth KimchiUniversity of Haifa, IsraelThe question of whether perception is analytic or wholistic is an enduring issue in psychology. Theglobal-precedence  hypothesis,  considered  by many as a  modern  version of the  Gestaltist  claimabout the perceptual primacy of wholes, has generated a large body of research, but the debate stillremains very active. This article  reviews the research  within the global/local  paradigm, and criti-cally analyzes the assumptions  underlying this paradigm.  The extent to which this line of researchcontributes to understanding the role of wholistic processing  in object perception  is discussed.  It isconcluded that one should be very cautious in making inferences about wholistic processing  fromthe  processing  advantage of the global  level of stimulus structure.  A distinction is proposed  be-tween global properties,  denned by their position in the hierarchical structure of the stimulus, andwholistic properties,  denned as a function of interrelations among component parts. It is suggestedthat a direct comparison  between processing of wholistic and component  properties is needed  tosupport the hypothesis about the perceptual primacy  of wholistic processing.Marco Polo describes a bridge, stone  by stone.\"But which is the stone that supports the bridge?\" Kublai Khan\"The  bridge  is not supported by one stone or another,\"  Marcoasks.answers, \"but by the line of the arch that they form.\"Kublai Khan remains silent, reflecting. Then he adds: \"Why doyou speak to me of stones? It is only the arch that matters to  me.\"Polo answers: \"Without stones there is no arch.\" (Italo Calvino,1972/1974, p. 82)One of the most enduring issues in the psychology of percep-tion  concerns  the  perceptual  relations  between  wholes  andtheir parts.  The question  is whether processing  of the overallstructure precedes and determines the processing of the compo-nent parts or properties or whether the parts are registered firstand are then synthesized to form the objects of our awareness.This question permeates many topics in psychology, theoreticaland applied. To mention just a few examples: Does one recog-nize  faces  by  identifying  facial  features, such  as  eyes,  nose,mouth,  or  by  perceiving the  overall configuration first? (se',\n",
       " 'Psychological BulletinA Metaphor-Enriched Social CognitionMark J. Landau, Brian P. Meier, and Lucas A. KeeferOnline First Publication, September 6, 2010. doi: 10.1037/a0020970CITATIONLandau, M. J., Meier, B. P., & Keefer, L. A. (2010, September 6). A Metaphor-Enriched SocialCognition. Psychological Bulletin. Advance online publication. doi: 10.1037/a0020970\\x0c',\n",
       " \"The Use of Faces to Represent Points in K-Dimensional Space GraphicallyHerman ChernoffJournal of the American Statistical Association, Vol. 68, No. 342. (Jun., 1973), pp. 361-368.Stable URL:http://links.jstor.org/sici?sici=0162-1459%28197306%2968%3A342%3C361%3ATUOFTR%3E2.0.CO%3B2-2Journal of the American Statistical Association is currently published by American Statistical Association.Your use of the JSTOR archive indicates your acceptance of JSTOR's Terms and Conditions of Use, available athttp://www.jstor.org/about/terms.html. JSTOR's Terms and Conditions of Use provides, in part, that unless you have obtainedprior permission, you may not download an entire issue of a journal or multiple copies of articles, and you may use content inthe JSTOR archive only for your personal, non-commercial use.Please contact the publisher regarding any further use of this work. Publisher contact information may be obtained athttp://www.jstor.org/journals/astata.html.Each copy of any part of a JSTOR transmission must contain the same copyright notice that appears on the screen or printedpage of such transmission.JSTOR is an independent not-for-profit organization dedicated to and preserving a digital archive of scholarly journals. Formore information regarding JSTOR, please contact support@jstor.org.http://www.jstor.orgFri Mar 23 11:05:16 2007\\x0c\",\n",
       " 'QS Spiral: Visualizing PeriodicQuanti\\xef\\xac\\x81ed Self DataJakob Eg LarsenTech. University of DenmarkDept. of Applied Mathematicsand Computer ScienceMatematiktorvet, Bld 303B2800 Kgs. Lyngby, Denmarkjel@imm.dtu.dkAndrea CuttoneTech. University of DenmarkDept. of Applied Mathematicsand Computer ScienceMatematiktorvet, Bld 303B2800 Kgs. Lyngby, Denmarkandreacuttone@gmail.comSune LehmannTech. University of DenmarkDept. of Applied Mathematicsand Computer ScienceMatematiktorvet, Bld 303B2800 Kgs. Lyngby, Denmarkslj@imm.dtu.dkCopyright is held by the author/owner(s).CHI\\xe2\\x80\\x9913, Apr 27\\xe2\\x80\\x93May 2, 2013, Paris, France.AbstractIn this paper we propose an interactive visualizationtechnique QS Spiral that aims to capture the periodicproperties of quanti\\xef\\xac\\x81ed self data and let the user explorethose recurring patterns. The approach is based ontime-series data visualized as a spiral structure. Theinteractivity includes the possibility of varying the timespan and the time frame shown, allowing for di\\xef\\xac\\x80erentlevels of detail and the discoverability of repetitivepatterns in the data on multiple scales. We illustrate thecapabilities of the visualization technique using twoquanti\\xef\\xac\\x81ed self data sets involving self-tracking ofgeolocation and physical activity respectively.Author KeywordsQuanti\\xef\\xac\\x81ed Self, Personal Informatics, Time-Series Data,Data Visualization, Periodic EventsACM Classi\\xef\\xac\\x81cation KeywordsH.5.m [Information interfaces and presentation (e.g.,HCI)]: Miscellaneous.IntroductionRecently self-tracking has gained increased attention anduptake with the availability of smartphones and low cost\\x0c',\n",
       " 'Towards Adaptive Information Visualization:   On the Influence of User Characteristics Dereck Toker, Cristina Conati, Giuseppe Carenini, and Mona Haraty Department of Computer Science, University of British Columbia   2366 Main Mall, Vancouver, BC, V6T1Z4, Canada   {dtoker,conati,carenini,haraty}@cs.ubc.ca Abstract. The long-term goal of our research is to design information visualiza-tion systems that adapt to the specific needs, characteristics, and context of each individual viewer. In order to successfully perform such adaptation, it is crucial to first identify characteristics that influence an individual user\\xe2\\x80\\x99s effectiveness, efficiency, and satisfaction with a particular information visualization type. In this paper, we present a study that focuses on investigating the impact of four user characteristics (perceptual speed, verbal working memory, visual working memory, and user expertise) on the effectiveness of two common data visuali-zation  techniques:  bar  graphs  and  radar  graphs.  Our  results  show  that  certain user characteristics do in fact have a significant effect on task efficiency, user preference, and ease of use. We conclude with a discussion of how our findings could be effectively used for an adaptive visualization system. Keywords:  User  characteristics,  User  Evaluation,  Adaptive  Information   Visualization. 1 Introduction Information  visualization  is  a  thriving  area  of  research  in  the  study  of  hu-man/computer  communication.  Though  the  field  has  made  substantial  progress  in measuring  and  formalizing  visualization  effectiveness,  results  and  suggestions  from the literature are sometimes inconclusive and conflicting [19]. We believe this may be attributed to the fact that existing visualizations are designed mostly around the target data set and associated task model, with little consideration for user differences. Both long  term  user  characteristics  (e.g.,  cognitive  abilities  and  expertise)  and  short  term factors (e.g., cognitive load and attention) have often been overlooked in the design of information visualizations, despite studies linking individual differences to visualiza-tion efficacy  for search and navigation tasks [1,8], for information seeking tasks [7, 25], as well as anecdotal evidence of diverse personal visualization preferences [3].   Our  long  term  goal  is  to  explore  the  possibilities  of  user-centered  visualizations, which understand that different users h',\n",
       " 'Proceedings of ICAD 04-Tenth Meeting of the International Conference onAuditory Display, Sydney, Australia, July 6-9, 2004A MULTIMODAL TOOLKIT FOR  STOCK MARKET DATAsMAXSONIFICATIONFabio Cifariello CiardiFederazione CE.M.AT.via Orazio 31, 00193 Roma, ItalyEdison Studiovia Voghera 7, 00185 Roma, Italyf.cifariellociardi@edisonstudio.itABSTRACTIn this work, we present sMax a multimodal toolkit  for  stockmarket  data  sonification.for the  user Unlike  most  research  focusing  their  effort  primarily  onthe  sonification  of  single  stock  information,  sMax  providesan  auditory  display to  monitor  paralleldistributed  data.  sMax  uses  a set  of  Java  and  Max  modulesto map real time stock  market  information  into  recognizablemusical patterns. One of the main design goals of  the  toolkitis real-time  datasonification.  Because  of  its  object-oriented  architecture,sMax  can  be  easily  extended  by  the  user  when  additionalfunctionality  is  required.low-latency  controls  over to  allow The  project  outcomes  range  from  the  creation  of  artto  auditory  display  for  mobile  computingWe present the theoretical  background,  and  the  structureinstallations devices.of the program.1. INTRODUCTIONSonification  of  real  financial  data  is  an  interesting  field  ofenquiry for composers, researchers and market traders.Composers may be  interested  in  combining  sonificationoutcomes in their music for aesthetics  purposes  [1, 2, 3]. Aninterdisciplinary  research  effort  is  particularly  inspiritingwhen  graphical  representation  of    multidimensional  datafalls  short  of  affording  us  an  immediate  insight  as  in  thecase  of  stock  market  data.  There are at  least  two  reasons  toexplore  the  musical  potentiality  of    financial  informationsonification.First, as the rate  of  change  in  stock  prices  is  often  sharpand  unexpected,  unforeseeable  sonic  result  might  occur  inthe  sonification  of  stocks  data.  Secondly,  the  inner    andsubtle  correlation  of  stock  price  variations  may  beconsidered  similar  to  the  correlation  of  patterns  within  amusical  composition.On the other  hand,  stock  market  environments,  in  whichlarge  numbers  of  changing  variables  and/or temporallycomplex  information  must  be  monitored  simultaneously,  arewell  suited  for  perceptual  research  in  sonification.It has been shown that the auditory system is  very  usefulfor  task  monitoring  and  analysis ',\n",
       " '  Personal Informatics and Context: Using Context to Reveal Factors that Affect Behavior    Ian Anthony Rosas Li CMU-HCII-11-106 August 2011  Human-Computer Interaction Institute School of Computer Science Carnegie Mellon University  Pittsburgh, Pennsylvania 15213  Thesis Committee: Anind Dey (co-chair), Carnegie Mellon University Jodi Forlizzi (co-chair), Carnegie Mellon University Aniket Kittur, Carnegie Mellon University John Stasko, Georgia Institute of Technology  Submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy  Copyright \\xc2\\xa9 2011 Ian Anthony Rosas Li. All rights reserved.  This work was supported in part by the National Science Foundation under Grants # IIS-0325047. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the author and do not necessarily reflect those of the funding agencies. i \\x0c',\n",
       " 'WILLETT KEMPTON:s at Twin Rivers. Cam-: the Animal and the.d Sons . (2nd ed . 1961)al Review of Energylodels, D . Gentner and)aum Associates . Pp .10How people construct mental models\\'Allan Collins & Dedre GentnerAnalogies ;are powerful ways to understand how things work in a newdomain . We think this is because analogies enable people to construct astructure-mapping that carries across the way the components in a systeminteract . This allows people to create new mental models that they canthen run to generate predictions about what should happen in various situa-tions in the real world . This paper shows how analogies can be used toconstruct models of evaporation and how two subjects used such modelsto reason about evaporation .As Lakoff and Johnson (1980) have documented, our language is fullof metaphor and analogy. People discuss conversation as a physical trans-fer: (e.g., \"Let\\'s see if I can get this across to you\" (Reddy 1979) . Theyanalogize marriage to a manufactured object : (e.g., \"They had a basicsolid foundation in their marriages that could be shaped into somethinggood\" (Quinn this volume) . They speak of anger as a hot liquid in a con-tainer (Lakoff & Kovecses this volume) ; and they describe their home ther-mostat as analogous to the accelerator on a car (Kempton this volume) `Why are analogies so common? What exactly are they doing for us?\\'?We believe people use them to create generative mental models, models }they can use to arrive at new inferences . In this paper, we first discussthe general notion of a generative mental model, using three examples ofartificial intelligence models of qualitative physics ; second, we lay out theanalogy hypothesis of the paper, which we illustrate in terms of the com-ponent analogies that enter into mental models of evaporation ; and finally,we describe how two subjects used these analogies in reasoning about,\\'evaporation .The notion of running a generative model can be illustrated by an ex-ample from Waltz (1981) . People hearing \"The dachshund bit the mailmanon the nose\" spontaneously imagine scenarios such as the dachshund stand-ing on a ledge, or the mailman bending down to pet the dachshund . Simi-larly, if you try to answer the question, \"How far can you throw a potatochip?\" your thought processes may have the feel of a mental simulation .Examples such as these suggest that simulation and generative inferenceare integral to language understanding (Waltz 1981) . However, such\\x0c',\n",
       " 'SO40CH05-MoodyHealyARI4 July 201413:29groData Visualizationin SociologyKieran Healy and James MoodySociology Department, Duke University, Durham, North Carolina 27708;email: kjhealy@soc.duke.edu, jmoody77@soc.duke.edu.ylno esu lanosrep roF.sweiverlaunna.wwwmorf  dedaolnwoD .821-501:04.4102 .loicoS .veR .unnA .41/13/70 no ytisrevinU ekuDyb Annu. Rev. Sociol. 2014. 40:105\\xe2\\x80\\x9328First published online as a Review in Advance onJune 6, 2014The Annual Review of Sociology is online atsoc.annualreviews.orgThis article\\xe2\\x80\\x99s doi:10.1146/annurev-soc-071312-145551Copyright c\\xe2\\x83\\x9d 2014 by Annual Reviews.All rights reservedKeywordsvisualization, statistics, methods, exploratory data analysisAbstractVisualizing data is central to social scienti\\xef\\xac\\x81c work. Despite a promisingearly beginning, sociology has lagged in the use of visual tools. Wereview the history and current state of visualization in sociology. Usingexamples throughout, we discuss recent developments in ways of seeingraw data and presenting the results of statistical modeling. We make ageneral distinction between those methods and tools designed to helpexplore data sets and those designed to help present results to others.We argue that recent advances should be seen as part of a broader shifttoward easier sharing of code and data both between researchers andwith wider publics, and we encourage practitioners and publishers towork toward a higher and more consistent standard for the graphicaldisplay of sociological insights.105\\x0c',\n",
       " 'Proceedings of the 13th International Conference on Auditory Display, Montr\\xc2\\xb4eal, Canada, June 26 - 29, 2007TOWARD A DATA SONIFICATION DESIGN SPACE MAPAlberto de CampoInstitute for Electronic Music and AcousticsUniversity for Music and Dramatic ArtsInffeldgasse 10, A-8010 Graz, Austriadecampo@iem.atABSTRACTWe propose a systematic approach for reasoning about experimen-tal soni\\xef\\xac\\x81cation designs for a given type of dataset. Starting fromgeneral data properties, the approach recommends initial strate-gies, and lists possible re\\xef\\xac\\x81nements to consider in the design pro-cess. An overview of the strategies included is presented as a men-tal (and visual) map, and the re\\xef\\xac\\x81nement steps to consider corre-spond to movements on the map.The main purpose of this approach is to extract \\xe2\\x80\\x99theory\\xe2\\x80\\x99 from\\xe2\\x80\\x99observation\\xe2\\x80\\x99 (in our case, of design practice), similar to groundedtheory in sociology [1]:to make implicit knowledge (often ex-pressed in \\xe2\\x80\\x99natural\\xe2\\x80\\x99 ad hoc decisions by soni\\xef\\xac\\x81cation experts) ex-plicit and thus available for re\\xef\\xac\\x82ection, discussion, learning, andapplication in design work.This approach is the result of analysing design sessions whichtook place in an interdisciplinary soni\\xef\\xac\\x81cation workshop \\xe2\\x80\\x99ScienceBy Ear\\xe2\\x80\\x99 [2], held in March 2006. In order to explain the conceptin practice as well, a set of workshop sessions on one dataset isanalysed here in the terms proposed.[Keywords: Soni\\xef\\xac\\x81cation Theory, Soni\\xef\\xac\\x81cation Design Strategies]1. BACKGROUNDWhen collaborations on soni\\xef\\xac\\x81cation for a new \\xef\\xac\\x81eld of applicationstart, soni\\xef\\xac\\x81cation researchers may know little about the new do-main, its common types of data, and its interesting research ques-tions; similarly, domain scientists may know little about soni\\xef\\xac\\x81ca-tion, its general possibilities, and its possible bene\\xef\\xac\\x81ts for them. Insuch early phases of collaboration, the task to be achieved with asingle particular soni\\xef\\xac\\x81cation is often dif\\xef\\xac\\x81cult to de\\xef\\xac\\x81ne clearly, soit makes sense to employ an exploratory strategy which allows formutual learning and exchange. Eventually, the interesting tasks toachieve become clearer in the process.Rheinberger describes in [3] that researchers deal with \\xe2\\x80\\x99epis-temic things\\xe2\\x80\\x99, which are by de\\xef\\xac\\x81nition vague at \\xef\\xac\\x81rst (they can bee.g. physical objects, concepts or procedures whose usefulness isonly slowly becoming clear); they choose \\xe2\\x80\\x99experimental setups\\xe2\\x80\\x99(ensembles of epistemic things and established tools, devices, pro-cedures), which allow for endless repetitions ',\n",
       " 'On the visualization of high-dimensional dataPierrick BruneauTo cite this version:Pierrick Bruneau. On the visualization of high-dimensional data. 2013. <hal-00787488v4>HAL Id: hal-00787488https://hal.archives-ouvertes.fr/hal-00787488v4Submitted on 12 Jun 2013HAL is a multi-disciplinary open accessarchive for the deposit and dissemination of sci-enti\\xef\\xac\\x81c research documents, whether they are pub-lished or not. The documents may come fromteaching and research institutions in France orabroad, or from public or private research centers.L\\xe2\\x80\\x99archive ouverte pluridisciplinaire HAL, estdestin\\xc2\\xb4ee au d\\xc2\\xb4ep\\xcb\\x86ot et `a la di\\xef\\xac\\x80usion de documentsscienti\\xef\\xac\\x81ques de niveau recherche, publi\\xc2\\xb4es ou non,\\xc2\\xb4emanant des \\xc2\\xb4etablissements d\\xe2\\x80\\x99enseignement et derecherche fran\\xc2\\xb8cais ou \\xc2\\xb4etrangers, des laboratoirespublics ou priv\\xc2\\xb4es.\\x0c',\n",
       " ' Discovering Perceptions of Personal Social Networks through Diagrams Lixiu Yu1, Jeffrey V. Nickerson1, and Barbara Tversky2  1 Stevens Institute of Technology, Hoboken, NJ 2 Teachers College, Columbia University, New York, NY lyu3@stevens.edu, jnickerson@stevens.edu, btversky@stanford.edu  Abstract.  By  examining  diagrams  created  by  study  participants,  we  can  gain insight into their perceptions of their personal social networks. In this study, we found that participants made use of both position and distance to differentiate the roles of those in their networks and express intimacy. This work has impli-cation for both the elicitation and visualization of social networks. Keywords: Diagram understanding, personal social networks. 1   Introduction and Methods Abstract diagrams such as networks are interesting to study  for several reasons.  Al-though abstract diagrams contain a minimum of depictive information, they take ad-vantage of spatial reasoning processes that verbal, descriptive representations do not normally afford.  Observers can follow the lines from node to node to assess relation-ships,  temporal,  social,  causal,  or  more.  Normally,  these  relations  are  not  in  and  of themselves  spatial,  but  rather  metaphorically  spatial,  a  mapping  to  diagrammatic space that even preschoolers can do [1]. People add to diagrams inessential spatial information, even metaphoric spatial in-formation.  In  a  set  of  studies,  students  in  classes  in  design  of  information  systems were asked to sketch their designs of the interrelationships of the components, com-puters, cell phones, satellites, trucks, buildings, and the like [2]. All that is needed is labeled boxes and lines in arbitrary locations. Nevertheless, students used location and proximity in the space of the page to convey inessential information. Including relevant, even if inessential information, may help users express, under-stand,  and  make  inferences  from  diagrams.  The  inessential  information  that  people add to their diagrams serves another role, not for the producers and users of diagrams, but for researchers.  That information can reveal how people think about the concepts and  relations  conveyed  in  the  diagrams.  An  especially  interesting  context  for  using diagrammatic productions to reveal thought is social network diagrams. A variety of social  relationships,  notably  agency  (e.  g.,  [3]),  are  thought  of  in  spatial  terms.  In particu',\n",
       " 'How safe is your quantified self?Mario Ballano Barcena, Candid Wueest, Hon LauVersion 1.1 \\xe2\\x80\\x93 August 11, 2014, 12:00 GMTSECURITY RESPONSEFueled by technological advances and social factors, the quantified self movement has experienced rapid growth. \\x0c',\n",
       " 'Eurographics / IEEE Symposium on Visualization 2011 (EuroVis 2011)H. Hauser, H. P\\xef\\xac\\x81ster, and J. J. van Wijk(Guest Editors)Volume 30 (2011), Number 3Visualizing High-Dimensional Structures by DimensionOrdering and Filtering using Subspace AnalysisBilkis J. Ferdosi\\xe2\\x80\\xa0Jos B.T.M. Roerdink\\xe2\\x80\\xa1Johann Bernoulli Institute for Mathematics and Computer Science, University of GroningenAbstractHigh-dimensional data visualization is receiving increasing interest because of the growing abundance of high-dimensional datasets. To understand such datasets, visualization of the structures present in the data, such asclusters, can be an invaluable tool. Structures may be present in the full high-dimensional space, as well as in itssubspaces. Two widely used methods to visualize high-dimensional data are the scatter plot matrix (SPM) and theparallel coordinate plot (PCP). SPM allows a quick overview of the structures present in pairwise combinationsof dimensions. On the other hand, PCP has the potential to visualize not only bi-dimensional structures but alsohigher dimensional ones. A problem with SPM is that it suffers from crowding and clutter which makes inter-pretation hard. Approaches to reduce clutter are available in the literature, based on changing the order of thedimensions. However, usually this reordering has a high computational complexity. For effective visualization ofhigh-dimensional structures, also PCP requires a proper ordering of the dimensions.In this paper, we propose methods for reordering dimensions in PCP in such a way that high-dimensional struc-tures (if present) become easier to perceive. We also present a method for dimension reordering in SPM whichyields results that are comparable to those of existing approaches, but at a much lower computational cost. Ourapproach is based on \\xef\\xac\\x81nding relevant subspaces for clustering using a quality criterion and cluster information.The quality computation and cluster detection are done in image space, using connected morphological operators.We demonstrate the potential of our approach for synthetic and astronomical datasets, and show that our methodcompares favorably with a number of existing approaches.Categories and Subject Descriptors (according to ACM CCS):Information Search and Retrieval [H.3.3]:Clustering\\xe2\\x80\\x94; Computer Applications [J.2]: Physical Sciences and Engineering\\xe2\\x80\\x94Astronomy; Computer Graphics[I.3.6]: Methodology and Techniques\\xe2\\x80\\x94Interaction techniques1. IntroductionHigh dimensionality is becomin',\n",
       " '   Development of a Data Visualization Model based on Information Processing Theory Falschlunger Lisa1, Lehner Othmar, Eisl Christoph and Losbichler Heimo  University of Applied Sciences Upper Austria, Faculty for Management Steyr Wehrgrabengasse 1-3, 4400 Steyr, AUTRIA 1 Corresponding author\\xe2\\x80\\x99s email: lisa.falschlunger@fh-steyr.at  ABSTRACT: Information has emerged as being the fourth production factor and is becoming increasingly important in global  competition.  Research  shows  that  managerial  decision  making  is  directly  correlated  to  both,  the swift availability, and subsequently the ease of interpretation of the relevant information. A holistic picture, including  the  relevant  key  performance  indicators  of  the  company,  zooming  between  the  micro  and  the macro environments, as well as the ability of the involved managers to interpret this information is there-fore crucial for the performance of a company. The availability of so called \\xe2\\x80\\x98big data\\xe2\\x80\\x99 and the ever shorter cycle  time  between  the  identification  of  an  important  piece  of  information  and  the  possible  need  of  the management to react force traditional business concepts to change. Visualizations are already widely used to transform raw data into a more understandable format and to compress the huge amounts of data pro-duced. However, research in this area is highly fragmented and results are contradicting. This paper pro-poses a preliminary model based on an extensive literature review incl. top current research on cognition theory. Furthermore an early stage validation of this model by experimental research using structural equa-tion modeling is presented. The authors are able to identify predicting and moderating variables for infor-mation perception of visual data.  1 INTRODUCTION A  visual  representation  of  data  can  be  seen  as  a  means  to  accelerate,  as  well  as  to  improve cognition and interpretation  [1]  of  such, and  thus  should  in theory  improve rational  managerial decision making. However, such representations  so far are used inconsistently in praxis  [4] [6] and sometimes either in a way that misses the purpose of informing the reader  in an effective and efficient way [9] or in a way that may be even misleading or manipulating [3].  According to  Conati and Maclaren  [5]  the success of visualizations should be  determined by the ability of users to retrieve relevant information in an effective and efficient way. In this con',\n",
       " 'DOI: 10.1111/j.1467-8659.2009.01429.xCOMPUTER GRAPHICS forumVolume 28 (2009), number 6 pp. 1670\\xe2\\x80\\x931690Visualization of Multi-Variate Scienti\\xef\\xac\\x81c DataR. Fuchs1,2 and H. Hauser2,31Institute of Computer Graphics and Algorithms, Vienna University of Technology, Austria2VRV is Research Center, Vienna, Austria3Department of Informatics, University of Bergen, NorwayAbstractIn this state-of-the-art report we discuss relevant research works related to the visualization of complex, multi-variate data. We discuss how different techniques take effect at speci\\xef\\xac\\x81c stages of the visualization pipeline andhow they apply to multi-variate data sets being composed of scalars, vectors and tensors. We also providea categorization of these techniques with the aim for a better overview of related approaches. Based on thisclassi\\xef\\xac\\x81cation we highlight combinable and hybrid approaches and focus on techniques that potentially leadtowards new directions in visualization research. In the second part of this paper we take a look at recenttechniques that are useful for the visualization of complex data sets either because they are general purpose orbecause they can be adapted to speci\\xef\\xac\\x81c problems.Keywords: visualization, scienti\\xef\\xac\\x81c visualization, multi-variate data visualization, multi-dimensional datavisualization, multi-\\xef\\xac\\x81eld visualization, scalar data visualization, \\xef\\xac\\x82ow visualization,tensor visualization,illustrative visualizationACM CCS:I.3.8 [Computer Graphics]: Computer Graphics Applications1. IntroductionIn the last decade, there has been enormous progress in scien-ti\\xef\\xac\\x81c visualization [Max05]. Still the visualization of multi-variate continuous three-dimensional (3D) data, especiallywhen the data is also time-dependent, remains a great visu-alization challenge. Recent publications have stated a shiftin visualization research from a classical approach dealingwith visualization of small, isolated problems to a new kindof challenge: visualization of massive scale, dynamic datacomprised of elements of varying levels of certainty andabstraction [TC06]. It is a well-known fact that we are ex-periencing an increase in the amount and complexity of datagenerated that exceeds our ability to easily understand andmake sense of it. To address this development, Lee et al.\\xe2\\x88\\x9702] have indicated the work with multi-variate data[LCGsets as one important task for future visualization researchthat will require signi\\xef\\xac\\x81cant advances in visualization algo-06] addressed top scienti\\xef\\xac\\x81crithms. Mu',\n",
       " 'University of Nebraska - LincolnDigitalCommons@University of Nebraska - LincolnFaculty Publications, Department of PsychologyPsychology, Department of3-5-2010Sonification Report: Status of the Field andResearch AgendaGregory KramerBruce WalkerTerri BonebrightPerry CookJohn H. FlowersUniversity of Nebraska at Lincoln, jflowers1@unl.eduSee next page for additional authorsFollow this and additional works at: http://digitalcommons.unl.edu/psychfacpubPart of the Psychiatry and Psychology CommonsKramer, Gregory; Walker, Bruce; Bonebright, Terri; Cook, Perry; Flowers, John H.; Miner, Nadine; and Neuhoff, John, \"SonificationReport: Status of the Field and Research Agenda\" (2010). Faculty Publications, Department of Psychology. Paper 444.http://digitalcommons.unl.edu/psychfacpub/444This Article is brought to you for free and open access by the Psychology, Department of at DigitalCommons@University of Nebraska - Lincoln. It hasbeen accepted for inclusion in Faculty Publications, Department of Psychology by an authorized administrator of DigitalCommons@University ofNebraska - Lincoln.\\x0c',\n",
       " '. Gentner, D. (2002). Mental models, Psychology of. In N. J. Smelser & P. B. Bates (Eds.), International Encyclopedia of the Social and Behavioral Sciences (pp. 9683-9687).  Amsterdam: Elsevier Science. configural description or a mixture of  the two,  and rarely any other kind. These questions are not just an issue of academic interest. We have all often had frustrating experience trying to understand verbal directions a b u t  how to get somewhere or trying to grasp the layout of an area by means of a map. Virtual reality is currently being proposed as having great potential for training people, e.g., soldiers, for tasks in new environments. However, with the present state-of-the-art it is difficult to build a good sense of the layout (a good mental map)  of  a virtual world one is moving through. How to use these media most effectively to enable the most  desirable mental map is a goal for future research. Bibliography Bloom P, Peterson  M A, Nadel  L,  Garrett  M F (eds.)  1996 Gallistel C R  1990  The Organization of Learning. MIT Press, Language and Space. MIT Press, Cambridge, MA Cambridge, MA Cambridge, MA Gladwin T  1970 East  is a Big Bird. Harvard University Press, Hazen N L, Lockman J J, Pick H L Jr 1978 The development of children\\xe2\\x80\\x99s representations of large-scale environments. Cltild Deuelopment 49: 623-36 Hutchins E 1995 Cognition in the  Wild. MIT Press, Cambridge, MA Hutchins E, Hinton G E 1984 Why the islands move. Perception Lewis D 1978 The Voyaging Stars: Secrets of  the Pacific Island 1 3  629-32 Nauigators. Norton, New York Loomis  JM,  Klatzky  RL,  Golledge  RG,  CicineIli  JG, Pellegrino J W, Fry P A 1993 Nonvisual navigation by blind and sighted: Assessment of path inkgration ability. Joumul of Experimental Psychology: General 122: 73-91 Rieser J J,  Guth D A, Hi11 E W  1988 Sensitivity to perspective structure while waking without vision. Perception 15 173-88 Thorndyke  P W,  Hayes-Roth  B 1982  Difierences in  spatia1 knowledge acquired from  maps and  navigation. Cognitive Psychology 14 56&89 Tversky B 1996 Spatial perspective in descriptions. In: Bloom P, Peterson M A ,  Nadel  L,  Garrett M F  (eds.) Language and Space. MIT Press, Cambridge, MA pp. 463-91 logical Review 56: 144-55 Tolman  E C  1948 Cognitive maps in  rats  and  men.  Psycho- Uttal  D H  2001  Seeing the  big  picture:  Map  use  and  the development of spatial cognition. Developmental Science 3 247-86 H. L. Pick Jr. Mental Models, Psychology of A mental mod',\n",
       " 'Topics in Cognitive Science 2 (2010) 15\\xe2\\x80\\x9335Copyright \\xc3\\x93 2009 Cognitive Science Society, Inc. All rights reserved.ISSN: 1756-8757 print / 1756-8765 onlineDOI: 10.1111/j.1756-8765.2009.01048.xVisualizing Scienti\\xef\\xac\\x81c InferenceDavid C. GoodingDepartment of Psychology, Science Studies Centre, University of BathReceived 10 July 2008; received in revised form 6 March 2009; accepted 15 June 2009AbstractThe sciences use a wide range of visual devices, practices, and imaging technologies. This diver-sity points to an important repertoire of visual methods that scientists use to adapt representations tomeet the varied demands that their work places on cognitive processes. This paper identi\\xef\\xac\\x81es keyfeatures of the use of visualization in a range of scienti\\xef\\xac\\x81c domains and considers the implications ofthis repertoire for understanding scientists as cognitive agents.Keywords: Cognition; Discovery; Imaging; Perception; Visualization; Visualmodelsinference; Visual1. IntroductionThe ability to create and manipulate visual representations is cognitive skills acquired asa scientist becomes an accomplished participant in the methods that de\\xef\\xac\\x81ne a particulardomain. In \\xef\\xac\\x81elds such as physical chemistry and developmental biology, visual modelingtechniques are so important that textbook presentation is driven by the adoption of newimaging technologies (Atkins, 2006; Gilbert & Singer, 2006). In others, such as physics,visualization skills are integral to mathematical and modeling techniques and are usuallylearned implicitly along with these. Such skills are learned by example\\xe2\\x80\\x94by seeing howmodels are constructed, used, evaluated, and re\\xef\\xac\\x81ned by a group. This requires active partici-pation in the practices of the group (Alac & Hutchins, 2004). Nevertheless, such knowledgecontinues to have an important personal component. It is learned by individuals so that theycan contribute to the knowledge-producing activity of the group. Innovations, in particular,requires the ability to introduce novel ways of seeing and thinking into an existing frame-work of concepts, categories, and models. Innovations may be provoked by anomalies inThe journal regrets to report that Professor Gooding passed away while this issue of topiCS was in production.We are honored to publish his last work.\\x0c',\n",
       " 'How Capacity Limits of Attention Influence Information Visualization Effectiveness Steve Haroz and David Whitney  Fig. 1. These images each have one colored square that is unique within that image. How long does it take you to find each? How many color categories are there in each panel? Why does grouping make both tasks substantially easier? Abstract\\xe2\\x80\\x94In this paper, we explore how the capacity limits of attention influence the effectiveness of information visualizations. We conducted a series of experiments to test how visual feature type (color vs. motion), layout, and variety of visual elements impacted user performance. The experiments tested users\\xe2\\x80\\x99 abilities to (1) determine if a specified target is on the screen, (2) detect an odd-ball,  deviant  target,  different  from  the  other  visible  objects,  and  (3)  gain  a  qualitative  overview  by  judging  the  number  of  unique categories  on  the  screen.  Our  results  show  that  the  severe  capacity  limits  of  attention  strongly  modulate  the  effectiveness  of information  visualizations,  particularly  the  ability  to  detect  unexpected  information.  Keeping  in  mind  these  capacity  limits,  we conclude with a set of design guidelines which depend on a visualization\\xe2\\x80\\x99s intended use. Index Terms\\xe2\\x80\\x94Perception, attention, color, motion, user study, nominal axis, layout, goal-oriented design. INTRODUCTION 1 An information visualization designer aims to present the maximum amount of data without overwhelming the user with complexity and information-overload.  The  components  arranged  to  form  a  GUI  or visualization are visual features \\xe2\\x80\\x93 the properties of any image that the brain is capable of encoding and integrating into a coherent percept [1]. Examples that apply to visualization include position, color, size, orientation, texture [2], and motion [3\\xe2\\x80\\x935]. The designer\\xe2\\x80\\x99s role is to effectively  associate  these  visual  features  with  corresponding dimensions or categories in the underlying data [6].  Unfortunately,  the  speed  and  capacity  of  human  attention  for these  visual  features  are  severely  limited  [7],  [8]  and  these  limits may  influence  the  effectiveness  of  information  visualizations. Exceeding  the  limits  of  visual  attention  markedly  impairs  both  the accuracy and timing of one\\xe2\\x80\\x99s response to a visual scene (Fig. 1). This consequence may seem intuitive (e.g., the benefit of grouping in Fig. 1  might  seem  obvious),  however  visuali',\n",
       " 'Listen to your Data:Model-Based Soni\\xef\\xac\\x81cation for Data AnalysisT. Hermann and H. RitterDepartment of Computer Science\\x00 University of Bielefeld\\x00 D-33615 Bielefelde-mail:\\x01 thermann,helge\\x02 @techfak.uni-bielefeld.deAbstractSoni\\xef\\xac\\x81cation is the use of non-speech audio to con-vey information. We are developing tools for interact-ive data exploration, which make use of soni\\xef\\xac\\x81cation fordata presentation. In this paper, model-based soni\\xef\\xac\\x81ca-tion is presented as a concept to design auditory dis-plays. Two designs are described: (1) particle trajec-tories in a \\xe2\\x80\\x9cdata potential\\xe2\\x80\\x9d is a soni\\xef\\xac\\x81cation model toreveal information about the clustering of vectorial dataand (2) \\xe2\\x80\\x9cdata-sonograms\\xe2\\x80\\x9d is a soni\\xef\\xac\\x81cation for data froma classi\\xef\\xac\\x81cation problem to reveal information about themixing of distinct classes.Keywords: Soni\\xef\\xac\\x81cation, Exploratory Data Analysis,Acoustics, Cluster Analysis1 IntroductionThe detection of hidden regularities in high dimen-sional data sets is one goal of the work in the researcharea of datamining[4]. Structures may occur as a clus-tering of the data, as hierarchical organization or in func-tional dependencies between the components of data. Inhigh-dimensional data this organization is mostly notobvious. This has motivated the development of var-ious visualization techniques such as multidimensionalscaling[3] or projection on principal components[8] thatattempt to create dimensionality reduced displays inwhich the \\xe2\\x80\\x9cmain\\xe2\\x80\\x9d structure of the data is more discern-able for humans. These methods are attractive, sincethey transform the given data into a format that allowsus to invoke our highly developed capabilities for detect-ing even sutble visual patterns in images. However, weare also capable to detect very subtle patterns in acousticsounds, which is exempli\\xef\\xac\\x81ed to an impressive degree inthe \\xef\\xac\\x81eld of music, or in medicine, where the stethoscopestill provides very valuable guidance to the physician.While these examples demonstrate that the use of soundfor detecting subtle structures is an important praxis inseveral \\xef\\xac\\x81elds, it so far has found comparably little atten-tion in the \\xef\\xac\\x81eld of datamining, which may be due to thelarger dif\\xef\\xac\\x81culty to communicate about sound in compar-ison to visualization.This paper presents two new methods for acousticdata presentation:listening to particle dynamics in adata potential reveals information about the clusteringof data. Listening to data sonograms gives an impres-sion on results of a prior clustering',\n",
       " 'SonART: A framework for data soni(cid:2)cation, visualization andnetworked multimedia applicationsWoon Seung Yeo, Jonathan Berger \\x00, Zune LeeCCRMA, Stanford Universitybrg@ccrma.stanford.eduAbstractSonART is a (cid:3)exible, multi-purpose multimedia environmentthat allows for networked collaborative interaction with ap-plications for art, science and industry. In this paper we de-scribe the integration of image and audio that SonART en-ables. An arbitrary number of layered canvases, each withindependent control of opacity, RGB values, etc., can transmitor receive data using Open Sound Control. Data from imagescan be used for synthesis or audio signal processing and viceversa. SonART provides an open ended framework for inte-gration of powerful image and audio processing methds witha (cid:3)exible network communications protocol. Applications in-clude multimedia art, collaborative and interactive art anddesign, and scienti(cid:2)c and diagnostic exploration of data.1 IntroductionSonART provides a framework for image and data soni(cid:2)-cation. In addition, tools for integrating image graphics, dig-ital audio, and other data provide a robust platform for mul-timedia interaction. Originally created for sound driven dataexploration and diagnostic purposes (O. Ben Tal, 2002), thesoftware also provides a powerful tool for multimedia perfor-mance over a network and facilitates real-time interactive cre-ation, manipulation and exploration of audio and images. Theprogram is currently implemented as a Cocoa-based OS X ap-plication. Functionality includes the ability to load and drawmulti-layered images, and to send/receive visual and controldata to/from other multimedia programs that support OpenSound Control (M. Wright, 2001).SonART\\xe2\\x80\\x99s core features include:image display and processing capabilities(cid:150) intuitive GUI features of audio mixers and of bothaudio and graphic editing software are preserved.(cid:150) analogies between audio and visual processes areutilized.\\x02 supported by DARPA F41624-03-1-7000(cid:150) an arbitrary number of images can be simultane-ously layered.(cid:150) user controlled parameters (i.e., opacity, composit-ing operations, visibility, location and size) foreach layer can be controlled within the programinterface or remotely by OSC messaging.(cid:150) a set of image processing (cid:2)lters and functions areavailable, and the program is designed to facili-tate plug-ins for any type of image processing.\\x01 Transmitting and receiving data f',\n",
       " 'Improving the Visual Analysis of High-dimensional Datasets UsingQuality MeasuresGeorgia Albuquerque\\xe2\\x88\\x97TU BraunschweigGermanyMartin Eisemann\\xe2\\x80\\xa0TU BraunschweigGermanyDirk J. Lehmann\\xe2\\x80\\xa1University of MagdeburgGermanyHolger Theisel\\xc2\\xa7University of MagdeburgGermanyMarcus Magnor\\xc2\\xb6TU BraunschweigGermanyABSTRACTModern visualization methods are needed to cope with very high-dimensional data. Ef\\xef\\xac\\x81cient visual analytical techniques are requiredto extract the information content in these data. The large number ofpossible projections for each method, which usually grow quadrat-ically or even exponentially with the number of dimensions, urgesthe necessity to employ automatic reduction techniques, automaticsorting or selecting the projections, based on their information-bearing content. Different quality measures have been successfullyapplied for several speci\\xef\\xac\\x81ed user tasks and established visualiza-tion techniques, like Scatterplots, Scatterplot Matrices or ParallelCoordinates. Many other popular visualization techniques exist,but due to the structural differences, the measures are not directlyapplicable to them and new approaches are needed. In this paperwe propose new quality measures for three popular visualizationmethods: Radviz, Pixel-Oriented Displays and Table Lenses. Ourexperiments show that these measures ef\\xef\\xac\\x81ciently guide the visualanalysis task.Index Terms: H.3.3 [Information Storage and Retrieval]: Infor-mation Search and Retrieval\\xe2\\x80\\x94; I.3.3 [Computer Graphics]: Pic-ture/Image Generation;1 INTRODUCTIONAlthough diverse visualization methods support the exploration ofhigh-dimensional datasets, the visual analysis of such data is stilla challenging task. The visualization and analysis of multivariatedatasets typically involves mapping the data to lower dimensionalembeddings, which is the case for Scatterplots or pixel-orientedmethods, or determining a placement of the dimensions in multi-variate visualizations, as in Parallel Coordinates [13] or Radviz [9].This approach may generate several hundreds or thousands possi-ble projections for high-dimensional datasets and the visual anal-ysis may quickly become an overwhelming task. An alternativesolution to this problem is to use a handful of quality measures toautomatically select information-bearing projections of the data.Quality measures are generally based on a speci\\xef\\xac\\x81c user task, andmay be used as a starting point in the visual analysis of multivari-ate data. Since the pioneering Projection Pursuit approac',\n",
       " 'Towards a Foundation for Information Visualization Engineering Lars Grammel1 and Margaret-Anne Storey2 University of Victoria   ABSTRACT Despite  much  progress,  it  remains  challenging  to  develop  new visualization  systems,  predict  their  qualities,  and  understand design  trade-offs.  We  propose  an  empirical  framework  for Information  Visualization  (InfoVis)  theories  consisting  of  a context  space,  a  visualization  space,  visualization  metrics,  and visualization  principles.  Using  this  framework,  we  identify  5 possible  steps  to  advance  InfoVis  theory.  While  the  underlying ideas  we  discuss  will  be  familiar  to  readers,  we  hope  that expressing  them in a systematic framework will contribute to the discussion of InfoVis theory, identify challenges that still need to be addressed, and shed light on how to integrate different theories in InfoVis.  KEYWORDS:  Information  Visualization,  InfoVis  Engineering, InfoVis Science, Theory, Framework 1 INTRODUCTION Despite  progress  in  Information  Visualization  (InfoVis), it remains challenging to develop new visualization systems, predict their  qualities,  and  understand  the  trade-offs  between  designs. Researchers  have  recognized  the  need  for  InfoVis  theory  to address these  challenges  [8,  9,  11, 12, 15]. Thomas and  Cook, in particular,  expressed  the  need  to  move  from  craftsmanship  to engineering, and to develop a theory for visual representations and interaction techniques [12]. We believe that practitioners must be able  to  apply  visualization  principles  grounded  in  systematic empirical work. To this end, we propose that InfoVis science and InfoVis engineering be considered distinct areas of InfoVis: InfoVis  Science  is  the  systematic  gathering  of  knowledge  about InfoVis  and  the  organization  of  that  knowledge  into  testable visualization principles. InfoVis  Engineering  is  the  creative  application  of  scientific visualization principles to design or develop InfoVis systems. While  both  InfoVis  science  and  engineering  require  us  to  build visualizations  and  work  with  visualization  principles,  they  differ in  their  goals.  InfoVis  science  is  concerned  with  creating, understanding  and  refining  visualization  principles.  In  InfoVis Science,  specific  visualizations  are  created  to  gather  empirical data in user studies. In contrast, InfoVis engineering is concerned with  creating  visualiza',\n",
       " 'J. Pers. Med. 2012, 2, 93-118; doi:10.3390/jpm2030093 OPEN ACCESS Journal of Personalized Medicine ISSN 2075-4426 www.mdpi.com/journal/jpm/ Opinion Health 2050: The Realization of Personalized Medicine through Crowdsourcing, the Quantified Self, and the Participatory Biocitizen Melanie Swan  MS Futures Group, P.O. Box 61258, Palo Alto, CA 94306, USA; E-Mail: m@melanieswan.com;  Tel.: +1-650-681-9482; Fax: +1-504-910-3803 Received: 2 July 2012; in revised form: 15 August 2012 / Accepted: 15 August 2012 /  Published: 12 September 2012  Abstract:  The  concepts  of  health  and  health  care  are  moving  towards  the  notion  of personalized preventive health maintenance and away from an exclusive focus on the cure of  disease.  This  is  against  the  backdrop  of  contemporary  public  health  challenges  that include  increasing  costs,  worsening  outcomes,  \\xe2\\x80\\x98diabesity\\xe2\\x80\\x99  epidemics,  and  anticipated physician shortages. Personalized preventive medicine could be critical to solving public health  challenges  at  their  causal  root.  This  paper  sets  forth  a  vision  and  plan  for  the realization of preventive medicine by 2050 and examines efforts already underway such as participatory health initiatives, the era of big health data, and qualitative shifts in mindset. Keywords:  personalized  medicine;  preventive  medicine;  crowdsourcing;  participatory medicine;  participant-centric  initiatives;  digital  health;  health  empowerment;  health  trust communities; quantified self; future of medicine  1. Introduction 1.1. Contemporary Public Health Challenges When considering the critical health challenges of the current era, it is easy to think of the 18% of the U.S. GDP being spent on health care ($8,402 per person per year in 2010) [1], health outcomes that lag those of other Organization for Economic Co-operation and Development (OECD) countries [2], \\x0c',\n",
       " 'J. Sens. Actuator Netw. 2012, 1, 217-253; doi:10.3390/jsan1030217 OPEN ACCESS Journal of Sensor  and Actuator NetworksISSN 2224-2708 www.mdpi.com/journal/jsan/ Review Sensor Mania! The Internet of Things, Wearable Computing, Objective Metrics, and the Quantified Self 2.0 Melanie Swan  MS Futures Group, P.O. Box 61258, Palo Alto, CA 94306, USA; E-Mail: m@melanieswan.com;  Tel.: +1-650-681-9482; Fax: +1-504-910-3803 Received: 4 September 2012; in revised form: 31 October 2012 / Accepted: 31 October 2012 /  Published: 8 November 2012  Abstract:  The number of devices on the Internet exceeded the number of people on the Internet in 2008, and is estimated to reach 50 billion in 2020. A wide-ranging Internet of Things  (IOT)  ecosystem  is  emerging  to  support  the  process  of  connecting  real-world objects like buildings, roads, household appliances, and human bodies to the Internet via sensors  and  microprocessor  chips  that  record  and  transmit  data  such  as  sound  waves, temperature, movement, and other variables. The explosion in Internet-connected sensors means  that  new  classes  of  technical  capability  and  application  are  being  created.  More granular 24/7 quantified monitoring is leading to a deeper understanding of the internal and external worlds encountered by humans. New data literacy behaviors such as correlation assessment,  anomaly  detection,  and  high-frequency  data  processing  are  developing  as humans adapt to the different kinds of data flows enabled by the IOT. The IOT ecosystem has four critical functional steps: data creation, information generation, meaning-making, and action-taking. This paper provides a comprehensive review of the current and rapidly emerging ecosystem of the Internet of Things (IOT). Keywords: Internet of Things; sensors; objective metrics; quantified self; personal metrics; high-tech  hardware;  integrated  sensor  platforms;  multi-sensor  platforms;  information visualization; health Internet of Things  1. Introduction: The Rapid Approach of the Internet of Things 1.1. What is the Internet of Things? There are several definitions of the Internet of Things (IOT). One that is salient for how the term is currently in use is provided by the U.S. National Intelligence Council: \\xe2\\x80\\x9cThe \\xe2\\x80\\x9cInternet of Things\\xe2\\x80\\x9d is the \\x0c',\n",
       " \"584 Automated  Analytical  Methods  to  Support Visual  Exploration  of  High-Dimensional  Data Andrada Tatu,  Georgia Albuquerque,  Martin  Eisemann,  Peter Sak,  Member,  IEEE, Holger Theisel,  Member,  IEEE,  Marcus  Magnor,  Member,  IEEE, and  Daniel  Keirn,  Member,  IEEE Abstract-Visual exploration of multivariate data typically requires projection onto lower dimensional representations. The number of possible  representations grows  rapidly  with  the  number of  dimensions,  and  manual  exploration  quickly becomes ineffective or even unfeasible. This  paper proposes automatic analysis  methods to  extract  potentially  relevant visual  structures from  a set  of candidate visualizations.  Based on  features,  the  visualizations are  ranked  in  accordance with  a specified user task.  The  user is  provided with  a manageable number of potentially useful candidate visualizations,  which can  be  used as a starting point for interactive data analysis. This can  effectively ease the task of finding truly useful visualizations and potentially speed up the data exploration task. In  this paper, we  present ranking  measures  for class-based as well as  non-class-based scatterplots and  parallel  coordinates visualizations. The proposed  analysis methods are  evaluated  on  different data sets. Index Terms-Dimensionality reduction,  quality measures, scatterplots,  parallel  coordinates. 1 INTRODUCTION D UE to  the technological  progress over  the  last decades, today's  scientific  and  commercial  applications  are capable  of  generating,  storing,  and  processing  large  and complex  data  sets.  Making  use  of  these  archives  of  data provides  new challenges  to  analysis  techniques.  It is  more difficult  to  filter  and  extract  relevant  information  from the  masses  of  data  since  the  complexity  and  volume have increased .  Effective  visual  exploration  techniques  are needed  that  incorporate  automated  analysis  components to  reduce  complexity  and  to  effectively  guide  the  user during  the  interactive exploration  process. The  visualization  of  large  complex  information  spaces typically involves mapping high-dimensional data to lower dimensional  visual  representations.  The  challenge  for the  analyst  is  to  find  an  insightful  mapping,  while  the dimensionality of the data, and consequently, the number of possible mappings increases. For an effective visual explora(cid:173)tion of large data source\",\n",
       " '\\x0c',\n",
       " '\\xc2\\xaby and Aging1995, Vo\\\\.  10. No. 3, 404-415Copyright  1995 by the American Psychological Association, Inc.0882-7974/95/S3.00Representations of Self Across the Life SpanGisela Labouvie-Vief, Lisa M. Chiodo, Lori A. Goguen,Manfred Diehl, and Luanda OrwollWayne State UniversityThis research  extends a  cognitive-developmental  approach  to  examining age differences in  self-representation  from adolescence to mature adulthood and later life. The authors suggest that matureadults move from representations  of self that are relatively poorly differentiated  from others or socialconventions to ones that involve emphasis on process, context, and individuality. Participants (nmen = 73, n women = 76), ranging in age from  11 to 85 years, provided spontaneous accounts oftheir self-representations and responded to measures assessing cognitive and emotional functioningand broad dimensions of personality. On average, self-representation  scores peaked in  middle-agedadults and were lowest in the preadolescent and older adult age groups. Level of self-representationwas related to cognitive and personality variables, but there was some evidence that the pattern ofcorrelates shifted from younger (ages 15-45) to older (ages 46-85) age segments.There has been a rising interest in the last decade in the studyof the  self and  its development across  the  life  span  (Cross  &Markus,  1991; Lipka & Brinthaupt,  1992; Noam, Powers, Kil-kenny, & Beedy, 1990). Although researchers  in this endeavorhave proposed multiple definitions, theoretical frameworks, andmethods, a common theme appears to tie together these diverseapproaches.  Recent  interest  in  the  self reflects a  move of  thefield away  from  the  study of the  self as a  unitary, conscious-rational, and integrated entity, and toward a view of the self as astructure or set of processes characterized  by multiplicity  thatis contextually (culturally, historically, and interpersonally) sit-uated, that is the locus of changes and transformation,  and thatis the site not only of integrative tendencies but also of tenden-cies  toward  fragmentation  and  distortion  (e.g.,  Fischer  &Ayoub,  1994; Gergen,  1991; Hermans & Kempen,  1993; Hig-gins, Bond, Klein, & Straumann,  1986; Markus & Wurf, 1987;Noam, 1988).Recent developments in the study of the self mirror the sug-gestions of earlier theorists. The emerging focus on the self as acomplex, changing, multiplex structure is well mirrored by ma-jor  proponents  of  a  li',\n",
       " 'Empirical Studies in Information Visualization: SevenScenariosHeidi Lam, Enrico Bertini, Petra Isenberg, Catherine Plaisant, SheelaghCarpendaleTo cite this version:Heidi Lam, Enrico Bertini, Petra Isenberg, Catherine Plaisant, Sheelagh Carpendale. EmpiricalStudies in Information Visualization: Seven Scenarios.IEEE Transactions on Visualizationand Computer Graphics, Institute of Electrical and Electronics Engineers (IEEE), 2012, 18 (9),pp.1520\\xe2\\x80\\x931536. <10.1109/TVCG.2011.279>. <hal-00932606>HAL Id: hal-00932606https://hal.inria.fr/hal-00932606Submitted on 17 Jan 2014HAL is a multi-disciplinary open accessarchive for the deposit and dissemination of sci-enti\\xef\\xac\\x81c research documents, whether they are pub-lished or not. The documents may come fromteaching and research institutions in France orabroad, or from public or private research centers.L\\xe2\\x80\\x99archive ouverte pluridisciplinaire HAL, estdestin\\xc2\\xb4ee au d\\xc2\\xb4ep\\xcb\\x86ot et `a la di\\xef\\xac\\x80usion de documentsscienti\\xef\\xac\\x81ques de niveau recherche, publi\\xc2\\xb4es ou non,\\xc2\\xb4emanant des \\xc2\\xb4etablissements d\\xe2\\x80\\x99enseignement et derecherche fran\\xc2\\xb8cais ou \\xc2\\xb4etrangers, des laboratoirespublics ou priv\\xc2\\xb4es.\\x0c',\n",
       " 'DOI: 10.1111/j.1467-8659.2012.03118.xEurographics Conference on Visualization (EuroVis) 2012S. Bruckner, S. Miksch, and H. P\\xef\\xac\\x81ster(Guest Editors)Volume 31 (2012), Number 3MatchPad: Interactive Glyph-Based Visualization forReal-Time Sports Performance AnalysisP. A. Legg1,2, D. H. S. Chung1,2, M. L. Parry1,2, M. W. Jones1, R. Long3, I. W. Grif\\xef\\xac\\x81ths2 and M. Chen41Department of Computer Science, Swansea University, UK2College of Engineering, Swansea University, UK3Centre of Excellence, Welsh Rugby Union, UK4e-Research Centre, Oxford University, UKAbstractToday real-time sports performance analysis is a crucial aspect of matches in many major sports. For example, insoccer and rugby, team analysts may annotate videos during the matches by tagging speci\\xef\\xac\\x81c actions and events,which typically result in some summary statistics and a large spreadsheet of recorded actions and events. To acoach, the summary statistics (e.g., the percentage of ball possession) lacks suf\\xef\\xac\\x81cient details, while reading thespreadsheet is time-consuming and making decisions based on the spreadsheet in real-time is thereby impossible.In this paper, we present a visualization solution to the current problem in real-time sports performance analysis.We adopt a glyph-based visual design to enable coaching staff and analysts to visualize actions and events \\xe2\\x80\\x9cat aglance\\xe2\\x80\\x9d. We discuss the relative merits of metaphoric glyphs in comparison with other types of glyph designs inthis particular application. We describe an algorithm for managing the glyph layout at different spatial scales ininteractive visualization. We demonstrate the use of this technical approach through its application in rugby, forwhich we delivered the visualization software, MatchPad, on a tablet computer. The MatchPad was used by theWelsh Rugby Union during the Rugby World Cup 2011. It successfully helped coaching staff and team analyststo examine actions and events in detail whilst maintaining a clear overview of the match, and assisted in theirdecision making during the matches. It also allows coaches to convey crucial information back to the players in avisually-engaging manner to help improve their performance.1. IntroductionPerformance analysis is a common practice in sports duringmatches and training [HB02]. It typically involves collect-ing laboratory or \\xef\\xac\\x81eld data, extracting quantitative measure-ment, carrying out statistical analysis, and data visualization.One crucial area of sports performance analysis is notat',\n",
       " 'A R T I S T \\xe2\\x80\\x99 S   A R T I C L E  Atmospherics/Weather Works:A Spatialized Meteorological Data Soni\\xef\\xac\\x81cation ProjectAndrea Polli Sound is wonderful, because, different than sight (which is alsobeautiful, of course), sound connects things, and sound accom-modates many voices at one time and they remain intelligible. . . .Sound, as a medium, aesthetically allows us to experience envi-ronment as connections between living things, and cycles, andrhythms [1].Why is scienti\\xef\\xac\\x81c data so often presented as visual image andso much less often presented as sound? One reason might have to do with time. A still visual image can be scanned overtime, allowing a viewer to study various aspects of the image.A piece of music or a soundscape, on the other hand, cannotbe examined in detail without the destructive process of stop-ping, selecting and replaying various parts. Identifying aspectsof a visual image is easily achieved by viewers. Speci\\xef\\xac\\x81c colorsand shapes are described more easily than speci\\xef\\xac\\x81c notes ormusical phrases. Although some sounds can be clearly identi-\\xef\\xac\\x81ed (like a dog\\xe2\\x80\\x99s bark or a cat\\xe2\\x80\\x99s meow), the sources of othersounds are not quite as clear.However, unlike still visual images, music and soundscapesare inherently narrative. For example, as I listen to footstepsand voices outside my apartment door, I can determine thattwo people are walking up the stairs of my apartment build-ing. I can determine approximately what \\xef\\xac\\x82oor they are on andeven gather a little information about their relationship. (Arethey a couple? A mother and child? Have they recently beenarguing or laughing?) In a visual image, emotional content canbe ambiguous. Looking at a photograph of a family, for ex-ample, I am likely to encounter a certain amount of ambiguityin determining the relationships between the subjects unlesstheir facial and body expressions are highly exaggerated.For over 10 years, I have been creating artistic works thattranslate numerical data into sound, from algorithmic com-positions modeling chaos to live improvisation using videotracking systems. Research areas of particular interest to meinclude modeling human methods of improvisation in inter-active computer systems and using data soni\\xef\\xac\\x81cation to illus-trate complex information [2].PROJECT BACKGROUND AND CONCEPTSome meteorologists call themselves \\xe2\\x80\\x9cstorm hunters.\\xe2\\x80\\x9d Theytravel  far  and  wide  and  take  considerable  physical  risk  in Andrea Polli (artist, educator), Department of Film and Media Studies',\n",
       " 'DOI: 10.1111/cgf.12366Eurographics Conference on Visualization (EuroVis) 2014H. Carr, P. Rheingans, and H. Schumann(Guest Editors)Volume 33 (2014), Number 3Distortion-Guided Structure-DrivenInteractive Exploration of High-Dimensional DataS. Liu1, B. Wang1, P.-T. Bremer2 and V. Pascucci11Scienti\\xef\\xac\\x81c Computing and Imaging Institute, University of Utah2Lawrence Livermore National LaboratoryAbstractDimension reduction techniques are essential for feature selection and feature extraction of complex high-dimensional data. These techniques, which construct low-dimensional representations of data, are typically ge-ometrically motivated, computationally ef\\xef\\xac\\x81cient and approximately preserve certain structural properties of thedata. However, they are often used as black box solutions in data exploration and their results can be dif\\xef\\xac\\x81cult tointerpret. To assess the quality of these results, quality measures, such as co-ranking [LV09], have been proposedto quantify structural distortions that occur between high-dimensional and low-dimensional data representations.Such measures could be evaluated and visualized point-wise to further highlight erroneous regions [MLGH13].In this work, we provide an interactive visualization framework for exploring high-dimensional data via its two-dimensional embeddings obtained from dimension reduction, using a rich set of user interactions. We ask thefollowing question: what new insights do we obtain regarding the structure of the data, with interactive manipula-tions of its embeddings in the visual space? We augment the two-dimensional embeddings with structural abstrac-tions obtained from hierarchical clusterings, to help users navigate and manipulate subsets of the data. We usepoint-wise distortion measures to highlight interesting regions in the domain, and further to guide our selection ofthe appropriate level of clusterings that are aligned with the regions of interest. Under the static setting, point-wisedistortions indicate the level of structural uncertainty within the embeddings. Under the dynamic setting, on-the-\\xef\\xac\\x82y updates of point-wise distortions due to data movement and data deletion re\\xef\\xac\\x82ect structural relations amongdifferent parts of the data, which may lead to new and valuable insights.1. IntroductionHigh-dimensional data arise naturally in many scienti\\xef\\xac\\x81c ap-plications and real-world phenomena. For instance, in ajet \\xef\\xac\\x82ame combustion simulation, half a million samples ofchemical composition are extracted point-wi',\n",
       " 'MUSE: A Musical Data Sonification ToolkitSuresh K. Lodha, John Beahan,* Travis Heppe, Abigail Joseph, and Brett Zane-UlmanABSTRACTKeywords:INTRODUCTIONBACKGROUNDDepartment of Computer ScienceUniversity of California, Santa Cruz, CA 95064lodha@cse.ucsc.eduTel: (408)-459-3773Fax: (408)-459-4829Data sonification is the representation of data using sound.  Last year we presented a flexible, interactive and portable datasonification toolkit called LISTEN, that allows mapping of data to several sound parameters such as pitch, volume, timbreand duration [20].  One of the potential drawbacks of LISTEN is that since the sounds generated are non-musical, they canbe fatiguing when exploring large data sets over extended periods of time.  A primary goal in the design of MUSE -- aMUsical Sonification Environment -- is to map scientific data to musical sounds.  The challenge is to ensure that the datameanings are preserved and brought out by these mappings.  MUSE provides flexible data mappings to musical soundsusing parameters such as pitch (melody), rhythm, tempo, volume, timbre and harmony.  MUSE is written in C++ for theSGI platform and works with the freely available sound specification software CSound developed at MIT.  We have appliedMUSE to map uncertainty in some scientific data sets to musical sounds. CSound, harmony, melody, music, rhythm, sonification, timbre.The usefulness of integrating sound into visualization systems is well-recognized [13].  Several examples of applyingsonification to scientific data analysis in diverse disciplines such as chemical analysis, economic analysis, analysis ofalgorithms, seismology, and computational fluid dynamics have been reported [8].  However, most sonification systemscurrently use pre-recorded patterns or simple synthesized sounds, which can become irritating or fatiguing due to theirunchanging nature.  This makes it difficult to explore large data sets or small data sets over extended periods of time usingsonification.In this work, we present MUSE -- MUsical Sonification Environment -- for sonifying data.  MUSE generates musical andengaging sounds allowing interactive and flexible mapping of data to six different sound parameters -- timbre, rhythm,volume, pitch (melody), tempo and harmony.In this work, we use sound in conjunction with visualization.  An excellent discussion of the benefits of this approach canbe found in Kramer [14].Although several sonification systems have been proposed [2, 3, 11, 17, 16, 15] that c',\n",
       " '\\x0c',\n",
       " 'INVISIBLE COMPUTINGINVISIBLE  COMPUTINGActivity Recognition for the Mind: Toward a Cognitive \\xe2\\x80\\x9cQuantified Self\\xe2\\x80\\x9dKai Kunze, Masakazu Iwamura, and  Koichi Kise, Osaka Prefecture UniversitySeiichi Uchida, Kyushu University Shinichiro Omachi, Tohoku University Applying mobile sensing technology to cognitive tasks will enable novel forms of activity recognition.  Physica l  activit y  recognition t e c h n o l o g y   h a s   b e c o m e mainstream\\xe2\\x80\\x94many  dedicated mobile  devices  and  smartphone apps count the steps we climb or the miles we run. What if devices and apps were also available that could  count  the  words  we  read and how far we\\xe2\\x80\\x99ve progressed in our learning? The authors of this article  demonstrate  that  mobile eye tracking can be used to do just that. Focusing on reading habits, they\\xe2\\x80\\x99ve  protot yped  cognitive activity recognition systems that monitor what and how much users read  as  well  as  how  much  they understand. Such systems could revolutionize teaching, learning, and assessment both inside and outside  the  classroom.  Further, as sensing technology improves, activity  recognition  could  be extended to other cognitive tasks including concentrating, retaining information, and auditory or visual processing. While this research is extremely exciting, it also raises numerous ethical questions\\xe2\\x80\\x94for example, who should know what we read or how much we understand?Albrecht Schmidt, column editorP eople increasingly use mobile computing technology to track their health and fitness progress, from simple step counting to monitoring food intake to measuring how long and well they sleep. Smartphone applications such as RunKeeper (http://runkeeper.com) and Lose It! (www.loseit.com) and wearable devices such as the Fitbit FLEX wristband (www.fitbit.com) foster better eating and exercise habits, decrease the risk of obesity-related diseases, and improve quality of life.  Activity-tracking abilities are still hampered by the limited battery power of today\\xe2\\x80\\x99s mobile devices, but emerging technologies such as the M7 motion-sensing coprocessor in the new iPhone 5s make it easier to aggregate and interpret sensor data in a power-efficient manner. In addition, while most activity-recognition apps continue to focus on physical movement, such as steps taken or stairs climbed, new products such as Withings Pulse (www.withings.com/en/pulse) also quantify physiological signals such as heart rate.Given these trends, it\\xe2\\x80\\x99s only a matter of time bef',\n",
       " 'An Empirical Study on Using Visual Metaphors in VisualizationR. Borgo, A. Abdul-Rahman, F. Mohamed, P. W. Grant, I. Reppa, L. Floridi, M. ChenAbstract\\xe2\\x80\\x94In written and spoken communications, metaphors are often used as an aid to help convey abstract or less tangibleconcepts. However, the bene\\xef\\xac\\x81ts of using visual metaphors in visualization have so far been inconclusive.In this work, we reportan empirical study to evaluate hypotheses that visual metaphors may aid memorization, visual search and concept comprehension.One major departure from previous metaphor-related experiments in the literature is that we make use of a dual-task methodologyin our experiment. This design offers an abstraction of typical situations where viewers do not have their full attention focused onvisualization (e.g., in meetings and classes). The use of the secondary task introduces \\xe2\\x80\\x9cdivided attention\\xe2\\x80\\x9d, and makes the effects ofvisual metaphors more observable. In addition, it also serves as additional masking in memory-based trials. The results of this studyshow that visual metaphors can help participants better remember the information depicted in visualization. On the other hand, visualmetaphors can have a negative impact on the speed of visual search. The results also show a complex pattern as to the bene\\xef\\xac\\x81ts ofvisual metaphors in helping participants grasp key concepts from visualization.Index Terms\\xe2\\x80\\x94Visual metaphors, icons, cognition, working memory, long-term memory, visual search, evaluation.1 INTRODUCTIONVisual metaphors are a form of non-linguistic metaphors and can beseen frequently in the visual arts, performing arts, advertisements,icons and signs, culture symbols, color symbolism, graphical user in-terface, and so forth. Ortony suggests that metaphors may aid commu-nication and thought processes through compactness, vividness andinexpressibility [30]. In terms of visual metaphors, compactness fa-cilitates the transfer of human \\xe2\\x80\\x9cexperience from well-known to lesswell-known contexts\\xe2\\x80\\x9d, vividness \\xe2\\x80\\x9cimpresses a more memorable learn-ing\\xe2\\x80\\x9d and understanding, and inexpressibility enables conveying \\xe2\\x80\\x9cextrameanings\\xe2\\x80\\x9d that are dif\\xef\\xac\\x81cult to encode in a language [40]. Naturally,one cannot help but wonder whether these three features of visualmetaphor can be transferred to positive effects in visualization, for ex-ample, to improve cognitive processes for memorization, visual searchand concept grasping as illustrated in Fig. 1.In written and spoken communications, metap',\n",
       " 'Beyond Mouse and Keyboard: Expanding Design Considerations for Information Visualization Interactions Bongshin Lee, Petra Isenberg, Nathalie Henry Riche, and Sheelagh Carpendale Abstract\\xe2\\x80\\x94The  importance  of  interaction  to  Information  Visualization  (InfoVis)  and,  in  particular,  of  the  interplay  between interactivity and cognition is widely recognized [12, 15, 32, 55, 70]. This interplay, combined with the demands from increasingly large  and  complex  datasets,  is  driving  the  increased  significance  of  interaction  in  InfoVis.  In  parallel,  there  have  been  rapid advances in many facets of interaction technologies. However, InfoVis interactions have yet to take full advantage of these new possibilities in interaction technologies, as they largely still employ the traditional desktop, mouse, and keyboard setup of WIMP (Windows,  Icons,  Menus,  and  a  Pointer)  interfaces.  In  this  paper,  we  reflect  more  broadly  about  the  role  of  more  \\xe2\\x80\\x9cnatural\\xe2\\x80\\x9d interactions  for  InfoVis  and  provide  opportunities  for  future  research.  We  discuss  and  relate  general  HCI  interaction  models  to existing InfoVis interaction classifications by looking at interactions from a novel angle, taking into account the entire spectrum of interactions.  Our  discussion  of  InfoVis-specific  interaction  design  considerations  helps  us  identify  a  series  of  underexplored attributes of interaction that can lead to new, more \\xe2\\x80\\x9cnatural,\\xe2\\x80\\x9d interaction techniques for InfoVis. Index Terms\\xe2\\x80\\x94Design considerations, interaction, post-WIMP, NUI (Natural User Interface). INTRODUCTION 1 The importance of interaction to Information Visualization (InfoVis) and, in particular, of the interplay between interactivity and cognition is  widely  recognized  [12,  15,  32,  55,  70].  Interaction  particularly rises in significance in InfoVis as we engage with increasingly large and complex datasets. Many tasks on visualized data can no longer be  completed  using  static  images  alone.  As  a  consequence, information workers request more and more interactive data analysis instruments  [18].  In  addition,  a  general  audience  is  beginning  to create  visualizations  using  data  of  their  own  interest  [49,  72,  80]. The  creation  of  visualizations  and  the  exploration  of  data  have  a number  of  dedicated  underlying  interaction  requirements  causing challenges that visualization research is just beginning to address. In  parallel',\n",
       " 'Original articledoi: 10.1111/j.1365-2729.2006.00219.xThe effect of animation on comprehensionand interestS. Kim,* M. Yoon,\\xe2\\x80\\xa0 S.-M. Whang,\\xe2\\x80\\xa1 B. Tversky\\xc2\\xa7 & J.B. Morrison\\xc2\\xb6*Department of Education, Korea University, Seoul, Korea\\xe2\\x80\\xa0Department of Teacher Education, Jeonju, Korea, Jeonju University\\xe2\\x80\\xa1Department of Psychology, Seoul, Korea, Yonsei University\\xc2\\xa7Department of Human Development, New York, USA, Columbia University\\xc2\\xb6Department of Psychology, Alendale, USA, Glendale Community CollegeAbstractAlthough animations are believed to be effective in learning and teaching, several studies havefailed to con\\xef\\xac\\x81rm this. Nevertheless, animations might be more attractive and motivating.Fourth and sixth grade students learned the operation of a bicycle pump from graphics thatwere: (i) presented simultaneously; (ii) presented successively; (iii) self-paced, or (iv)animated. The presentation mode affected evaluation of perceived comprehensibility, interest-ingness, enjoyment and motivation, but not comprehension test score. Fourth graders who werelow in need for cognition rated the animations as more enjoyable and motivating, whereas sixthgraders rated self-paced graphics as more interesting and motivating. The evaluations of sixthgraders correspond to results of many studies on learning. Animations are not more effectivethan equivalent static graphics in learning, and they are not seen as more motivating by sixthgraders.Keywordsanimation, comprehension,graphics.interest, need for cognition, self-paced presentation, staticThe effect of animation on learningAs multimedia and computer graphic technology havedeveloped and become widely available, animationshave been increasingly incorporated into learningmaterials. Both researchers and educational practitio-ners have believed that animation would facilitatelearning. Reasoning a priori, animations are more real-istic for showing change; they can demonstrate in actionthe systems to be taught. Because animations can showchange in time, they are thought to be natural and effec-tive for conveying change in time (Nielsen 1995;Tversky et al. 2002).Accepted: 25 October 2006Correspondence: Sung-il Kim, Department of Education, KoreaUniversity, 1, 5-Ka, Anam-Dong, Sungbuk-Ku, Seoul 136-701, Korea.Email: sungkim@korea.ac.krSeveral studies have compared animated graphicswith static graphics directly. Some have claimed thatstudents learning from animated graphics outperformedthose learning from static graphics, for example, forunder',\n",
       " 'DONNORMANR E V I S E D   &   E X PA N D E D    E D I T I O NThe DESIGN of EEVVEERRYYDDAAYY  TTHHIINNGGSSThe  DESIGNof EVERYDAYTHINGSDONNORMANBUSINESS / PSYCHOLOGY\\xe2\\x80\\x9cPart operating manual for designers and part manifesto on the power of designing for people, The Design of Everyday Things is even more relevant today than it was when \\xef\\xac\\x81 rst published.\\xe2\\x80\\x9d   \\xe2\\x80\\x94TIM BROWN, CEO, IDEO, and author of Change by DesignEven the smartest among us can feel inept as we try to \\xef\\xac\\x81 gure out the shower control in a hotel or attempt to navigate an unfamiliar television set or stove. When The Design of Everyday Things was published in 1988, cognitive scientist Don Norman provocatively proposed that the fault lies not in ourselves but in design that ignores the needs and psychology of people. Alas, bad design is everywhere, but fortunately, it isn\\xe2\\x80\\x99t di(cid:29)  cult to design things that are understandable, usable, and enjoyable. Thoughtfully revised to keep the timeless principles of psychology up to date with ever-changing new technologies, The Design of Everyday Things is a powerful appeal for good design, and a reminder of how\\xe2\\x80\\x94and why\\xe2\\x80\\x94some products satisfy while others only disappoint.\\xe2\\x80\\x9cDesign may be our top competitive edge. This book is a joy\\xe2\\x80\\x94fun and of the utmost importance.\\xe2\\x80\\x9d\\xe2\\x80\\x94TOM PETERS, author of In Search of Excellence\\xe2\\x80\\x9cThis book changed the \\xef\\xac\\x81 eld of design. As the pace of technological change accelerates, the principles in this book are increasingly important. The new examples and ideas   about design and product development make it essential reading.\\xe2\\x80\\x9d              \\xe2\\x80\\x94PATRICK WHITNEY, Dean, Institute of Design, and Steelcase/Robert C. Pew      Professor of Design, Illinois Institute of Technology\\xe2\\x80\\x9cNorman enlightened me when I was a student of psychology decades ago and he continues to inspire me as a professor of design. The cumulated insights and wisdom of the cross- disciplinary genius Donald Norman are a must for designers and a joy for those who are interested in artifacts and people.\\xe2\\x80\\x9d        \\xe2\\x80\\x94CEES DE BONT, Dean, School of Design, and Chair Professor of Industrial Design, The Hong Kong Polytechnic UniversityDON NORMAN is a co-founder of the Nielsen Norman Group, and holds graduate degrees in both engineering and psychology. His many books include Emotional Design, The Design of Future Things, and Living with Complexity. He lives in Silicon Valley, California.W W W.JND.ORGCover design by Nicole CaputoCover image:  Jacques Carelman \\xe2\\x80\\x9cCo(cid',\n",
       " '\\x0c',\n",
       " 'Guidelines for Using Multiple Views in Information Visualization Michelle Q. Wang Baldonado, Allison Woodruff Xerox Pale Alto Research Center 3333 Coyote Hill Road Pale Alto, CA 94304 USA +1 650 812 4797, +1 650 812 4429 { michelle, woodruff} @parc.xerox.com Allan Kuchinsky Hewlett Packard Laboratories 1501 Page Mill Road Pale Alto, CA 94304 USA +1 650 857 7423 kuchinsk@ hpl.hp.com ABSTRACT A multiple view system uses two or more distinct views to support the investigation of a single conceptual entity. Many such systems exist, ranging from computer-aided design (CAD) systems for chip design that display both the logical structure and the actual geometry of the integrated circuit to overview-plus-detail systems that show both an overview for context and a zoomed-in-view for detail. Designers of these systems must make a variety of design decisions, ranging from determining layout to constructing sophisticated coordination mechanisms. Surprisingly, little work has been done to characterize these systems or to express guidelines for their design. Based on a workshop discussion of multiple views, and based on our own design and implementation experience with these systems, we present eight guidelines for the design of multiple view systems. Keywords Multiple views, information visualization, design guidelines, usability heuristics, user interfaces INTRODUCTION Multiple view systems--systems that use two or more distinct views to support the investigation of a single conceptual entity--are both common and useful [6,12,16,20,27,28,29,30]. Neurophysiologists at the University of Pittsburgh Medical Center [25] recognized the value of multiple views when they considered extending a multimedia system to support the task of identifying seizures in infants. These seizures are very subtle events and it is difficult to identify seizure activity Permission to make digital or hand copie of all or part of this work for personal or classroom use is granted without fee provi- d~-~l that copies are not made or distributed for profit or commer- cial advantage, and that copies bear this notice and the full cita- tion on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requiresprior specific permis- sion and/or a fee. AVI 2000, Palermo, Italy. \\xc2\\xa9 2000 ACM 1-58113-252-2/00/0005..$5.00 using a single source of data. Their conclusion was that the identification process would be significantly improved by simultaneous review of physiol',\n",
       " 'Applying Quanti\\xef\\xac\\x81ed Self Approaches to Support Re\\xef\\xac\\x82ectiveLearningVer\\xc3\\xb3nica Rivera-Pelayo, Valentin Zacharias, Lars M\\xc3\\xbcller, and Simone BraunFZI Research Center for Information TechnologiesHaid-und-Neu Str. 10-14, Karlsruhe, Germanyrivera@fzi.de, zach@fzi.de, lmueller@fzi.de, braun@fzi.deABSTRACTThis paper presents a framework for technical support ofre\\xef\\xac\\x82ective learning, derived from a uni\\xef\\xac\\x81cation of re\\xef\\xac\\x82ectivelearning theory with a conceptual framework of Quanti\\xef\\xac\\x81edSelf tools \\xe2\\x80\\x93 tools for collecting personally relevant informa-tion for gaining self-knowledge. Re\\xef\\xac\\x82ective learning meansreturning to and evaluating past experiences in order to pro-mote continuous learning and improve future experiences.Whilst the re\\xef\\xac\\x82ective learning theories do not su\\xef\\xac\\x83ciently con-sider technical support, Quanti\\xef\\xac\\x81ed Self (QS) approaches arerather experimental and the many emergent tools are dis-connected from the goals and bene\\xef\\xac\\x81ts of their use. Thispaper brings these two strands into one uni\\xef\\xac\\x81ed frameworkthat shows how QS approaches can support re\\xef\\xac\\x82ective learn-ing processes on the one hand and how re\\xef\\xac\\x82ective learningcan inform the design of new QS tools for informal learningpurposes on the other hand.Categories and Subject DescriptorsJ.1 [Administrative Data Processing]: Education; K.3.1[Computer Uses in Education]: Collaborative learning,Computer-assisted instruction (CAI), Computer-managed in-struction (CMI), Distance learningGeneral TermsTheoryKeywordsRe\\xef\\xac\\x82ective learning, Quanti\\xef\\xac\\x81ed Self, Learning Analytics,Framework, Mobile applications1.INTRODUCTIONRe\\xef\\xac\\x82ection is becoming of relevance in the learning commu-nity and therefore re\\xef\\xac\\x82ective learning is being investigated inboth educational and work settings. According to Boud etal. [1], learning by re\\xef\\xac\\x82ection (or re\\xef\\xac\\x82ective learning) o\\xef\\xac\\x80ers thePermission to make digital or hard copies of all or part of this work forpersonal or classroom use is granted without fee provided that copies arenot made or distributed for pro\\xef\\xac\\x81t or commercial advantage and that copiesbear this notice and the full citation on the \\xef\\xac\\x81rst page. To copy otherwise, torepublish, to post on servers or to redistribute to lists, requires prior speci\\xef\\xac\\x81cpermission and/or a fee.LAK \\xe2\\x80\\x9912, 29 April - 2 May 2012, Vancouver, BC, Canada.Copyright 2012 ACM 978-1-4503-1111-3/12/04 ...$10.00.chance of learning by returning to and evaluating past workand personal experiences in order to improve future experi-ences and promote continuous learning.',\n",
       " 'Understanding Quantified-Selfers\\xe2\\x80\\x99 Practices in  Collecting and Exploring Personal Data  Eun Kyoung Choe1, Nicole B. Lee2, Bongshin Lee2, Wanda Pratt1, Julie A. Kientz1  1University of Washington  {eunky, wpratt, jkientz}@uw.edu 2Microsoft Corporation  {nilee, bongshin}@microsoft.com      ABSTRACT  Researchers  have  studied  how  people  use  self-tracking technologies and discovered a long list of barriers including  lack  of  time  and  motivation  as  well  as  difficulty  in  data  integration  and  interpretation.  Despite  the  barriers,  an  in-creasing number of Quantified-Selfers diligently track many  kinds  of  data  about  themselves,  and  some  of  them  share  their  best  practices  and  mistakes  through  Meetup  talks,  blogging,  and  conferences.  In  this  work,  we  aim  to  gain insights from these \\xe2\\x80\\x9cextreme users,\\xe2\\x80\\x9d who have used exist-ing technologies and built their own workarounds to over- come  different  barriers.  We  conducted  a  qualitative  and quantitative  analysis  of  52  video  recordings  of  Quantified Self  Meetup  talks  to  understand  what  they  did,  how  they did it, and what they learned. We highlight several common  pitfalls to self-tracking, including tracking too many things, not tracking triggers and context, and insufficient scientific  rigor.  We  identify  future  research  efforts  that  could  help  make  progress  toward  addressing  these  pitfalls.  We  also  discuss  how  our  findings  can  have  broad  implications  in  designing and developing self-tracking technologies.           Author Keywords  Quantified Self; self-monitoring; self-tracking; health; per-sonal informatics; personal analytics; self-experimentation.    ACM Classification Keywords  H.5.2. Information interfaces and presentation (e.g., HCI): User-centered design; J.3. Life and medical sciences: Health.        INTRODUCTION Although many people do not routinely track personal data, Quantified-Selfers  (Q-Selfers)  are  notable  exceptions  who diligently track many kinds of data about themselves. They are a diverse group of life hackers, data analysts, computer scientists,  early  adopters,  health  enthusiasts,  productivity Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for com-pone',\n",
       " 'Personal Tracking as Lived Informatics John Rooksby, Mattias Rost, Alistair Morrison, Matthew Chalmers  School of Computing Science,  University of Glasgow, UK. {john.rooksby, mattias.rost, alistair.morrison, matthew.chalmers}@glasgow.ac.uk   accelerometers  into  their  latest  high-end  mobile  devices. The advent of smart watches, smart glasses and other forms of  wearable  computing  in  the  consumer  domain  is  also likely  to  bring  further  innovation  and  proliferation  in  this area.  Personal  tracking  is,  however,  not  new.  People  have long been able to track and manage activities using diaries and/or  personal  computers.  Tracking  can  in  fact  be  traced back to at least Roman times (where trackers were used not as  personal  devices  but  for  measuring  the  mobility  of soldiers). However, with the popularity of smartphones and digital  devices  with  built  in  accelerometers  and  location services, the area of personal tracking appears to be one of great investment and growth.  Previous research in this area has predominantly focused on individual, researcher-supplied technologies. From a health research perspective, a tracker is either an instrument with which to measure activity, or an intervention to be applied across  a  cohort  of  people.  Standard  devices  are  used,  and often treated as invisible lenses on activity (e.g. [19, 21]). In health  research,  consumer trackers  are  usually  used, whereas evaluation in HCI is usually of a novel prototype (e.g.  [13,  10]).  In  HCI  the  devices  themselves  are  not treated invisibly but, as with health research, evaluation is predominantly of an individual technology and oriented to intervention. There is some research looking at integration of technologies, notably Bentley et al.\\xe2\\x80\\x99s [2] work on health mashups  for  behaviour  change.  Yet  even  here the researchers selected what the study participants should use. The  agency  of  the  people  using  such  technologies  is  too often denied; Maitland et al.\\xe2\\x80\\x99s [12] study of weight loss and Mamykina  et  al.\\xe2\\x80\\x99s  [14]  study  of  diabetes  management  are rare  exceptions.  They  point  out  that  people  choose,  use, interweave and abandon various technologies in their own, lived  efforts  to  improve  their  health.  They  found  people were not changing their behaviour because of a technology, but were using technology because they wanted to change.  What people decide to track using consumer products, what tracke',\n",
       " '\\x0c',\n",
       " 'Video Games for Collection Exploration: Games for and out of Data Repositories Amalia KallergiLIACS, Leiden UniversityNiels Bohrweg 1, 2333 CALeiden, The Netherlands+31 - (0)71 - 527 5777akallerg@liacs.nlFons J. VerbeekLIACS, Leiden University Niels Bohrweg 1, 2333 CALeiden, The Netherlands+31 - (0)71 - 527 5773fverbeek@liacs.nlABSTRACTIn this paper, we establish a link between video games and data collections. In particular, we examine video games as potential interfaces for collection exploration, i.e. as a platform for a more insightful   and   exploratory   interaction   with   a   repository. Furthermore,   we   question   if   a   more   structural   relationship between the game and the collection is possible: Can we produce video games based on the structure of a repository? We explore these ideas on theoretical grounds and by means of a prototype game developed as a case study for a scientific image repository.Categories and Subject DescriptorsH.5.2 [User Interfaces]: Graphical user interfaces (GUI).General TermsHuman Factors, Theory, ExperimentationKeywordsvideo games, data collections, data explorationGAMES FOR DATA REPOSITORIES: 1.GAMING AS EXPLORATIONIn most, well-maintained data collections there is a potential for discovery. Think of it: data collections create opportunities for processes that are considered stimulating for discovery, such as (serendipitous)   encounters   with   valuable   items   or   the establishment   of   insightful   associations   between   items.   But   if there are treasures to lie hidden in data repositories, what tools do we need to discover them? We believe that, in interacting with data in repositories, there is a need for interfaces that challenge and engage the user to explore. To this end, we propose video games and gaming as a suitable platform for an interaction for exploration. An   interaction   for   collection   exploration   differs   in   focus   and intention   from   regular   search   interfaces   to   collections.   In Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.MindTrek 2010, October 6th-October 8th 2010, Tampere, FINLAND.Copyright 201',\n",
       " 'Seeing Further: Extending Visualization as a Basis for Usable Security Jennifer Rode, Carolina Johansson\\xe2\\x80\\xa0, Paul DiGioia, Roberto Silva Filho, Kari Nies,  David H. Nguyen, Jie Ren, Paul Dourish, and David Redmiles Institute for Software Research University of California, Irvine Irvine, CA 92697-3425 \\xe2\\x80\\xa0Department of Information Technology Uppsala University Box 337, 751 05 Uppsala, Sweden {jen, cjohanss, pdigioia, rsilvafi, kari, dhn, jie, jpd, redmiles}@ics.uci.edu   ABSTRACT The  focus  of  our  approach  to  the  usability  considerations  of privacy  and  security  has  been  on  providing  people  with information  they  can  use  to  understand  the  implications  of  their interactions with a system, as well as, to assess whether or not a system is secure enough for their immediate needs.  To this end, we  have  been  exploring  two  design  principles  for  secure interaction: integrating configuration  and  action.  Here  we  discuss  the  results  of  a  user study designed as a broad formative examination of the successes and failures of an initial prototype based around these principles.  Our response to the results of this study has been twofold. First, we  have  fixed  a  number  of  implementation  and  usability problems.    Second,  we  have  extended  our  visualizations  to incorporate  new  considerations  regarding  the  temporal  and structural organization of interactions.  visualizing system activity and Categories and Subject Descriptors H.5.1 Information interfaces and presentation (e.g., HCI): General \\xe2\\x80\\x93  Evaluation/methodology;  K.4.4  General:  Computers  and Society \\xe2\\x80\\x93 Security General Terms Design, Experimentation, Security, Human Factors  Keywords Effective security, theoretical security, usable security, user study, dynamic  visualizations,  configuration  in  action,  peer-to-peer  file sharing, history, user and media characterization 1.  INTRODUCTION Although interest has been growing in the usability of privacy and security,  there  is  still  considerable  debate  over  what  topics  are actually  of  concern  here.  One  approach  (what  we call the \\xe2\\x80\\x9cstrict usability\\xe2\\x80\\x9d  approach)  applies  traditional  usability  measures  to individual  security  components  that  people  might  employ  in  the course  of  regular  computer  usage  (e.g.  passwords  and  other  Copyright  is  held  by  the  author/owner.  Permission  to  make  digital  or hard copies of all or part of this work for personal or classroom use is ',\n",
       " 'Personal Informatics in Chronic Illness Management Haley MacLeod1 Anthony Tang2 University of Calgary Sheelagh Carpendale3   ABSTRACT Many 1 people 2 with 3 chronic  illness  suffer  from  debilitating symptoms  or  episodes  that  inhibit  normal  day-to-day  function. Pervasive  tools  offer  the  possibility  to  help  manage  these conditions,  particularly  by  helping  people  understand their conditions. But, it is unclear how to design these tools, as prior designs  have  focused  on  effortful  tracking  and  many  see  those tools as a burden to use. We report here on an interview study with  12  individuals  with  chronic  illnesses  who  collect  personal data.  We  learn  that  these  people  are  motivated  through  self-discovery  and  curiosity.  We  explore  how  these  concepts  may support the design of tools that engage curiosity  and encourage self-discovery, rather than emphasize the behaviour change aspect of chronic illness management.  Keywords:  Personal  informatics,  Healthcare,  Chronic  disease management, Qualitative studies. Index  Terms:! H.5.m.  Information  interfaces  and  presentation INTRODUCTION (e.g., HCI): Miscellaneous. J.3 Life and Medical Sciences: Health, Medical information systems. 1 The  continuing  miniaturization  and  increasing  affordability  of sensors  and  electronic  devices  provide  tantalizing  opportunities for  pervasive  computing.  One  of  these  opportunities  is  in supporting  self-monitoring,  where  tools  have  been  designed  to help people understand and change their behaviour in the context of  wellness  [9,17,27],  eco-behaviour  [14],  and  chronic  illness management  [4,29,39].  These  kinds  of  tools  apply  principles  of cognitive  behaviour  therapy  [32]  and  goal  setting  theory  [22], where  a  core  tenet  is  that  people  may  misinterpret  their  actual behaviour relative to their own desired behaviour. By visualizing one\\xe2\\x80\\x99s actual behaviour relative to desired targets, these tools (e.g. [6,17,18,27]) aim to motivate behaviour change using elements of cognitive dissonance theory [12].  A prerequisite for this is effective data collection, and mobile devices (such as smartphones) offer the ability to collect data in a timely, in situ manner. This is especially important in the context of chronic illness management. People with chronic pain fill out paper-based \\xe2\\x80\\x9cpain diaries\\xe2\\x80\\x9d at the end of each day, trying to detail each incident of pain for the day, along with i',\n",
       " \"Using Shape to Visualize Multivariate Data Christopher D. Shaw, James A. Hall, Christine Blahut, David S. Ebert U. of Regina * U. of Maryland Baltimore County t D. Aaron Roberts NASA Goddard t Abstract This paper describes our recent findings in the area of using glyph shape to display one or two data dimensions in the visualization of 3D scalar and vector fields. In our glyph-based visualization system, each glyph represents a data point in 3D space. Visual attributes such as size, orientation, color and transparency can be mapped to data dimensions in the 3D space. We are exploring the use of glyph shape as a display dimension, using superquadric supereUipses as a means of supplying a parameterizable shape. A basic factor in effectively using shape for quantitative visualization is determining how many (and which) superellipse shapes people can distinguish. Since the superquadric shape's parameter set is not perceptually linear, we conducted a user study to which shapes people can generally distinguish. The findings show that with large superellipses, about 22 separate shapes can be distinguished on average. These results provide the foundation for exploring how effective superellipses may be in quantitative shape visualizaton. 1 Introduction Our goal is the visualization of complex informations spaces in the realm of traditional scientific visualization, and in the emerging field of information visualization. Our emphasis has been on glyph-based visualization, where each data item is represented by a small visual symbol or glyph 8, 9, 5. Glyphs have been successfully used to indicate flow, and they allow multiple data values to be encoded in their visual parameters. Glyph rendering is an extension to the use of glyphs and icons in numerous fields, including cartography, logic, and statistics. In this paper, We explore the perceptibility of glyph shapes gen- erated by superquardics 1 as a display mechanism. We have recently developed new techniques for automatic glyph shape gen- eration that allow perceptualization of data though shape variation. Cleveland 3 cites experimental evidence that shows the most ac- curate method to visually decode a quantitative variable in 2D is to *Department of Computer Science, University of Regina, Regina, Saskatchewan, Canada $4S 0A2, Phone: (306) 585-4071, email: cd- shaw@cs.uregina.ca, hallj @ cs.uregina.ca t Computer Science and Electrical Engineering Department, University of Maryland Baltimore County, 1000 Hilltop C\",\n",
       " 'Distributed Cognition: Toward a NewFoundation for Human-ComputerInteraction ResearchJAMES HOLLAN, EDWIN HUTCHINS, and DAVID KIRSHUniversity of California, San DiegoWe are quickly passing through the historical moment when people work in front of a singlecomputer, dominated by a small CRT and focused on tasks involving only local information.Networked computers are becoming ubiquitous and are playing increasingly significant rolesin our lives and in the basic infrastructures of science, business, and social interaction. Forhuman-computer interaction to advance in the new millennium we need to better understandthe emerging dynamic of interaction in which the focus task is no longer confined to thedesktop but reaches into a complex networked world of information and computer-mediatedinteractions. We think the theory of distributed cognition has a special role to play inunderstanding interactions between people and technologies, for its focus has always been onwhole environments: what we really do in them and how we coordinate our activity in them.Distributed cognition provides a radical reorientation of how to think about designing andsupporting human-computer interaction. As a theory it is specifically tailored to understand-ing interactions among people and technologies. In this article we propose distributedcognition as a new foundation for human-computer interaction, sketch an integrated researchframework, and use selections from our earlier work to suggest how this framework canprovide new opportunities in the design of digital work materials.Categories and Subject Descriptors: D.2.1 [Software Engineering]: Requirements/Specifica-tions\\xe2\\x80\\x94Methodologies (e.g., object-oriented, structured); H.1.2 [Models and Principles]:User/Machine Systems; H.5.2 [Information Interfaces and Presentation]: User Interfac-es\\xe2\\x80\\x94Evaluation/methodology; H.5.3 [Information Interfaces and Presentation]: Groupand Organization Interfaces\\xe2\\x80\\x94Theory and models; Evaluation/methodologyGeneral Terms: Design, Human Factors, TheoryAdditional Key Words and Phrases: Cognitive science, distributed cognition, ethnography,human-computer interaction, research methodologyThis work was supported by grant #9873156 from the National Science Foundation. Additionalsupport was provided by Intel, Sony, and Sun.Authors\\xe2\\x80\\x99 address: Distributed Cognition and HCI Laboratory, Department of CognitiveScience, University of California, San Diego, La Jolla, CA 92093-0515; email:{hollan;hutchins; kirsh}@hci.ucsd.e',\n",
       " 'Highlighting Interventions and User Differences:            Informing Adaptive Information Visualization Support Giuseppe Carenini, Cristina Conati, Enamul Hoque, Ben Steichen, Dereck Toker, James Enns*1 Department of Computer Science, *Department of Psychology University of British Columbia, Vancouver, Canada {carenini, conati, enamul, steichen, dtoker}@cs.ubc.ca, jenns@psych.ubc.ca  ABSTRACT There  is  increasing  evidence  that  the  effectiveness  of information visualization techniques can be impacted by the particular  needs  and  abilities  of  each  user.  This  suggests that it is important to investigate information visualization systems  that  can  dynamically  adapt  to  each  user.  In  this paper,  we  address  the  question  of  how  to  adapt.  In particular, we present a study to evaluate a variety of visual prompts, called \\xe2\\x80\\x98interventions\\xe2\\x80\\x99, that can be performed on a visualization to help users process it.  Our results show that some  of  the  tested  interventions  perform  better  than  a condition  in  which  no  intervention  is  provided,  both  in terms of task performance as well as subjective user ratings. We also discuss findings on how intervention effectiveness is influenced by individual differences and task complexity. Author Keywords User characteristics, Adaptive Information Visualization. ACM Classification Keywords H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous. INTRODUCTION Recent advances in visualization research have shown that individual user needs, abilities and preferences can have a significant  impact  on  user  performance  and  satisfaction during  visualization  usage  (e.g.,  [6][14][19][33]).  It  is therefore  important  to  investigate  the  potential  of  user-adaptive  visualizations,  i.e.,  visualization  techniques  and systems  that  support  the  provision  of  visual  information personalized to each user\\xe2\\x80\\x99s needs and differences. The benefits of user-adaptive interaction have been shown in  a  variety  of  human-computer  interaction  tasks  and applications  such  as  operation  of  menu  based  interfaces, web  search,  desktop  assistance,  and  human  learning  [22]. There  are  three  key  decisions  that  need  to  be  made  when designing a user-adaptive system: (1) what to adapt to, i.e., understanding which user features should be considered for adaptation,  including  stable,  long-term  user  traits  (e.g., Permission to make digital or hard copies of all ',\n",
       " 'Critical Design and Realization Aspectsof Glyph-based 3D Data VisualizationAndreas E. Lie\\xe2\\x88\\x97University of BergenNorway, www.ii.UiB.no/visJohannes Kehrer\\xe2\\x80\\xa0University of BergenNorway, www.ii.UiB.no/visHelwig Hauser\\xe2\\x80\\xa1University of BergenNorway, www.ii.UiB.no/vis(a) Two data attributes are representedas the upper / lower glyph shape(b) Added data attribute to overallglyph size(c) Glyph rotation has been assigneda data attribute as well(d) A data attribute has been assignedto glyph aspect ratioFigure 1: Adding more attributes to the glyph, while preserving the glyph\\xe2\\x80\\x99s orthogonality.AbstractGlyphs are useful for the effective visualization of multi-variatedata. They allow for easily relating multiple data attributes to eachother in a coherent visualization approach. While the basic princi-ple of glyph-based visualization has been known for a long time,scienti\\xef\\xac\\x81c interest has recently increased focus on the question ofhow to achieve a clever and successful glyph design. Along thisnewer trend, we present a structured discussion of several criticaldesign aspects of glyph-based visualization with a special focus on3D data. For three consecutive steps of data mapping, glyph instan-tiation, and rendering, we identify a number of design considera-tions. We illustrate our discussion with a new glyph-based visual-ization of time-dependent 3D simulation data and demonstrate howeffective results are achieved.Keywords: Glyphs, Multi-variate, Simulation, Glyph Design, Vi-sualization1 IntroductionIn scienti\\xef\\xac\\x81c projects as well as in commercial applications we seean increased utilization of computational simulation for the investi-gation of natural phenomena. Compared to earlier years, current\\xe2\\x88\\x97e-mail: Andreas.Lie@student.uib.no\\xe2\\x80\\xa0e-mail: Johannes.Kehrer@uib.no\\xe2\\x80\\xa1e-mail: Helwig.Hauser@uib.noCopyright \\xc2\\xa9 2009 by the Association for Computing Machinery, Inc. Permission  to  make  digital  or  hard  copies  of  part  or  all  of  this  work  for  personal  or classroom use is granted without fee provided that copies are not made or distributed for commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers,  or  to  redistribute  to  lists,  requires  prior  specific  permission  and/or  a  fee. Request permissions from Permissions Dept, ACM Inc., fax +1 (212) 869-0481 o',\n",
       " 'Evaluating Bag-of-Visual-Words Representations in SceneClassi\\xef\\xac\\x81cationJun YangSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213juny@cs.cmu.eduAlexander G. HauptmannSchool of Computer ScienceCarnegie Mellon UniversityPittsburgh, PA 15213alex@cs.cmu.eduABSTRACTBased on keypoints extracted as salient image patches, animage can be described as a \\xe2\\x80\\x9cbag of visual words\\xe2\\x80\\x9d and thisrepresentation has been used in scene classi\\xef\\xac\\x81cation. Thechoice of dimension, selection, and weighting of visual wordsin this representation is crucial to the classi\\xef\\xac\\x81cation per-formance but has not been thoroughly studied in previouswork. Given the analogy between this representation andthe bag-of-words representation of text documents, we ap-ply techniques used in text categorization, including termweighting, stop word removal, feature selection, to generateimage representations that di\\xef\\xac\\x80er in the dimension, selection,and weighting of visual words. The impact of these repre-sentation choices to scene classi\\xef\\xac\\x81cation is studied throughextensive experiments on the TRECVID and PASCAL col-lection. This study provides an empirical basis for designingvisual-word representations that are likely to produce supe-rior classi\\xef\\xac\\x81cation performance.Categories and Subject DescriptorsH.3.3 [Information Storage and Retrieval]: InformationSearch and RetrievalGeneral TermsExperimentation, PerformanceKeywordsscene classi\\xef\\xac\\x81cation, keypoint, local interest point, bag-of-visual-wordsPermission to make digital or hard copies of all or part of this work forpersonal or classroom use is granted without fee provided that copies arenot made or distributed for pro\\xef\\xac\\x81t or commercial advantage and that copiesbear this notice and the full citation on the \\xef\\xac\\x81rst page. To copy otherwise, torepublish, to post on servers or to redistribute to lists, requires prior speci\\xef\\xac\\x81cpermission and/or a fee.MIR\\xe2\\x80\\x9907, September 28\\xe2\\x80\\x9329, 2007, Augsburg, Bavaria, Germany.Copyright 2007 ACM 978-1-59593-778-0/07/0009 ...$5.00.Yu-Gang JiangDept of Computer ScienceCity University of Hong KongKowloon, Hong Kongyjiang@cs.cityu.edu.hkChong-Wah NgoDept of Computer ScienceCity University of Hong KongKowloon, Hong Kongcwngo@cs.cityu.edu.hk1.INTRODUCTIONClassifying images or video scenes into semantic categoriesis a problem of great interest in both research and prac-tice. For example, an online collection of photos needs tobe grouped into categories like \\xe2\\x80\\x9clandscape\\xe2\\x80\\x9d, \\xe2\\x80\\x9cportrait\\xe2\\x80\\x9d, and\\xe2\\x80\\x9canimal\\xe2\\x80\\x9d to support e\\xef',\n",
       " ' Personal Informatics and Reflection:  A Critical Examination of the Nature  of Reflection   Afarin Pirzadeh School of Informatics-IUPUI, Indiana University, Indianapolis, IN 46202 USA  apirzade@iupui.edu  Li He School of Informatics-IUPUI, Indiana University, Indianapolis, IN 46202 USA  lh6@iupui.edu  Erik Stolterman School of Informatics and Computing-Bloomington, Indiana University, Bloomington, IN 47408 USA estolter@indiana.edu  Permission  to make  digital or  hard  copies of  all or  part  of  this work  forpersonal or classroom use is granted without fee provided that copies arenot  made  or  distributed  for  profit  or  commercial  advantage  and  thatcopies  bear  this  notice  and  the  full  citation  on  the  first  page.  To  copyotherwise,  or  republish,  to  post  on  servers  or  to  redistribute  to  lists,requires prior specific permission and/or a fee. CHI 2013 Extended Abstracts, April 27\\xe2\\x80\\x93May 2, 2013, Paris, France. Copyright \\xc2\\xa9 2013 ACM 978-1-4503-1952-2/13/04...$15.00. Abstract Personal informatics systems that help people both collect and reflect on various kinds of personal information are growing rapidly. Despite the importance of journaling and the main role it has in tracking one\\xe2\\x80\\x99s personal growth, a limited number of studies have examined journaling in the area of personal informatics in detail. In this paper, we critically examine the process of reflection on experiences, thoughts and evolving insights through a qualitative research study. We also present the design research process we conducted to develop the Wandering Mind as a support tool to help individuals record and reflect on their experiences. Author Keywords Personal informatics; reflection; journaling ACM Classification Keywords H5.2 [Information interfaces and presentation]: User Interfaces. \\xe2\\x80\\x93 User-centered design; J.4 [Social and behavioral science]: Psychology Introduction Reflecting on oneself is an ongoing quest through life. Most of us spend time daily reflecting on who we are, what we have done, our experiences and expectations. In many cases we do this based on what we remember alt.chi: Reflection and EvaluationCHI 2013: Changing Perspectives, Paris, France1979\\x0c',\n",
       " 'A case study inside Virtual Worlds:  use of analytics for immersive spaces Vanessa Camilleri University of Malta Faculty of Education Malta 00356 23403413 vanessa.camilleri@um.edu.mt   Matthew Montebello University of Malta Faculty of ICT Malta 00356 23402132 matthew.montebello@um.edu.mt  Sara de Freitas Serious Games Institute University of Coventry UK 0044 24 7615 8208 SFreitas@cad.coventry.ac.uk Paul McDonagh-Smith Avaya House, Guildford AvayaLive Engage   UK 0044 1483 309291 paulmcsm@avaya.com ABSTRACT In this paper we describe some case studies of the use of virtual worlds  in  corporate  training  as  well  as  Higher  Education.  In particular  for  Higher  Education  we  describe  how  the  Virtual World constructed using the platform Avaya Live Engage, is used as an immersive environment with pre-service teachers, who are undergoing  a  1-year  teacher  training  program,  and  how  the  data analytics  collected  in-world  is  being  used  to  monitor  and  direct content  development.  We  focus  our  studies  on  the  initial hypothesis that 3D immersive environments are highly engaging and offer an experience that goes beyond the \\xe2\\x80\\x98traditional\\xe2\\x80\\x99 online education. We want to combine different analysis methods to be able to get empirical evidence showing the students\\xe2\\x80\\x99 engagement with the 3D space in ways that  can help us in the design of the learning experience accompanying the learners in their journey. In this paper we describe the research methods we use for the study, and give an overview of the information we can collect from the in-world  analytics.  We  also  propose  how  these  analytics  can  be used  for  a  predictive  model  with  the  intention  of  refocusing  the virtual world experience to match learner needs.  General Terms Measurement,  Documentation,  Design,  Experimentation,  Human Factors. Keywords Virtual Worlds, Pre-service teachers, Higher Education, Corporate Training, data analytics. 1.  INTRODUCTION Virtual Worlds (VWs) have been described as 3D representations  Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not  made  or  distributed  for  profit  or  commercial  advantage  and  that copies bear this notice and the full citation on the first page. Copyrights for  components  of  this  work  owned  by  others  than  ACM  must  be honored.  Abstracting  with  credit  is  permitted.  To  copy  otherwise,  to republ',\n",
       " 'MyLifeBits: Fulfilling the Memex VisionJim Gemmell, Gordon Bell, Roger Lueder, Steven Drucker and Curtis Wong Microsoft Research 455 Market St., #1690 San Francisco, CA, 94105 {jgemmell,gbell,rlueder,sdrucker,wong}@microsoft.comABSTRACTMyLifeBits is a project to fulfill the Memex vision first posited by Vannevar Bush in 1945. It is a system for storing all of one\\xe2\\x80\\x99s digital media, including documents, images, sounds, and videos. It is built on four principles: (1) collections and search must replace hierarchy for organization (2) many visualizations should be supported (3) annotations are critical to non-text media and must be made easy, and (4) authoring should be via transclusion.Categories and Subject DescriptorsH.3.0 [Information Storage and Retrieval]: General H.5.4 [Information Interfaces and Presentation]: Hypertext/ Hypermedia \\xe2\\x80\\x93 Architectures, Navigation, User issues  General TermsManagement, Design, Human Factors. KeywordsMemex, hypermedia, annotation, multimedia, database. 1. INTRODUCTIONIn  1945,  Vannevar  Bush  posited  Memex:  \\xe2\\x80\\x9ca  device  in  which  an individual stores all his books, records, and communications, and which  is  mechanized  so  that  it  may  be  consulted  with exceeding speed  and  flexibility\\xe2\\x80\\x9d  [2].  Bush  did  not  foresee  the  exact technology to accomplish this, but he correctly foresaw two of the fundamental  features:  annotation  and  links.  The  MyLifeBits project  is  an  effort  to  implement  a  personal  digital  store.  It  is Memex,  extended  beyond  Bush\\xe2\\x80\\x99s  vision  to  handle  audio  and video,  to  perform  database  style  queries,  and  to  allow  multiple visualizations in the user interface. Bush posited an era of virtually unlimited storage: \\xe2\\x80\\x9cyet if the user inserted 5000 pages of material a day it would take him hundreds of  years  to  fill  the  repository,  so  that  he  can  be  profligate  and enter material freely.\\xe2\\x80\\x9d In 2002, such abundant storage is finally on the  horizon.  Within  five  years,  terabyte  hard  drives  will  be common and inexpensive (<$300). Thus, purchasing an additional terabyte  of  personal  storage  every  year  will  be  feasible  for  the average  computer  user.  It  turns  out  that  filling  a  terabyte  is  not Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for personal  or  classroom  use is granted without fee provided that copies are Permission to make digital or hard copies of all or part of this work for not mad',\n",
       " '   StepCity: A Preliminary Investigation Of A Personal Informatics-Based Social Game On Behavior Change  Greg Walsh Digital Whimsy Lab University of Baltimore 1420 N Charles St Baltimore, MD 21201 gwalsh@ubalt.edu  Jenifer Golbeck HCIL/UMIACS  University of Maryland  2117 Hornbake Bldg, South Wing College Park, MD 20742 golbeck@cs.umd.edu   Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the Owner/Author.   Copyright is held by the owner/author(s).  CHI 2014, Apr 26 - May 01 2014, Toronto, ON, Canada ACM 978-1-4503-2474-8/14/04. http://dx.doi.org/10.1145/2559206.2581326 Abstract Encouraging physical activity is an important public health issue. In this study, we set out to see if a game could be used to motivate people to be more active. We recruited 74 subjects to wear Fitbits \\xe2\\x80\\x93 a personal activity monitoring device that tracked the number of steps taken in a day \\xe2\\x80\\x93 and compared step totals in three experimental conditions: a control, a social interaction experience, and a social game we developed called StepCity. We found that for newer Fitbit users, the game led to users taking more steps than they did in a control condition. In this poster, we present the details of our system and the results of a controlled experiment.  Author Keywords Fitbit; exercise; games; gamification; serious games; games with a purpose ACM Classification Keywords H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous. INTRODUCTION A Fitbit is a wireless activity tracker that tracks a user\\xe2\\x80\\x99s steps (along with other information, depending on the Work-in-ProgressCHI 2014, One of a CHInd, Toronto, ON, Canada2371\\x0c',\n",
       " '   Personal Informatics and HCI: Design, Theory, and Social ImplicationsKristina H\\xc3\\xb6\\xc3\\xb6k Mobile Life Stockholm University 164 40 Kista, Sweden kia@sics.se  Yevgeniy Medynskiy GVU Center Georgia Institute of Technology Atlanta, GA 30332 USA eugenem@gatech.edu  Ian Li HCII Carnegie Mellon University Pittsburgh, PA 15213 USA ianli@cmu.edu  Anind Dey HCII Carnegie Mellon University Pittsburgh, PA 15213 USA anind@cs.cmu.edu  Jodi Forlizzi HCII Carnegie Mellon University Pittsburgh, PA 15213 USA forlizzi@cs.cmu.edu Copyright is held by the author/owner(s). CHI 2011, May 7\\xe2\\x80\\x9312, 2011, Vancouver, BC, Canada. ACM  978-1-4503-0268-5/11/05. Abstract Personal informatics is a class of systems that help people collect personal information to improve self-knowledge. The development of personal informatics applications poses new challenges in human-computer interaction and creates opportunities for collaboration between diverse disciplines, including design, ubiquitous computing, persuasive technology and information visualization. This workshop will continue the conversation from the CHI 2010 workshop [6] and extend the discussion of personal informatics to include behavioral theories that can guide the development of such systems, as well as the social implications of self-tracking. Keywords Personal informatics, reflection, awareness, behavior, life logging, visualizations, study methods ACM Classification Keywords H5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous. General Terms Design, Experimentation, Human Factors CHI 2011 \\xe2\\x80\\xa2 WorkshopMay 7\\xe2\\x80\\x9312, 2011 \\xe2\\x80\\xa2 Vancouver, BC, Canada2417\\x0c',\n",
       " 'A Mobile Personal Informatics System with InteractiveVisualizations of Mobility and Social InteractionsAndrea CuttoneTech. University of DenmarkDept. of Applied Mathematicsand Computer ScienceMatematiktorvet, Bld 303B2800 Kgs. Lyngby, Denmarkancu@dtu.dkSune LehmannTech. University of DenmarkDept. of Applied Mathematicsand Computer ScienceMatematiktorvet, Bld 303B2800 Kgs. Lyngby, Denmarksljo@dtu.dkJakob Eg Larsen \\xe2\\x88\\x97Tech. University of DenmarkDept. of Applied Mathematicsand Computer ScienceMatematiktorvet, Bld 303B2800 Kgs. Lyngby, Denmarkjaeg@dtu.dkABSTRACTWe describe a personal informatics system for Android smart-phones that provides personal data on mobility and social in-teractions through interactive visualization interfaces. Themobile app has been made available to N=136 \\xef\\xac\\x81rst yearuniversity students as part of a study of social network in-teractions in a university campus setting. The design of theinteractive visualization interfaces enabling the participantsto gain insights into own behaviors is described. We re-port initial \\xef\\xac\\x81ndings based on device logging of participantinteractions with the interactive visualization app on thesmartphone and from a survey on usage with response from45 (33%) of the participants indicating that the system al-lowed new insights into behavioral patterns.Categories and Subject DescriptorsH.5.m. [Information Interfaces and Presentation (e.g.HCI)]: MiscellaneousKeywordsSelf-tracking; Quanti\\xef\\xac\\x81ed Self; Personal Data; Mobility; So-cial Interaction; Visualization; Feedback Interface; MobileSensing1.INTRODUCTIONThe self-tracking phenomenon has recently gained increasedattention as a research topic [7], but also among peoplein general with the availability of health and self-trackingsmartphone apps and low cost wearable devices, such as Fit-Bit1 and Basis Band2. In the stage-based model of personalinformatics systems proposed by Li et al. [6] self-re\\xef\\xac\\x82ection is\\xe2\\x88\\x97Corresponding author: jaeg@dtu.dk1http://www.\\xef\\xac\\x81tbit.com2http://www.mybasis.comPermission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor pro\\xef\\xac\\x81t or commercial advantage and that copies bear this notice and the full citationon the \\xef\\xac\\x81rst page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, re',\n",
       " '   Personal Informatics in Practice: Improving Quality of Life Through Data Ian Li Carnegie Mellon University Pittsburgh, PA 15213 USA ianli@cmu.edu  Yevgeniy Medynskiy Georgia Institute of Technology Atlanta, GA 30332 USA eugenem@gatech.edu  Jon Froehlich University of Maryland College Park, MD 20742 jonf@cs.umd.edu  Jakob Eg Larsen Technical University of Denmark Lyngby, Denmark jel@imm.dtu.dk Copyright is held by the author/owner(s). CHI\\xe2\\x80\\x9912, May 5\\xe2\\x80\\x9310, 2012, Austin, Texas, USA. ACM 978-1-4503-1016-1/12/05. Abstract Personal informatics refers to a class of software and hardware systems that help individuals collect personal information to improve self-understanding. Improving self-understanding can foster self-insight and promote positive behaviors: healthy living, energy conservation, etc. The development of personal informatics applications poses new challenges for human-computer interaction and creates opportunities for applications in various domains related to quality of life, such as fitness, nutrition, wellness, mental health, and sustainability. This workshop will continue the conversations from the CHI 2010 and CHI 2011 workshops on personal informatics [6][7]. The focal themes for this workshop are: (1) practical lessons from previous research and development experiences that can guide interface design for systems that allow users to collect and reflect on personal data; (2) requirements for building robust personal informatics applications; and (3) design and development of infrastructures that make personal informatics applications easier to create and evaluate.  Author Keywords Personal informatics; quantified self; reflection; awareness; behavior; lifelogging; visualizations Workshop SummaryCHI 2012, May 5\\xe2\\x80\\x9310, 2012, Austin, Texas, USA2799\\x0c',\n",
       " 'Individual User Characteristics and Information Visualization: Connecting the Dots through Eye Tracking Dereck Toker, Cristina Conati, Ben Steichen, Giuseppe Carenini Department of Computer Science University of British Columbia, Vancouver, Canada {dtoker, conati, steichen, carenini}@cs.ubc.ca the investigates relationship  between ABSTRACT There is increasing evidence that users\\xe2\\x80\\x99 characteristics such as cognitive abilities and personality have an impact on the effectiveness  of  information  visualization  techniques.  This paper such characteristics  and  fine-grained  user  attention  patterns.  In particular,  we  present  results  from  an  eye  tracking  user study involving bar graphs and radar graphs, showing that a user\\xe2\\x80\\x99s  cognitive  abilities  such  as  perceptual  speed  and verbal working memory have a significant impact on gaze behavior,  both  in  general  and  in  relation  to  task  difficulty and visualization type. These results are discussed in view of our long-term goal of designing information visualisation systems  that  can  dynamically  adapt  to  individual  user characteristics. Author Keywords User Characteristics, Information Visualization, Eye Tracking, Adaptive Information Visualization. ACM Classification Keywords H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous. General Terms User Studies; Human Factors; Design; Measurement.  INTRODUCTION Information  visualization  (Infovis  for  short)  aims  to  assist users in exploring, managing, and understanding the ever-growing information.  While visualizations have gained increasingly in terms of general usage and usability, they have traditionally followed a one-size-fits-all  model,  typically  ignoring  user  differences. However,  recent  research  has  shown individual differences  can  indeed  have  a  significant  impact  on  task effectiveness and user satisfaction during Infovis usage. For example,  personality  traits  have  been  found  to  impact  a user\\xe2\\x80\\x99s performance with different Infovis designs  [31, 15]. Velez  et  al.  [30]  found  that  a  user\\xe2\\x80\\x99s  abilities  for  spatial reasoning  (e.g.,  spatial  orientation)  were  correlated  with amount digital that of  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first pa',\n",
       " 'An Approachto Visualizingand UnderstandingLandscapesExpansive NewsGalaxy of NewsEarl RennisonLanguage WorkshopVisibleMIT Media Lab20 Ames St.Cambridge, MA 02139E-mail:rennison@media. mit.eduABSTRACTspace,relationnetworkof Newsconstructsrelationshipinformation,the Galaxyconstructionan associativeof News uses pyramidalin this case news stories. Atbuild implicitthese relationships,and visual presentation,animatedcuessystem embodieslarge quantities of independentlyan approachtoauthored piecesthe heart ofenginetolinks between related articles.and hence the newsThe Galaxyvisualizingofthis system is a powerfulthatautomaticallyTo visualizeinformationstructuringpanning,between articles, andconstructed to illustratefluid interactionspace toinformationbrowse and search through large databases of news articles.gain aThe resultbroadanabstracted presentationbase, and throughdetails ofthe informationgeneralized into a modelto providespaces and derivation of an interactive news experience.for news access and visualizationof news informationthespace. This research has beensemantic zooming andthatthat covers the entire informationof a news base by providingthat allows people to quicklyis a toolunderstandingin a three dimensionalare dynamicallyprogressivelyrelationshipsconstructioninteraction,automaticrefinesvisualKEYWORDS:informationinteractiveinteraction design.graphics,Informationspaces, pyramidalvisualization,informationabstractedstructures, 3Dinformationspace design,informationcomputersystems and infrastructuremany ways existingare still directedandmanagement.newsinformationin this structure is a secondary action and ismost often left up to the readers, with little support by theinformationthese forms of distributiontowardAccessingunderstandinginfrastructure.andincreasinginformationto constructthe problem,in a meaningfulnews productionhas led to increasingand hence,news articles and/or(e.g. articlesthat are linked) will become increasinglythat relate to otherAs a result, authoringof news organization, management,To expoundresulting from the rise in connectivitycomplexityunderstanding.presentationsor presentationsmore difficulthelp the reader to understand the full nature ofinformationinformationexplodingcorrelation.infrastructurerelationshipsconstructcontent,newsexpandingunderstandingthatlooking at individualscaleHence, whatthat automaticallybetweenbase and allowsis deeperthatinfrastructurereaders to dynamicallysimplyinformationtheexplorethem to gainanthey would gain by',\n",
       " 'User-Adaptive Information Visualization - Using Eye Gaze Data to Infer Visualization Tasks and User Cognitive Abilities Ben Steichen, Giuseppe Carenini, Cristina Conati Department of Computer Science, University of British Columbia, Vancouver, Canada {steichen, carenini, conati}@cs.ubc.ca systems  have ABSTRACT Information  Visualization traditionally followed  a  one-size-fits-all  model,  typically  ignoring  an individual user\\xe2\\x80\\x99s needs, abilities and preferences. However, recent research has indicated that visualization performance could be improved by adapting aspects of the visualization to  each  individual  user.  To  this  end,  this  paper  presents research  aimed  at  supporting  the  design  of  novel  user-adaptive  visualization  systems.  In  particular,  we  discuss results on using information on user eye gaze patterns while interacting  with  a  given  visualization  to  predict  the  user\\xe2\\x80\\x99s visualization  tasks,  as  well  as  user  cognitive  abilities including  perceptual  speed,  visual  working  memory,  and verbal working memory. We show that such predictions are significantly better than a baseline classifier even during the early  stages  of  visualization  usage.  These  findings  are discussed  in  view  of  designing  visualization  systems  that can adapt to each individual user in real-time. Author Keywords Adaptive Information Visualization; Eye-tracking; Adaptation; Machine Learning. ACM Classification Keywords H.5.m. INTRODUCTION Information  Visualization  is  a  thriving  area  of  Human-Computer  Interaction  that  aims  to  help  users  in  managing and  understanding  increasing  amounts  of  information. While visualization systems have gained in terms of general usage  and  usability,  they  have  traditionally  been  designed using  a  one-size-fits-all  approach,  typically  ignoring  an individual  user\\xe2\\x80\\x99s  needs,  abilities  and  preferences.  In  order to  better  assist  each  individual  user  during  visualization tasks, recent research has started to investigate novel user-adaptive visualizations  that can dynamically infer relevant user  characteristics  and  provide  appropriate  interventions tailored  to  these  characteristics.  Initial  research  of  user- Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and ',\n",
       " '   Personal Informatics in the Wild: Hacking Habits for Health & Happiness Catherine Grevet Georgia Institute of Technology Atlanta, GA 30332 USA cgrevet@gatech.edu  Ernesto Ramirez University of California, San Diego La Jolla, CA 92093 USA erramirez@ucsd.edu  Ian Li Google Mountain View, CA 94043 USA ianli@google.com  Jon Froehlich University of Maryland College Park, MD 20742 jonf@cs.umd.edu  Jakob Eg Larsen Technical University of Denmark Lyngby, Denmark jel@imm.dtu.dk  Copyright is held by the author/owner(s). CHI 2013 Extended Abstracts, April 27\\xe2\\x80\\x93May 2, 2013, Paris, France. ACM 978-1-4503-1952-2/13/04. Abstract Personal informatics is a class of systems that help people collect personal information to improve self-knowledge. Improving self-knowledge can foster self-insight and promote positive behaviors, such as healthy living and energy conservation. The development of personal informatics applications poses new challenges in human-computer interaction and creates opportunities for applications in various domains related to quality of life, such as fitness, nutrition, wellness, mental health, and sustainability. This workshop will continue the conversations from the 3 previous CHI workshops [6][7][8] through discussions on practical lessons from previous research and development experiences. In particular, this workshop will extend this ongoing work through a focus on rapid prototyping and deployment in the wild. Topics covered will include designing interfaces for collecting and reflecting on personal data, building robust applications, and infrastructures to make applications easier to create.  Keywords Personal informatics; Reflection; Awareness; Behavior; Life logging; Visualizations Workshop SummaryCHI 2013: Changing Perspectives, Paris, France3179\\x0c',\n",
       " ' \\xe2\\x80\\x9cEverybody Knows What You\\xe2\\x80\\x99re Doing\\xe2\\x80\\x9d: A Critical Design Approach to Personal Informatics Vera Khovanskaya1, Eric P.S. Baumer2,1, Dan Cosley1, Stephen Voida1, Geri Gay2,1 1Department of Information Science Cornell University Ithaca, NY 14850 USA 2Department of Communication Cornell University Ithaca, NY 14850 USA {vdk9, ericpsb, drc44, svoida, gkg1}@cornell.edu  ABSTRACT We  present  an  alternative  approach  to  the  design  of personal informatics systems: instead of motivating people to  examine  their  own  behaviors,  this  approach  promotes awareness  of  and  reflection  on  the  infrastructures  behind personal informatics and the modes of engagement that they promote. Specifically, this paper presents an interface that displays personal web browsing data. The interface aims to reveal  underlying  infrastructure  using  several  methods: drawing attention to the scope of mined data by displaying deliberately  selected  sensitive  data,  using  purposeful malfunction as a way to encourage reverse engineering, and challenging normative expectations around data mining by displaying information in unconventional ways. Qualitative results  from  a  two-week  deployment  show  that  these strategies can raise people\\xe2\\x80\\x99s awareness about data mining, promote efficacy and control over personal data, and inspire reflection  on  the  goals  and  assumptions  embedded  in infrastructures for personal data analytics. Author Keywords Personal informatics; critical design; design strategies ACM Classification Keywords H.5.m. [Information interfaces and presentation (e.g., HCI)]: Miscellaneous. INTRODUCTION Users  of  modern  technology  live  in  an  environment  filled with  logging  technologies  that  gather  information  about them,  both  with  and  without  their  knowledge.  Personal informatics systems invite users to reflect on and use these data,  notionally  to  understand  themselves  better.  The conventional approach driving personal informatics systems in through  self-knowledge: the fruits of data mining should be presented to users self-improvement in various aspects of their lives [16]. to  promote  personal  optimization  and the  field  has  been  self-betterment  Permission to make digital or hard copies  of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first p',\n",
       " '367  The Irony and Re-interpretation of Our Quantified Self Rafael A. Calvo School of Electrical and Information Engineering The University of Sydney Sydney, NSW 2006 Rafael.Calvo@sydney.edu.au  Dorian Peters Faculty of Education & Social Work The University of Sydney Sydney, NSW 2006 Dorian.Peters@sydney.edu.au    ABSTRACT The new possibilities afforded by cloud computing infrastructure, with respect to the large amounts of data that can now be collected and processed unobtrusively, have triggered a growing interest in systems that record personal life events. We go on the notion that this information can be used as a kind of extended memory to support insights into our past and our present lives. However, as we argue in this paper, the psychological processes and consequences underlying the interpretation of this data can be significantly more complex and less predictable than has generally been acknowledged.  Specifically we look at two phenomena: first, that of re-interpretation (that events are reinterpreted every time we recall them) and second, that humans participate in ironic processes such that even self-control goals can become obstacles to behavior change. In this paper we put forward that as we design life-logging systems, personal informatics or quantified-self technologies in future, will need to better find ways to take into account this psychological complexity in order to be effective and avoid inadvertent harm. We also briefly review theoretical frameworks and psychological evidence that may inform the way we design such systems going forward. Author Keywords Personal Informatics; Quantified Self; Life logging  ACM Classification Keywords H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous.  General Terms Human Factors; Design; Measurement.   INTRODUCTION \\xe2\\x80\\x9cKnow thyself\\xe2\\x80\\x9d (through behavioral data that we store on the cloud) is a motto that drives much of modern HCI research (Li, Forlizzi, & Dey, 2010). The idea is that by reflecting on our past we can improve the way we lead our lives; for example, by detecting bad eating habits we can eat healthier, or by realizing the impact of sedentary behaviors we can decide to do more exercise. In essence we seek to build a computer model of \\xe2\\x80\\x98self\\xe2\\x80\\x99 and use it to understand ourselves better.  A number of researchers have developed design guidelines for specific application areas. For example, Consolvo and Everitt (Consolvo, Everitt, Smith, & Landay, 2006) provide guidelin',\n",
       " \"This cluster visualization shows an intermediate-level view of a five-dimensional, 16,000-recordremote-sensing data set. Lines indicate clustercenters and bands indicate the extent of the clusters in each dimension. Data represents fivechannels\\xe2\\x80\\x94spot, magnetics, and three involvingradiometrics\\xe2\\x80\\x94focusing on potassium, thorium,and uranium from the Grant's Pass region of Australia. Data courtesy of Peter Ketelaar, Commonwealth Scientific and Industrial ResearchOrganization, Australia. Image generated usingXmdvTool, a public-domain multivariate datavisualization package; courtesy Matthew Ward,Worcester Polytechnic Institute, Worcester, MA. 38August  2001/Vol. 44, No. 8 COMMUNICATIONS OF THE ACM\\x0c\",\n",
       " '\\x0c',\n",
       " 'Understanding My Data, Myself:  Supporting Self-Reflection with Ubicomp Technologies Ian Li1, Anind K. Dey1, Jodi Forlizzi1,2 1Human Computer Interaction Institute, 2School of Design Carnegie Mellon University, Pittsburgh, PA 15213 ianli@cmu.edu, {anind, forlizzi}@cs.cmu.edu  two  phases  of to  appropriately ABSTRACT We live in a world where many kinds of data about us can be  collected  and  more  will  be  collected  as  Ubicomp technologies  mature.  People  reflect  on  this  data  using different  tools  for  personal  informatics.  However,  current tools  do  not  have  sufficient  understanding  of  users\\xe2\\x80\\x99  self-reflection  needs leverage  Ubicomp technologies.  To  design  tools  that  effectively  assist  self-reflection,  we  need  to  comprehensively  understand  what kinds of questions people have about their data, why they ask  these  questions,  how  they  answer  them  with  current tools,  and  what  kinds  of  problems  they  encounter.  To explore this, we conducted interviews with people who use various  kinds  of  tools  for  personal  informatics.  We  found six  kinds  of  questions  that  people  asked  about  their  data. We  also  found  that  certain  kinds  of  questions  are  more important  at  certain  times,  which  we  call  phases.  We reflection:  Discovery  and identified Maintenance.  We  discuss  the  kinds  of  questions  and  the phases  in  detail  and  identify  features  that  should  be supported in personal informatics tools for which Ubicomp technologies can play an important role. Author Keywords Personal  informatics,  reflection,  phases,  discovery,  design features, visualizations ACM Classification Keywords H5.m.  Information  interfaces  and  presentation  (e.g.,  HCI): Miscellaneous. General Terms Design, Human Factors INTRODUCTION The abundance of computers, mobile devices, sensors, and access to information via the Internet enables the recording of  a  myriad  of  personal  data  (e.g.,  physiological  data, behaviors,  habits,  and  thoughts).  All  of  this  data  can  be used for self-reflection to help people become more aware  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or  republish,  to  post  on  servers  or  to  redistribute  to  lists,  ',\n",
       " 'Audio-Visual Data Mapping for GIS-based Data: An Experimental Evaluation Suresh K. Lodha Abigail J. Joseph Jose C. Renteria Department of Computer Science University of California, Santa Cruz, CA 95064 {lodha,ajjoseph,renteria}~cse.ucsc.edu ABSTRACT In this work, we present our experience of utilizing audio- visual data mappings for GIS-based information visualiza- tion. The application we choose is a GIS-based system for visualizing crime in a city. In this application, we enhance the pseudo-colored visual presentation of crime information by mapping data to several sound parameters - volume, bal- ance, bass and treble. Our motivation for choosing sound in addition to vision is guided by our belief that data quan- tities mapped to various colors in a coloring scheme do not always clearly describe the information being presented for many different tasks that visualization is expected to sup- port. In many cases additional data characteristics can be conveyed to the user through sound to enhance the per- formance of the user on those tasks. We have conducted experiments with human users to compare the performance of users on visual data mapping alone vs. visual and sound data mappings together on several tasks including estimates of raw data values, local averaging, and global comparison. In most cases, we found that the use of bi-modal visual and sound data mappings together provided more accurate un- derstanding of data displays. Keywords: user interface, evaluation, sonification, visual- ization, mapping. 1. INTRODUCTION Visual displays are an integral part of the way people ob- tain information. We look at weather maps to see what the temperature in a certain area will be, use maps to navigate ourselves through unfamiliar territory, and read the colors on traffic lights to know when to proceed through an inter- section. Sound cues play an equally important role in our daily lives as visual cues. We use sound to change gears in a car or to alert us when to get up in the morning. People use maps to collect various types of information about different aspects of the world on a daily basis. Maps can present a vast amount of data relating to specific regions of Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the fidl citation on the first page. To copy otherwise, to',\n",
       " '   A Quantified Past: Remembering  with Personal InformaticsChris Elsden  School of Computer Science  Culture Lab Newcastle University, UK c.r.elsden@newcastle.ac.uk  David Kirk School of Computer Science Culture Lab Newcastle University, UK david.kirk@newcastle.ac.uk    Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the owner/author(s). Copyright is held by the author/owner(s). DIS 2014, June 21\\xe2\\x80\\x9325, 2014, Vancouver, BC, Canada. ACM 978-1-4503-2902-6/14/06.  Abstract This paper questions how we will interact with our \\xe2\\x80\\x98Quantified Past\\xe2\\x80\\x99, the historical record created by our daily use of personal informatics tools.  Bringing together HCI research on memory and personal informatics, we introduce an ongoing user-study and several speculations for the long-term design and use of personal informatics tools.  Author Keywords Remembering; Personal Informatics; Quantified Self; Time; Experience;  ACM Classification Keywords H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous.  Introduction As our digital footprint grows, through lives lived increasingly online, HCI researchers have considered \\xe2\\x80\\x98The Future of Looking Back\\xe2\\x80\\x99 [1]. Rather than simply augmenting human memory, this considers the role digital technologies will play in mediating the lifelong experience of remembering. If we are to focus on the experience, then we view remembering as a situated, present-oriented process of reconstruction. This demands a more social and cultural minded study of memory, and a departure from some purely cognitivist Provocations and Work-in-ProgressDIS 2014, June 21\\xe2\\x80\\x9325, 2014, Vancouver, BC, Canada45\\x0c',\n",
       " \"  45Tricks to Animating Characters with a Computer John Lasseter Pixar i .. . .. These ~ : !notes c~-SIGGRAPH ~i ~ :~::: ~;~ ~ ~:~=~:~ z~:c~ course m An~~' ' : Abstract When I presented the first animation I had created with a computer, The Adventures of Andr~ and Wally B., at SIGGRAPH 84, a number of people asked me what cool new soPcware I had used to achieve such believable characters. I explained to them that the soft- ware was a ke)rframe animation system, not much different in theory than other systems that were around then. What was different was that I was using basic animation princi- ples that I had learned as a traditional animator. It was not the software that gave life to the characters, it was these principles of animation, these tricks of the trade that animators had developed over 50 years ago. I was surprised at how few people in the computer animation community were aware of these principles. Traditional animation is basically one trick after another. Whatever it takes to get it working right on the screen is fair game. It should be the same in computer animation.At Pixar, we constantly use tricks, old and new, to get what we need on the screen. In this talk, I will give away a few trade secrets that will be useful to anyone attempting to animate characters with computers, regard- less of the software they are using. Keyframes Host commercially available computer anima- tion systems are based on animating with keyframes. At first, this seems like the same thing as key~rames in traditional hand-drawn animation, but it is slightly different, and therefore, you should approach your anima- tion differently. In hand-drawn animation, you work on the basic poses of the scene first, drawing poses of the entire character so the timing and acting can be worked out with a minimum of drawings created. Once the poses are finalized, then the in-between draw- ings are created to complete the action.With computer animation, keyframes are values at certain frames for the articulation controls of a model, which are usually set up in a hier- archy. The computer calculates the in- betweens values based on a spline curve connecting the keyframe values. When I first began animating with a computer, I was used to hand-drawn anima- tion and thought a keyframe in one medium was the same as the other. So I worked on one complete pose, went ahead a few frames, then worked on the next pose. Well, the in- betweens produced by the computer were completely useless. I e\",\n",
       " 'Data Soni\\xef\\xac\\x81cation from the Desktop: Should Sound Be Partof Standard Data Analysis Software?JOHN H. FLOWERS, DION C. BUHMAN, and KIMBERLY D. TURNAGEUniversity of Nebraska \\xe2\\x80\\x93 LincolnThe design of auditory formats for data display is presently focused on applications for blind or visually impaired users, specializeddisplays for use when visual attention must be devoted to other tasks, and some innovative work in revealing properties of complexdata that may not be effectively rendered by traditional visual means. With the availability of high-quality and \\xef\\xac\\x82exible soundproduction hardware in standard desktop computers, the potential exists for using sound to represent characteristics of typical\\xe2\\x80\\x9csmall and simple\\xe2\\x80\\x9d samples of data in routine data inspection and analysis. Our research has shown that basic properties ofsimple functions, distribution properties of data samples, and patterns of covariation between two variables can be effectivelydisplayed by simple auditory graphs involving patterns of pitch variation over time. While such developments have implicationsfor specialized applications and populations of users, these displays are easily comprehended by normal users with minimalpractice. Providing further software enhancement to encourage exploration of data representation by sound may lead to avariety of useful creative developments in data display technology.Categories and Subject Descriptors: [General Literature\\xe2\\x80\\x94General]\\xe2\\x80\\x94Conference proceedingsGeneral Terms: Experimentation, Human Factors, PerformanceAdditional Key Words and Phrases: Soni\\xef\\xac\\x81cation, auditory display, data mappingINTRODUCTION1.Data soni\\xef\\xac\\x81cation is a useful technique for presenting information to visually impaired individuals, fordisplaying data to users whose visual attention must be devoted elsewhere, and for revealing dataproperties not easily rendered by visual graphics. Although auditory formats for describing data arenot common at present, it is our view that the use of sound for revealing characteristics of small andrelatively simple data samples, even by normally sighted users performing routine data inspectionand manipulation activities, holds considerable promise [Flowers and Hauer, 1992] Improvements inhardware capabilities of current desktop and portable computers (multimedia readiness) have thepotential to vastly increase the availability of auditory data display formats for general users. Providingsoftware enhancement to encourage exploration of symbolic data repres',\n",
       " 'Online Social Networks for Personal Informatics  to Promote Positive Health Behavior University of British Columbia Media and Graphics Interdisciplinary University of British Columbia Dept. of Electrical and Computer FSC 3640 \\xe2\\x80\\x93 2424 Main Mall; 2332 Main Mall; Vancouver, BC Noreen Kamal Centre Vancouver, BC +1-604-822-2761 noreenk@ece.ubc.ca Sidney Fels Engineering +1-604-822-5338 ssfels@ece.ubc.ca  Kendall Ho University of British Columbia eHealth Strategy Office 855 West 10th Ave; Vancouver, BC  kendall.ho@ubc.ca ABSTRACT Social  network  services  are  becoming  increasingly  popular,  and people are using these networks to obtain and share information.  The  application  of  social  network  and  social  media  to  the collection,  storage  and  review  of  personal  information  presents opportunities  for  improved  personal  health  management.    This paper presents a survey of the literature on the models for the use of online social networks and models for health behavior change.  These  are  then  combined  to  present  a  framework  for  health behavior  change  through  social  media.    This  framework  is  then used to develop a prototype for the system design.   Categories and Subject Descriptors [Information  Interfaces  and  Presentation]:  User H.5.2 Interfaces  \\xe2\\x80\\x93  prototyping,  theory  and  methods,  user-centered design.  General Terms Design, Human Factors, Theory. Keywords Personal  informatics,  life  logging,  personal  health  management, personal health informatics, health behavior change. 1.  INTRODUCTION Today,  the  explosion  of  on-line  social  network  services  has demonstrated that individuals are willing to share a multitude of information  with  close  and  distant  social  connections  [7,  9]. Recent  advances  in  web  technologies  and  in  particular  Web  2.0 and  mobile  applications  offer  tremendous  opportunities  for  user created  information  through  a  rich  interface  using  social  media [17, 31]. Additionally,  it  has  been  widely  accepted  that  personal  health management or self-management is an effective way of managing chronic disease and avoiding illness in healthy people [5].  Social  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not  made  or  distributed  for  profit  or  commercial  advantage  and  that copies  bear  this  notice  and  the  full  citation  on  the  first  page.  To  c',\n",
       " 'CHI 99  15-20 MAY 1999 VR\\xe2\\x80\\x99s  Frames  of  Reference:  A Visualization  Technique Information Mastering  Abstract  Multidimensional Papers for Marilyn  C.  Salzman Human Factors &  Applied Cognitive Psychology George Mason University Fairfax VA  22030 USA +1303  5416454 mcsalzm@advtech.uswest.com Chris  Dede Graduate School of Education George Mason University Fairfax VA  22030 USA +17039932019 cdede@gmu.edu R,  Bowen  Loftin Virtual  Environment Technologies Lab University  of Houston Houston TX  77023 USA +1713 743 1006 bowen@uh.edu reference frames  of ABSTRACT This  paper describes a research study  that  investigated  how designers  can  use (egocentric, exocentric,  and  a  combination  of  the  two)  to  support  the mastery  of  abstract  multidimensional information.  The focus  of  this  study  was  the  relationship  between primary FORs  and  mastery;  the  secondary  focus  was  on  other interaction factors experience)  that  were  likely the  relationship between  FORs  and  mastery.  This  study\\xe2\\x80\\x99s  outcomes  (1) clarify  how  FORs  work  in  conjunction  with  other  factors  in shaping  mastery,  (2)  highlight  strengths  and  weaknesses of different FORs,  (3)  demonstrate  the  benefits  of  providing for  our characteristics to  influence (individual and multiple  FORs,  and recommendations  to HCI  researchers and designers. (4)  provide the  basis these  scientists  are  extraordinary theory  of  relativity.  Unfortunately, of for  most  people  [5,  181. Thus,  techniques  that  can difficult help  people  recognize  patterns,  reason  qualitatively  about physical  processes,  translate  among  frames  of  reference, and envision  dynamic  models  are important. the  area  of  graphic  design  and  HCI,  considerable In attention  has been given  to the development  of  visualization techniques  to support  these processes [e.g., 6,  171. in  using  visualization on  their  perceptual  abilities  when  looking  for  patterns  and relationships Brown [lo] designers are trying  to achieve  through  visualization: in Keywords Virtual reality,  visualization, design,  education  applications interaction  design,  visual to visualize complex for  communicating  and  understanding INTRODUCTION to  visualize In  today\\xe2\\x80\\x99s  knowledge-based  society,  the  ability information and  manipulate  abstract  and  multidimensional is  crucial ideas  [5, 141. Whether  working  in  scientific,  environmental,  political, find  themselves or  even ',\n",
       " 'A Stage-Based Model of Personal Informatics Systems  Ian Li1, Anind Dey1, and Jodi Forlizzi1,2 1Human Computer Interaction Institute, 2School of Design Carnegie Mellon University, Pittsburgh, PA 15213 ianli@cmu.edu, {anind, forlizzi}@cs.cmu.edu  these  properties,  we  recommend ABSTRACT People strive to obtain self-knowledge. A class of systems called  personal  informatics  is  appearing  that  help  people collect and reflect on personal information. However, there is no comprehensive list of problems that users experience using  these  systems,  and  no  guidance  for  making  these systems  more  effective.  To  address  this,  we  conducted surveys and interviews with people who collect and reflect on  personal  information.  We  derived  a  stage-based  model of  personal  informatics  systems  composed  of  five  stages  (preparation, collection, integration, reflection, and action) and  identified  barriers  in  each  of  the  stages.  These  stages have  four  essential  properties:  barriers  cascade  to  later stages;  they  are  iterative;  they  are  user-driven  and/or system-driven;  and  they  are  uni-faceted  or  multi-faceted. From that  personal informatics  systems  should  1)  be  designed  in  a  holistic manner across the stages; 2) allow iteration between stages; 3)  apply  an  appropriate  balance  of  automated  technology and  user  control  within  each  stage  to  facilitate  the  user experience; and 4) explore support for associating multiple facets of people\\xe2\\x80\\x99s lives to enrich the value of systems. Author Keywords Personal informatics, collection, reflection, model, barriers ACM Classification Keywords H5.m.  Information  interfaces  and  presentation  (e.g.,  HCI): Miscellaneous.  General Terms Design, Human Factors INTRODUCTION AND MOTIVATION The importance of knowing oneself has been known since ancient  times.  Ancient  Greeks  who  pilgrimaged  to  the Temple  of  Apollo  at  Delphi  to  find  answers  were  greeted with  the  inscription  \\xe2\\x80\\x9cGnothi  seauton\\xe2\\x80\\x9d  or  \\xe2\\x80\\x9cKnow  thyself\\xe2\\x80\\x9d. To  this  day,  people  still  strive  to  obtain  self-knowledge. One way to obtain self-knowledge is to collect information about oneself\\xe2\\x80\\x94one\\xe2\\x80\\x99s behaviors, habits, and thoughts\\xe2\\x80\\x94and reflect  on  them.  Computers  can  facilitate  this  activity  Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or ',\n",
       " 'Taming Data Complexity in Lifelogs:  Exploring Visual Cuts of Personal Informatics Data Daniel A. Epstein1, Felicia Cordeiro1, Elizabeth Bales1,2, James Fogarty1, Sean A. Munson2 1Computer Science & Engineering 2Human Centered Design & Engineering DUB Group, University of Washington {depstein, felicia0, lizbales, jfogarty}@cs.washington.edu, smunson@uw.edu  ABSTRACT As people continue to adopt technology-based self-tracking devices and applications, questions arise about how personal informatics tools can better support self-tracker goals. This paper  extends  prior  work  on  analyzing  and  summarizing self-tracking  data,  with  the  goal  of  helping  self-trackers identify more meaningful and actionable findings. We begin by surveying physical activity self-trackers to identify their goals  and  the  factors  they  report  influence  their  physical activity. We then define a cut as a subset of collected data with some shared feature, develop a set of cuts over location and physical activity data, and visualize those cuts using a variety of presentations. Finally, we conduct a month-long field deployment with participants tracking their location and physical activity data and then using our methods to examine their data. We report on participant reactions to our methods and future design opportunities suggested by our work. Author Keywords Personal informatics; reflection; routines; physical activity sensing; lifelogs; self-monitoring; self-tracking. ACM Classification Keywords H.5.m. Information Interfaces and Presentation (e.g., HCI). INTRODUCTION A  wide  variety  of  devices  and  applications  are  becoming increasingly  popular  for  collecting  and  tracking  personal data.  Personal  informatics  tools  have  been  developed  and studied in a variety of domains, including physical activity (e.g.,  FitBit,  JawBone  UP,  [6,7]),  sleep  (e.g.,  SleepCycle, [15]), location (e.g.,  FourSquare, [14]), food consumption (e.g., MyFitnessPal, [27]), expenses (e.g., Mint, [25]), and media  consumption  (e.g.,  last.fm,  [22]).  Tools  can  also combine and track multiple types of data. For example, the smartphone  applications Moves and Saga passively  record location and physical activity. Such tools have already begun to enter the mainstream and are likely to become even more ubiquitous and important: 69% of U.S. adults report tracking a health factor with 14% using technology to do so [11]. Permission  to  make  digital  or hard  copies  of  all  or',\n",
       " 'A PE  RSONAL DATABASE for EVERYTHING88January  2006/Vol. 49, No. 1 COMMUNICATIONS OF THE ACM\\x0c',\n",
       " 'Force Constancy and Its Effect on Haptic Perception ofVirtual SurfacesSEUNGMOON CHOI, LARON WALKER, and HONG Z. TANHaptic Interface Research Laboratory, Purdue UniversityandSCOTT CRITTENDEN and RON REIFENBERGERNanophysics Laboratory, Purdue UniversityThe force-constancy hypothesis states that the user of a force-feedback device maintains a constant penetration force whenstroking virtual surfaces in order to perceive their topography. The hypothesis was developed to address a real-world dataperceptualization problem where the perception of surface topography was distorted when the surface stiffness was nonuniform.Two experiments were conducted. In Experiment I, we recorded the penetration depths of the probe tip while the user strokedtwo surfaces with equal height but different stiffness values. We found that the data could be quantitatively modeled by theforce-constancy hypothesis when the virtual surfaces were neither too soft nor too hard. In Experiment II, we demonstrated thatgiven two adjacent surfaces, their perceived height difference depended on both the surface stiffness values as well as the relativeheights of the surfaces. Speci\\xef\\xac\\x81cally, we showed that the higher but softer surface could be perceived to be lower, at the sameheight, or higher than the other surface, depending on how much higher it was than the other surface. The results were consistentwith the predictions of the force-constancy hypothesis. Our \\xef\\xac\\x81ndings underscore the importance of understanding the interplayof haptic rendering parameters.Categories and Subject Descriptors: H.1.2 [Models and Principles]: User/Machine Systems\\xe2\\x80\\x94human information processing;H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems\\xe2\\x80\\x94arti\\xef\\xac\\x81cial, augmented, and virtual re-alities; H.5.2 [Information Interfaces and Presentation]: User Interfaces\\xe2\\x80\\x94evaluation/methodology; Haptic I/OGeneral Terms: Experimentation, Theory, Veri\\xef\\xac\\x81cationAdditional Key Words and Phrases: Haptic rendering, force constancy, surface topography, psychophysicsINTRODUCTION1.This paper is concerned with how users interact with a haptic virtual surface and how the interactionstrategy affects the perception of surface properties. Given that most force-feedback haptic interfaces areThis work was supported in part by a National Science Foundation (NSF) Faculty Early Career Development (CAREER) awardunder grant no. 9984991-IIS, an NSF award under grant no. 0098443-IIS, a NASA award under grant no. NCC 2-1363, and',\n",
       " 'Learning Analytics for Visualization and RecommendationAttention Please!Erik DuvalDept. Computer ScienceKatholieke Universiteit LeuvenCelestijnenlaan 200AB3000 Leuven, Belgiumerik.duval@cs.kuleuven.beABSTRACTThis paper will present the general goal of and inspirationfor our work on learning analytics, that relies on attentionmetadata for visualization and recommendation. Throughinformation visualization techniques, we can provide a dash-board for learners and teachers, so that they no longer needto \\xe2\\x80\\x9ddrive blind\\xe2\\x80\\x9d. Moreover, recommendation can help todeal with the \\xe2\\x80\\x9dparadox of choice\\xe2\\x80\\x9d and turn abundance froma problem into an asset for learning.Categories and Subject DescriptorsK.3 [Computers and Education]: Computer Uses in Ed-ucationGeneral TermsDesign, Human Factors, TheoryKeywordsLearning Analytics, Visualization, Recommendation1.INTRODUCTIONAttention is a core concern in learning: as learning re-sources become available in more and more abundant ways,attention becomes the scarce factor, both on the side oflearners as well as on the side of teachers. (This is a widerconcern, as we evolve towards an \\xe2\\x80\\x99attention economy\\xe2\\x80\\x99 [10].)Learners and teachers leave many traces of their attention:some are immediately obvious to others, for instance in theform of posts and comments on blogs, or as twitter mes-sages. These explicit traces are human readable, but can bedi\\xef\\xac\\x83cult to cope with in a world of abundance [29]. Althoughsome refer to \\xe2\\x80\\x99information overload\\xe2\\x80\\x99, we prefer Shirky\\xe2\\x80\\x99s \\xe2\\x80\\x9d\\xef\\xac\\x81l-ter failure\\xe2\\x80\\x9d as a way to think about the problem of dealingwith this abundance [30].In any case, human attentiontraces are extremely valuable, but do not scale very well.Permission to make digital or hard copies of all or part of this work forpersonal or classroom use is granted without fee provided that copies arenot made or distributed for pro\\xef\\xac\\x81t or commercial advantage and that copiesbear this notice and the full citation on the \\xef\\xac\\x81rst page. To copy otherwise, torepublish, to post on servers or to redistribute to lists, requires prior speci\\xef\\xac\\x81cpermission and/or a fee.LAK\\xe2\\x80\\x9911 February 27-March 1, 2011, Banff, AB, Canada.Copyright 2011 ACM 978-1-4503-1057-4/11/02 ...$10.00.In this paper, we will explain how machine readable tracesof attention can be used to \\xef\\xac\\x81lter and suggest, provide aware-ness and support social links.This paper is structured as follows: section 2 provides abrief background on the \\xef\\xac\\x81eld of analytics in general. Thesection thereafter focuses o',\n",
       " 'Beyond Quantified Self:  Data For Wellbeing   Jochen Meyer OFFIS Institute for Information Technology Oldenburg, Germany meyer@offis.de  Steven Simske Hewlett-Packard, HP Labs Fort Collins, Colorado, USA steven.simske@hp.com  Katie Siek Indiana University  Bloomington, Indiana, USA ksiek@indiana.edu  Cathal Gurrin Dublin City University Dublin, Ireland cgurrin@computing.dcu.ie  Hermie J Hermens Roessingh Research and Development,  Enschede, The Netherlands h.hermens@rrd.nl     Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.  Copyrights for third-party components of this work must be honored. For all other uses, contact the Owner/Author.  Copyright is held by the owner/author(s). CHI 2014 , Apr 26 - May 01 2014, Toronto, ON, Canada ACM 978-1-4503-2474-8/14/04. http://dx.doi.org/10.1145/2559206.2560469  Abstract Sustaining our health and wellbeing requires lifelong efforts for prevention and healthy living. Continuously observing ourselves is one of the fundamental measures to be taken. While many devices support monitoring and quantifying our health behavior and health state, they all are facing the same trade-off: the higher the data quality is the higher are the efforts of data acquisition. However, for lifelong use, minimizing efforts for the user is crucial. Nowadays, few devices find a good balance between cost and value. In this interdisciplinary workshop we discuss how this trade-off can be approached by addressing three topics: understanding the user\\xe2\\x80\\x99s information needs, exploring options for data acquisition, and discussing potential designs for life-long use. Author Keywords wellbeing; data analysis; user oriented design ACM Classification Keywords H.5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous. J.3. Applied computing: Life and medical sciences: Consumer health Workshop SummaryCHI 2014, One of a CHInd, Toronto, ON, Canada95\\x0c',\n",
       " 'DOI: 10.1111/j.1467-8659.2012.03126.xEurographics Conference on Visualization (EuroVis) 2012S. Bruckner, S. Miksch, and H. P\\xef\\xac\\x81ster(Guest Editors)Volume 31 (2012), Number 3Semi-Supervised Dimensionality Reduction based on PartialLeast Squares for Visual Analysis of High Dimensional DataJose Gustavo S. Paiva1,3, William Robson Schwartz2,4, Helio Pedrini2 and Rosane Minghim11USP, Sao Carlos, Brazil, 2UNICAMP, Campinas, Brazil, 3UFU, Uberlandia, Brazil, 4UFMG, Belo Horizonte, BrazilAbstractDimensionality reduction is employed for visual data analysis as a way to obtaining reduced spaces for highdimensional data or to mapping data directly into 2D or 3D spaces. Although techniques have evolved to improvedata segregation on reduced or visual spaces, they have limited capabilities for adjusting the results accordingto user\\xe2\\x80\\x99s knowledge. In this paper, we propose a novel approach to handling both dimensionality reduction andvisualization of high dimensional data, taking into account user\\xe2\\x80\\x99s input. It employs Partial Least Squares (PLS),a statistical tool to perform retrieval of latent spaces focusing on the discriminability of the data. The methodemploys a training set for building a highly precise model that can then be applied to a much larger data set veryeffectively. The reduced data set can be exhibited using various existing visualization techniques. The training datais important to code user\\xe2\\x80\\x99s knowledge into the loop. However, this work also devises a strategy for calculating PLSreduced spaces when no training data is available. The approach produces increasingly precise visual mappingsas the user feeds back his or her knowledge and is capable of working with small and unbalanced training sets.Categories and Subject Descriptors (according to ACM CCS):Generation\\xe2\\x80\\x94Display algorithmsI.3.3 [Computer Graphics]: Picture/Image1. IntroductionDimension reduction is an important task involved in dataanalysis in general, and in particular for data sets that reacha high number of dimensions or attributes. It is applied in avisual analysis pipeline usually at the start of the process ofvisual mapping, whereby a method, such as Principal Com-ponent Analysis (PCA), is employed to \\xef\\xac\\x81nd principal direc-tions that recombine coordinates in new and fewer dimen-sions. To allow visualization of multidimensional data, vari-ous dimension reduction techniques have been employed tomap from multidimensional to bidimensional spaces by re-ducing the dimension of the original spa',\n",
       " '  Designing Personal Informatics Applications and Tools that Facilitate Monitoring of Behaviors Human Computer Interaction Institute, Carnegie Mellon University Ian Li 5000 Forbes Avenue, Pittsburgh, PA 15213 Advisors: Anind Dey and Jodi Forlizzi  ianli@cmu.edu  ABSTRACT A new class of applications and web sites called personal informatics  is  appearing  that  collects  personal  behavioral information  about  users  and  provides  access  to  this  infor-mation to help users become more aware of their own be-haviors. Interaction with personal informatics systems has two inter-dependent phases: monitoring and feedback. Us-ers  must  interact  with  the  system  in  at  least  one  of  the phases for users to become aware of their behavior. In my proposed work, I focus on user\\xe2\\x80\\x99s interaction with the sys-tem during the monitoring phase. The main question of my research  is  what  are  the  problems  with  the  monitoring phase  of  personal  informatics  and  how  can  they  be  re-solved? I explore three aspects of this question: (1) How do you reduce the burden of manual monitoring? (2) How can systems  motivate  manual  monitoring?  (3)  What  are  the advantages and disadvantages of automated monitoring? ACM  Classification:  H5.2  [Information  interfaces  and presentation]: User Interfaces. - Graphical user interfaces. General terms: Design, Human Factors Keywords: Personal informatics, daily recording, personal behavior INTRODUCTION Knowing oneself through self-awareness and self-reflection has  many  benefits,  such  as  fostering  self-insight  [4],  im-proving  learning  and  exam  performance  [11],  increasing self-control  [7],  and  promoting  positive  behaviors  such  as exercise  [8]  and  energy  conservation  [10].  Unfortunately, knowing  oneself  can  be  difficult  because  we  often  have incomplete knowledge of ourselves [11]; we cannot moni-tor our behaviors all the time and we may be too busy to introspect. Computers can help. Computers can store large amounts of data,  analyze  the  data  for  patterns,  visualize  the  data,  and provide feedback to users at opportune times. A new class of applications and web sites called personal informatics is appearing that collects behavioral information about people and  provides  access  to  these  information  (e.g.,  Mint.com and Google Web History).  Interaction  with  personal  informatics  systems  has  two  Copyright is held by the owner/author(s). UIST\\xe2\\x80\\x9909, October 4\\xe2\\x80\\x937, 2009, V',\n",
       " 'Analytics of Play: Using InformationVisualization and Gameplay Practices for Visualizing Video Game DataBEN MEDLER, PhD STUDENT & BRIAN MAGERKO, PhDKEYWORDS Game analytics, game design, game develop-ment, game metrics, gameplay, information visualization, play, player, playful visualization, visual analytics ABSTRACT Tracking player data in video games has increased in recent years. Data such as click-through-streams and event logs are currently being captured within most major games, while other researchers are prototyp-ing new ways of capturing data from a player\\xe2\\x80\\x99s physical body movement or internal brainwaves. The wealth of data produced is beneficial for a wide variety of audiences within the game community: designers, programmers, marketers, executives and players. Visualizing this data is an obvious choice for connecting these audiences to their data by augmenting their ability to cognitively digest the enormous amount of data available to them.While the principles of information visualization can inform the design of game-related visual analytic systems, such as monitoring player performance over time, video games offer a unique perspective on analytics: analytics that are playful. In this paper we explore the properties that define a playful visualization, one that supports and promotes play. The authors draw on their work building visual game analytic systems for game designers and play-ers, reinforcing their experience with a large number of examples of new visual systems being deployed to analyze game data by both game companies and players. With such a wide variety of game audiences it becomes neces-sary to explore the avenues between analysis and play in order to provide game audiences with visual experiences that promote gameplay as much as analytics.PLAY WITH DATAA child playing with blocks is comparable with a data analyst working with dots. Both manipulate the objects\\xe2\\x80\\x94organizing them into patterns. Both theorize about the object\\xe2\\x80\\x99s meaning and project interpretations upon them. Both explore the possibilities of the objects beyond their common representations. One might argue that data analysis is nothing like play\\xe2\\x80\\x94a seemingly unproductive activity. Analysis requires a specific set of skills to under-stand data comprised of fixed content, context, and rela-THE PARSONS INSTITUTE FOR INFORMATION MAPPING68 Fifth Avenue  New York, NY 10011212 229 6825piim.newschool.edutionships from the real world that represent fact and truth. Play is t',\n",
       " 'PRINCIPLES OF GESTALT PSYCHOLOGY by Kurt KOFFKA (1935)  Principles of Gestalt Psychology , Lund Humphries, London, 1935.  Chapter 1 reproduced here.    Chapter I Why Psychology?  AN INTRODUCTORY QUESTION When I first conceived the plan of writing this book I guessed, though I did not know, how much effort it would cost to carry it out, and what demands it would put on a potential reader. And I doubted, not rhetorically but very honestly and sincerely, whether such labour on the part of the author and the reader was justified. I was not so much troubled by the idea of writing another book on psychology in addition to the many books which have appeared during the last ten years, as by the idea of writing a book on psychology. Writing a book for publication is a social act. Is one justified in demanding co-operation of society for such an enterprise? What good can society, or a small fraction of it, at best derive from it? I tried to give an answer to this question, and when now, after having completed the book, I return to this first chapter, I find that the answer which then gave me sufficient courage to start on my long journey, has stayed with me to the end. I believed I had found a reason why a book on psychology might do some good. Psychology has split up into so many branches and schools, either ignoring or fighting each other, that even an outsider may have the impression - surely strengthened by the publications. \"Psychologies of 1925\" and \"Psychologies of 1930\" - that the plural \"psychologies\" should be substituted for the singular. Psychology has been pampered in the United States, where for many years it has enjoyed great popularity, though it seems to me that its fortunes have somewhat ebbed and may be ebbing more; in England, the land of conservative change, it found for a long time as cold a welcome as any other loud and startling innovation, but has gradually gained ground and is, in my belief, still gaining; in Germany, where experimental psychology was born and had at first a period of rapid expansion, a strong reaction set in soon afterwards which very definitely kept psychology \"in its place.\" I confess that today I feel much less animosity towards the active enemies of psychology - or those of them who are serious and honest - than when I was younger. The comparison of psychology as it is today with other branches of human knowledge has raised the question in my mind what contribution psychology has made through the very extensive and int',\n",
       " 'PROCEEDINGS of the HUMAN FACTORS and ERGONOMICS SOCIETY 56th ANNUAL MEETING - 20122142Faces as Ambient Displays: Assessing the attention-demanding characteristics of facial expressions  Brock M. Bass & Richard Pak Clemson University Department of Psychology Ambient displays are used to provide information to a user in a non-distracting manner. The purpose of this research is to examine the efficacy of facial expressions as ambient displays. Facial emotion recognition requires very little if any conscious attention, which makes it an excellent candidate for the ambient presentation of information. This study will investigate whether using facial expressions as an ambient display permits humans to gain information with ease. This study will assess the attention-demanding characteristics of Chernoff faces in a dual-task experiment. The data from this study could be helpful in understanding whether humans are able to use facial expressions for gaining quick and concise information about a particular system or device.    INTRODUCTION  Ambient displays convey information to the user without being very cognitively demanding\\xe2\\x80\\x94they are in the background. For example, the battery meter icon of a computer interface, or a dangling string from the ceiling to represent network traffic on a computer network (Weiser & Brown, 1995). Some important characteristics of ambient displays are: useful and relevant information, sufficient information design, consistent and intuitive mapping, and the match between the system and the real world (Mankoff, Dey, Hsieh, Kientz, Lederer, & Ames, 2003). Using these heuristics as a benchmark, facial expressions could be considered a type of ambient display. The purpose of this study is to examine the ambient quality of facial expressions; that is to measure their attention-demanding qualities when conveying simple numerical information. We will study this in the context of user-system automation calibration. When users are interacting with computerized decision support systems or automated aids, the user must, over time, determine how much they should trust the system.  Optimally, the user would calibrate their trust to match the level of actual system reliability. That is, to be highly trusting of a highly reliable automated system, or distrusting of a very unreliable system (Parasuraman, 1997). However, this scenario of human-automation interaction (HAI) can be problematic in some cases. For example, an operator may place too much trust',\n",
       " 'REVIEWTHE QUANTIFIEDSELF:Fundamental Disruption in Big Data Scienceand Biological DiscoveryMelanie SwanMS Futures Group, Palo Alto, CaliforniaAbstractA key contemporary trend emerging in big data science is the quanti\\xef\\xac\\x81ed self (QS)\\xe2\\x80\\x93individuals engaged in the self-tracking of any kind of biological, physical, behavioral, or environmental information as n = 1 individuals or ingroups. There are opportunities for big data scientists to develop new models to support QS data collection,integration, and analysis, and also to lead in de\\xef\\xac\\x81ning open-access database resources and privacy standards forhow personal data is used. Next-generation QS applications could include tools for rendering QS data meaningfulin behavior change, establishing baselines and variability in objective metrics, applying new kinds of patternrecognition techniques, and aggregating multiple self-tracking data streams from wearable electronics, biosensors,mobile phones, genomic data, and cloud-based services. The long-term vision of QS activity is that of a systemicmonitoring approach where an individual\\xe2\\x80\\x99s continuous personal information climate provides real-time perfor-mance optimization suggestions. There are some potential limitations related to QS activity\\xe2\\x80\\x94barriers to wide-spread adoption and a critique regarding scienti\\xef\\xac\\x81c soundness\\xe2\\x80\\x94but these may be overcome. One interesting aspectof QS activity is that it is fundamentally a quantitative and qualitative phenomenon since it includes both thecollection of objective metrics data and the subjective experience of the impact of these data. Some of this dynamicis being explored as the quanti\\xef\\xac\\x81ed self is becoming the quali\\xef\\xac\\x81ed self in two new ways: by applying QS methods tothe tracking of qualitative phenomena such as mood, and by understanding that QS data collection is just the \\xef\\xac\\x81rststep in creating qualitative feedback loops for behavior change. In the long-term future, the quanti\\xef\\xac\\x81ed self maybecome additionally transformed into the extended exoself as data quanti\\xef\\xac\\x81cation and self-tracking enable thedevelopment of new sense capabilities that are not possible with ordinary senses. The individual body becomes amore knowable, calculable, and administrable object through QS activity, and individuals have an increasinglyintimate relationship with data as it mediates the experience of reality.IntroductionWhat is the quanti\\xef\\xac\\x81ed self?The quanti\\xef\\xac\\x81ed self (QS) is any individual engaged inthe self-tracking of any kind of biological, ph',\n",
       " 'Psychological Review1981, Vol. 88, No. 1,46-66Copyright 1981 by the American Psychological Association, Inc.0033-295X/81/8801-0046S00.75The Medium and the Message in Mental Imagery:A TheoryStephen Michael KosslynHarvard UniversityA computational theory of imagery is described in this article. This theory positsthat visual mental images are transitory data structures that occur in an analoguespatial medium. These \"surface\" representations are generated from more ab-stract \"deep\" representations in long-term memory and, once formed, can beoperated upon in various ways. The theory is described in terms of detailed claimsabout the mental structures and processes invoked during imagery. In addition,the philosophical and empirical roots of the present theory are briefly reviewed.Further, arguments and data that have been offered against the theory are crit-ically examined, and none are found damaging. An alternative account of thedata that purportedly support the theory is also examined and found deficientin several respects. Finally, the current status of the \"analogue-prepositional\"debate is reviewed, and it is concluded that there has been genuine progress inour understanding of the issues during the past decade.In the Theaetetus Plato likened memoryrepresentations to impressions on a wax tab-let, perhaps thereby becoming the first the-orist to distinguish between representations(the different possible impressions) and themedium in which they occur (the wax tab-let). The distinction between a representa-tion and a medium has proven important inthe study of visual mental imagery. Al-though no serious researcher today main-tains that images are actual pictures in thehead, some still find it reasonable to positquasi-pictorial representations that are sup-ported by a medium that mimics a coordi-nate space. On this view, images are not lan-guagelike \"symbolic\" representations butbear a nonarbitrary correspondence to thething being represented. Partly because ofthe primitive origins of this idea, many peo-ple seem wary of it. But the idea that imagesare a special kind of representation that de-picts information and occurs in a spatialI wish to thank Ned Block, Sharon Fliegel, AlexanderGeorge, Reid Hastie, Edward E. Smith, George E.Smith, and Lucia Vaina for insightful comments andilluminating criticisms of an earlier draft of this article.Work reported herein was supported by National Sci-ence Foundation Grant BNS 79-12418.Requests for reprints should be sent to St',\n",
       " 'BEHAVIORAL AND BRAIN SCIENCES (2002) 25, 157\\xe2\\x80\\x93238Printed in the United States of AmericaMental imagery: In search of a theoryZenon W. PylyshynRutgers Center for Cognitive Science, Rutgers University, Busch Campus,Piscataway, NJ 08854-8020.zenon@ruccs.rutgers.eduhttp://ruccs.rutgers.edu/faculty/pylyshyn.htmlAbstract: cial, however, has never been satisfactorily spelled out, despite more than thirty years of research in the post-behaviorist tradition. Thisarticle considers some of the general motivation for the assumption that entertaining mental images involves inspecting a picture-likeobject. It sets out a distinction between phenomena attributable to the nature of mind to what is called the cognitive architecture, andones that are attributable to tacit knowledge used to simulate what would happen in a visual situation. With this distinction in mind, thepaper then considers in detail the widely held assumption that in some important sense images are spatially displayed or are depictive,and that examining images uses the same mechanisms that are deployed in visual perception. I argue that the assumption of the spatialor depictive nature of images is only explanatory if taken literally, as a claim about how images are physically instantiated in the brain,and that the literal view fails for a number of empirical reasons \\xe2\\x80\\x93 for example, because of the cognitive penetrability of the phenomenacited in its favor. Similarly, while it is arguably the case that imagery and vision involve some of the same mechanisms, this tells us verylittle about the nature of mental imagery and does not support claims about the pictorial nature of mental images. Finally, I considerwhether recent neuroscience evidence clarifies the debate over the nature of mental images. I claim that when such questions as whetherimages are depictive or spatial are formulated more clearly, the evidence does not provide support for the picture-theory over a symbol-structure theory of mental imagery. Even if all the empirical claims were true, they do not warrant the conclusion that many people havedrawn from them: that mental images are depictive or are displayed in some (possibly cortical) space. Such a conclusion is incompatiblewith what is known about how images function in thought. We are then left with the provisional counterintuitive conclusion that theavailable evidence does not support rejection of what I call the \\xe2\\x80\\x9cnull hypothesis\\xe2\\x80\\x9d; namely, that reasoning with mental images involves th',\n",
       " 'BEHAVIORAL AND BRAIN SCIENCES (1999) 22, 341\\xe2\\x80\\x93423Printed in the United States of AmericaIs vision continuous with cognition?The case for cognitive impenetrabilityof visual perceptionZenon PylyshynRutgers Center for Cognitive Science,Rutgers University, New Brunswick, NJ 08903zenon@ruccs.rutgers.eduruccs.rutgers.edu/faculty/pylyshyn.htmlAbstract: Although the study of visual perception has made more progress in the past 40 years than any other area of cognitive science,there remain major disagreements as to how closely vision is tied to cognition. This target article sets out some of the arguments for bothsides (arguments from computer vision, neuroscience, psychophysics, perceptual learning, and other areas of vision science) and defendsthe position that an important part of visual perception, corresponding to what some people have called early vision, is prohibited fromaccessing relevant expectations, knowledge, and utilities in determining the function it computes \\xe2\\x80\\x93 in other words, it is cognitively im-penetrable. That part of vision is complex and involves top-down interactions that are internal to the early vision system. Its function isto provide a structured representation of the 3-D surfaces of objects sufficient to serve as an index into memory, with somewhat differ-ent outputs being made available to other systems such as those dealing with motor control. The paper also addresses certain concep-tual and methodological issues raised by this claim, such as whether signal detection theory and event-related potentials can be used toassess cognitive penetration of vision. A distinction is made among several stages in visual processing, including, in addition to the inflexible early-vision stage, a pre-per-ceptual attention-allocation stage and a post-perceptual evaluation, selection, and inference stage, which accesses long-term memory.These two stages provide the primary ways in which cognition can affect the outcome of visual perception. The paper discusses argu-ments from computer vision and psychology showing that vision is \\xe2\\x80\\x9cintelligent\\xe2\\x80\\x9d and involves elements of \\xe2\\x80\\x9cproblem solving.\\xe2\\x80\\x9d The casesof apparently intelligent interpretation sometimes cited in support of this claim do not show cognitive penetration; rather, they show thatcertain natural constraints on interpretation, concerned primarily with optical and geometrical properties of the world, have been com-piled into the visual system. The paper also examines a number of examples where',\n",
       " 'Visual Pattern Discovery using Random ProjectionsAnushka Anand\\xe2\\x88\\x97Leland Wilkinson\\xe2\\x80\\xa0Tuan Nhon Dang\\xe2\\x80\\xa1Department of Computer Science, University of Illinois at ChicagoABSTRACTAn essential element of exploratory data analysis is the use ofrevealing low-dimensional projections of high-dimensional data.Projection Pursuit has been an effective method for \\xef\\xac\\x81nding in-teresting low-dimensional projections of multidimensional spacesby optimizing a score function called a projection pursuit index.However, the technique is not scalable to high-dimensional spaces.Here, we introduce a novel method for discovering noteworthyviews of high-dimensional data spaces by using binning and ran-dom projections. We de\\xef\\xac\\x81ne score functions, akin to projection pur-suit indices, that characterize visual patterns of the low-dimensionalprojections that constitute feature subspaces. We also describe ananalytic, multivariate visualization platform based on this algorithmthat is scalable to extremely large problems.Keywords: Random Projections, High-dimensional Data.Index Terms: H.5.2 [User Interfaces]: Graphical user interfaces(GUI)\\xe2\\x80\\x94 [H.2.8]: Database Applications\\xe2\\x80\\x94Data Mining1 INTRODUCTIONThis work is motivated by the lack of pattern detection methodsthat are ef\\xef\\xac\\x81cient in high-dimensional spaces. While many of thesemethods [16, 10, 35, 28] are effective in low-dimensional spaces,their computational complexity prevents their application in veryhigh-dimensional spaces. While there are approaches to speed upthese methods [24, 49, 14], most involve parallelization schemes,computationally complex ideas or ad-hoc pre-processing methods.By contrast, we have attempted to integrate a recent methodcalled random projections, in an iterative framework, to detect vi-sual patterns in high-dimensional spaces. The main use of the ran-dom projection theorem in data mining has been as a preprocess-ing step in order to reduce the dimensionality of a space to a man-ageable subspace before applying classi\\xef\\xac\\x81cation algorithms such asSupport Vector Machines or decision trees that are not readily scal-able to very high-dimensional spaces. CHIRP [46] proposed a dif-ferent approach: it is a visual-analytic classi\\xef\\xac\\x81er, based on iteratedrandom projections, that approximates the distribution-free \\xef\\xac\\x82ex-ibility of Projection Pursuit without the computational complex-ity. This motivated us to see whether guided random projectionscould be used to construct a visual analytics platform for discerningmeaningful st',\n",
       " 'Combining automated analysis and visualization techniques for effective exploration of high-dimensional data Andrada Tatu\\' University of  Konstanz Germany Georgia Albuquerque t TU  Braunschweig Germany Martin Eisemann::: TU  Braunschweig Germany Jarn Schneidewind\\xc2\\xa7 Telefonica 02 Business Intelligence Center Germany Holger Theisel\\'l University of Magdeburg Germany Marcus Magnorll TU  Braunschweig Germany Daniel Keim\" University of  Konstanz Germany ABSTRACT Visual exploration of multivariate data typically requires projection onto  lower-dimensional  representations.  The  number of possible representations grows  rapidly  with  the number of dimensions,  and manual  exploration  quickly  becomes  ineffective  or even  uoJeasi-ble.  This  paper  proposes  automatic  analysis  methods  to  extract potentially  relevant  visual  structures  from  a set  of candidate  visu-alizations.  Based on  features,  the  visualizations are ranked  in  ac-cordance  with  a specified  user  task.  The  user  is  provided  with  a manageable number of potentially useful  candidate visualizations, which  can  be  u ed  as  a  starting  point  for  interactive  data  analy-sis.  This can  effectively t:ase  the  task  of finding  truly  useful  visu-alizations  and  potcntially  speed  up  the  data  exploration  task.  In this  paper,  we  present  ranking  measures  for  class-based  as  well as  non class-based Scatterplots and Parallel Coordinates visualiza-tions.  The  proposed  analysis  methods  are  evaluated  on  different datasets. Index  Terms:  H.3.3  [Information  Storage  and  Retrieval):  In-formation  Search  and  Retrieval  1.3.3  [Computer  Graphics):  Pic-turclImage Generation; INTRODUCTION Due to the technological progress over the last decades,  today\\'s sci-entific and commercial applications are capable of generating, stor-ing, and  processing massive  amounts of data.  Making use of these archives of data provides new challenges to  analysis techniques.  It is  more  difficult  to  filter and  extract relevant  information  from  the masses of data since the complexity and  volume has increased.  Ef-fective  visual  exploration  techniques  are  needed  that  incorporate automated  analysis  components  to  reduce  complexity  and  la ef-fectively  guide the  user during  the  interactive exploration  process. The visualization of large complex information spaces typically in-volves mapping high-dimensional data la lower-dimensional visual representati',\n",
       " 'Utah State UniversityDigitalCommons@USUITLS Faculty Publications10-1-2013The Quantified Self (QS) Movement and SomeEmerging Opportunities for the EducationalTechnology FieldVictor R. LeeUtah State UniversityRecommended CitationLee, Victor R., \"The Quantified Self (QS) Movement and Some Emerging Opportunities for the Educational Technology Field\"(2013). ITLS Faculty Publications. Paper 480.http://digitalcommons.usu.edu/itls_facpub/480This Article is brought to you for free and open access byDigitalCommons@USU. It has been accepted for inclusion in ITLS FacultyPublications by an authorized administrator of DigitalCommons@USU.For more information, please contact becky.thoms@usu.edu.\\x0c',\n",
       " 'External Representations Contribute to the DynamicConstruction of IdeasMasaki Suwa1 and Barbara Tversky21 Information and Human Activity, PRESTO, JSTSchool of Computer and Cognitive Sciences, Chukyo University,101 Tokodachi, Kaizu, Toyota, 470-0393, Japansuwa@sccs.chukyo-u.ac.jp2 Department of Psychology, Stanford University, Stanford, CA 94305-2130, USAbt@psych.stanford.eduExtended AbstractExternal  representations  such  as  diagrams,  sketches,  charts,  graphs  and  scribbles  onnapkins  play  facilitatory  roles  in  inference,  problem-solving  and  understanding  (e.g.[1],[2],[3],[4],[5],[6],[7],[8],[9]). How does the  externality  and  visibility  of  represen-tations  facilitate  inference  and  problem-solving?  One  benefit  of  external  representa-tions is on memory. They reduce working memory load by providing external tokensfor the elements that must otherwise be kept in mind. This frees working memory toperform mental calculations on the elements rather than both keeping elements in mindand  operating  on  them  [2],[9].  External  representations  also  serve  as  visuo-spatialretrieval  cues  for  long  term  memory,  evoking  relevant  information  that  might  nototherwise be retrieved. Another benefit of external representations is to promote dis-covery  and  inference,  both  visuo-spatial  and  metaphorical.  Perceptual  judgementsabout  size,  distance,  and  direction  are  easily  made  from  external  representations(e.g.[4]). In a Venn diagram, set relations such as inclusion are abstractly mapped ontovisuo-spatial  diagrammatic  features,  enabling  direct  perceptual  calculation.  Visuo-spatial features such as proximity, connectivity, and alignment provide useful hints toselection of appropriate inference paths (e.g.[1],[6],[8]) and to proper understanding ofthe structure of a  target  system  (e.g.[5]).  Calculations  requiring  counting,  sorting,  orordering are easily made by rearranging external spaces (e.g. [7]).   To serve these functions of memory, inference, and calculation, the interpretationof the external representation is static; it must stay the same in order not to introduceerror in the operations performed from the external representation. External represen-tations, however, are visuo-spatial displays, and it is known from research on percep-tion that such displays, especially vague and ambiguous ones, can be interpreted andreinterpreted. Are there situations where the very instability of visuo-spatial displa',\n",
       " 'The Fourth Paradigm: Data-Intensive Scientific Discovery Tony\\xc2\\xa0HeyCorporate\\xc2\\xa0Vice\\xc2\\xa0PresidentMicrosoft\\xc2\\xa0External\\xc2\\xa0ResearchThis\\xc2\\xa0work\\xc2\\xa0is\\xc2\\xa0licensed\\xc2\\xa0under\\xc2\\xa0a\\xc2\\xa0Creative\\xc2\\xa0Commons\\xc2\\xa0Attribution\\xc2\\xa03.0\\xc2\\xa0United\\xc2\\xa0States\\xc2\\xa0License.\\x0c',\n",
       " 'Proceedings of the 15th International Conference on Auditory Display, Copenhagen, Denmark May 18 - 22, 2009MULTI-TOUCH INTERACTIONS FOR MODEL-BASED SONIFICATIONRen\\xc2\\xb4e T\\xc2\\xa8unnermann, Thomas HermannAmbient Intelligence GroupCognitive Interaction Technology - Center of Excellence (CITEC){rtuenner|thermann}@techfak.uni-bielefeld.deBielefeld, GermanyABSTRACTThis paper presents novel interaction modes for Model-Based Soni-\\xef\\xac\\x81cation (MBS) via a multi-touch interface. We \\xef\\xac\\x81rst lay out detailsabout the constructed multi-touch surface. This is followed by adescription of the Data Sonogram Soni\\xef\\xac\\x81cation Model and how itis implemented using the system. Modi\\xef\\xac\\x81cations from the originalsoni\\xef\\xac\\x81cation model such as the limited space scans are describedand discussed with soni\\xef\\xac\\x81cation examples. Videos showing exam-ples of interaction are provided for various data sets. Beyond DataSonograms, the presented system provides a basis for the imple-mentation of known and novel soni\\xef\\xac\\x81cation models. We discussthe available interaction modes with multi-touch surfaces and howthese interactions can be pro\\xef\\xac\\x81tably used to control spatial and non-spatial soni\\xef\\xac\\x81cation models.1. INTRODUCTIONExploratory Data Analysis aims to develop techniques for users tobetter grasp the hidden structure in complex data. If we take thisstatement literally, we might not only ask how we could imple-ment techniques to manually interact and get our hands on data,but also, how it sounds or should sound if we interact physicallywith data. Real-world acoustic responses that we experience whentouching (hitting, scratching, ...) an object or surface are oftenvery useful and reveal a whole range of information about the ob-ject\\xe2\\x80\\x99s properties (material, stiffness, surface properties, etc.). Weoften underestimate the utility of such direct feedback since it isomnipresent and at the same time effortlessly integrated into ourmulti-modal perceptions.The arising questions are how can we inherit the bene\\xef\\xac\\x81ts ofaction-perception loops for a better understanding of complex dataand how can we structure surface-based interfaces so that usersobtain an informative acoustic reaction on arbitrary interactions?Model-Based Soni\\xef\\xac\\x81cation takes these aspects of interaction par-ticularly into account [10]. Soni\\xef\\xac\\x81cation models according to MBScan be excited by the user. For this excitatory process many dif-ferent interaction interfaces beyond the mouse, such as the audio-haptic ball interface, or the malleable user interface have ',\n",
       " 'Topics in Cognitive Science 3 (2011) 499\\xe2\\x80\\x93535Copyright \\xc3\\x93 2010 Cognitive Science Society, Inc. All rights reserved.ISSN: 1756-8757 print / 1756-8765 onlineDOI: 10.1111/j.1756-8765.2010.01113.xVisualizing ThoughtBarbara TverskyColumbia Teachers College and Stanford UniversityReceived 16 June 2009; received in revised from 12 May 2010; accepted 12 May 2010AbstractDepictive expressions of thought predate written language by thousands of years. They haveevolved in communities through a kind of informal user testing that has re\\xef\\xac\\x81ned them. Analyzingcommon visual communications reveals consistencies that illuminate how people think as well asguide design; the process can be brought into the laboratory and accelerated. Like language, visualcommunications abstract and schematize; unlike language, they use properties of the page (e.g., prox-imity and place: center, horizontal \\xe2\\x81\\x84 up\\xe2\\x80\\x93down, vertical \\xe2\\x81\\x84 left\\xe2\\x80\\x93right) and the marks on it (e.g., dots, lines,arrows, boxes, blobs, likenesses, symbols) to convey meanings. The visual expressions of thesemeanings (e.g., individual, category, order, relation, correspondence, continuum, hierarchy) haveanalogs in language, gesture, and especially in the patterns that are created when people design theworld around them, arranging things into piles and rows and hierarchies and arrays, spatial-abstrac-tion-action interconnections termed spractions. The designed world is a diagram.Keywords: Diagrams; Visual communication; Gesture; Spatial cognition; Analogy; Action;Metaphor1. IntroductionCommunication in the wild is a sound and light show combining words, prosody, facialexpressions, gestures, and actions. Although it is often presumed\\xe2\\x80\\x94think of the \\xe2\\x80\\x98\\xe2\\x80\\x98letter ofthe law\\xe2\\x80\\x99\\xe2\\x80\\x99 and transcripts of trials\\xe2\\x80\\x94that meanings are neatly packaged into words joined byrules into utterances, in fact, other channels of communication carry signi\\xef\\xac\\x81cant aspects ofmeaning, despite or perhaps because of the fact that they cannot be neatly packaged intounits strung together by rules (e.g., Clark, 1996; Goldin-Meadow, 2003; Kendon, 2004;McNeill, 1992, 2005). Prosody, as in irony or sarcasm, can overrule and even reversemeanings of words, as can facial expressions. Pointing can replace words, for things, forCorrespondence should be sent to Barbara Tversky, Department of Human Development, Columbia TeachersCollege, 525 W. 120th Street, New York, NY 10027; Department of Psychology, Stanford University, 450 SerraMall, Stanford, CA 94305-2130. E-mail',\n",
       " 'Adaptive Information Visualization - Predicting user characteristics and task context from eye gaze Ben Steichen, Giuseppe Carenini, Cristina Conati  Department of Computer Science, University of British Columbia  2366 Main Mall, Vancouver, BC, V6T1Z4, Canada  {steichen, carenini, conati}@cs.ubc.ca Abstract.  Our  research  aims  to  design  information  visualization  systems  that adapt to each individual user\\xe2\\x80\\x99s characteristics and task context. In order to pro-vide such Adaptive Information Visualizations, the first step is to predict these characteristics and context from a number of real-time measures. In particular, this paper presents initial results from an eye tracking user study, providing ev-idence  that  a  user\\xe2\\x80\\x99s  eye gaze can  indeed  be  used  for  predicting  a  user\\xe2\\x80\\x99s  task context and cognitive abilities. Keywords: Information Visualization, Eye Tracking, Machine Learning 1 Introduction While  Information  Visualization  systems  have  gained  in  terms  of  general  usage and  usability,  they  have  traditionally  followed  a  one-size-fits-all  model,  typically ignoring  an  individual  user\\xe2\\x80\\x99s  needs,  abilities  and  task  context.  However,  recent  re-search  has  shown  that  such  characteristics  can  indeed  have  a  significant  impact  on user effectiveness during visualization usage [1][2]. It is therefore crucial to design information visualization systems that can dynamically adapt to individual task and user characteristics in order to best support each individual user. Adaptation and Personalization have long been established as effective techniques to support individual users in information seeking tasks, in particular in areas such as Personalized  Information  Retrieval  and  Adaptive  Hypermedia  [3].  However,  only very recently researchers have started to apply similar techniques to support users of Information Visualization systems. Such adaptive systems (e.g. [4]) typically monitor users\\xe2\\x80\\x99 actions (e.g. mouse clicks) in order to infer their current intent/task. If subopti-mal  user  patterns  are  detected,  alternative  visualization  techniques  are  then  recom-mended that better support the inferred task. The research presented in this paper differs from such systems in a number of as-pects. Firstly, in addition to recommending different visualization techniques, we also aim to provide adaptive interventions within the current visualization. Secondly, we are interested in adapting to different user ',\n",
       " '   Using Personal Informatics to Motivate Physical Activity: Could we be Doing it Wrong?Patrick Burns Shlomo Berkovsky School of Computing and CSIRO Tasmanian ICT Centre Information Systems, Castray Esplanade University of Tasmania Hobart, TAS 7001 Australia Grosvenor Crescent Shlomo.Berkovsky@csiro.au Hobart, TAS 7001 Australia  Patrick.Burns@utas.edu.au  Christopher Lueg School of Computing and Information Systems, University of Tasmania Grosvenor Crescent Hobart, TAS 7001 Australia Christopher.Lueg@utas.edu.au Copyright is held by the author/owner(s). CHI\\xe2\\x80\\x9912, May 5\\xe2\\x80\\x9310, 2012, Austin, Texas, USA. ACM 978-1-4503-1016-1/12/05. Abstract The global level of obesity and overweight is on the increase. Personal informatics \\xe2\\x80\\x93 tools which assist users to collect and view information on their behaviours and habits \\xe2\\x80\\x93 could help to reverse this trend by making users more aware of their daily level of physical activity. Most tools available use high-complexity high-engagement interfaces to convey this information. We argue that simpler interfaces may be more suitable for users who are not highly motivated to undertake physical activity. We discuss our recent work in designing and evaluating such an interface. Author Keywords Personal Informatics, Physical Activity, Wearable Ambient Display. ACM Classification Keywords H5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous. Introduction According to the World Health Organisation, over 1.6 billion adults are overweight, with this figure projected to climb to 2.3 billion by 2015 [8]. The global increase in overweight and obesity is attributable to a higher \\x0c',\n",
       " 'I. KWAK ET AL.: VISUAL RECOGNITION OF URBAN TRIBES1From Bikers to Surfers:Visual Recognition of Urban TribesIljung S. Kwak1iskwak@cs.ucsd.eduAna C. Murillo2acm@unizar.esPeter N. Belhumeur3belhumeur@cs.columbia.eduDavid Kriegman1kriegman@cs.ucsd.eduSerge Belongie1sjb@cs.ucsd.edu1 Dept. of Computer Science andEngineeringUniversity of California, San Diego.San Diego, CA, USA2 Dpt. Inform\\xc3\\xa1tica e Ing. Sistemas - Inst.Investigaci\\xc3\\xb3n en Ingenier\\xc3\\xada de Arag\\xc3\\xb3n.University of Zaragoza, Spain.3 Department of Computer ScienceColumbia University, USA.AbstractThe terms Biker, Punk, Hipster, Goth or Surfer often spark visual depictions of indi-viduals with very distinct fashion styles. These visually salient styles can provide insightinto the social identity of an individual. However, despite its potential usefulness, littlework has been done to automatically classify images of people into social categories. Wetackle this problem by analyzing pictures of groups of individuals and creating modelsto represent them. We capture the features that distinguish each subculture and showpromising results for automatic classi\\xef\\xac\\x81cation. This work gives vision algorithms accessto the social identity of an individual and helps improve the quality of socially motivatedimage search, relevance of advertisements, and recommendations of social groups.Introduction1In the past few years there has been a massive in\\xef\\xac\\x82ux of images provided by social media;Facebook alone receives around 300 million photos a day[1]. The abundance of social me-dia presents a compelling opportunity to analyze the social identity of individuals capturedwithin images. This points to an excellent opportunity for computer vision to interact withother \\xef\\xac\\x81elds, including marketing strategies and psychological sociology [7, 12].Although there have been major strides in image semantic content analysis (in face, ob-ject, scene, and more recently clothing recognition), current algorithms fail to fully captureinformation from groups of individuals within images. For example, as shown in Fig. 1,visual searches of groups of people often provide uninspiring results. Rather than matchingpersonal style or social identity, the search provided images with similar global image statis-tics. The mainstream media has noticed this de\\xef\\xac\\x81ciency in some recent discussions [4] andwonders when vision algorithms will catch up to their expectations.c(cid:13) 2013. The copyright of this document resides with its authors.It may be distributed u',\n",
       " 'Subspace Search and Visualization to Make Sense of AlternativeClusterings in High-Dimensional DataAndrada Tatu\\xe2\\x88\\x97University of KonstanzGermanyFabian Maa\\xc3\\x9f\\xe2\\x80\\xa0University of KonstanzGermanyInes F\\xc2\\xa8arber\\xe2\\x80\\xa1RWTH Aachen UniversityGermanyEnrico Bertini\\xc2\\xa7University of KonstanzGermanyTobias Schreck\\xc2\\xb6University of KonstanzGermanyThomas Seidl(cid:107)RWTH Aachen UniversityGermanyDaniel Keim\\xe2\\x88\\x97\\xe2\\x88\\x97University of KonstanzGermanyABSTRACTIn explorative data analysis, the data under consideration often re-sides in a high-dimensional (HD) data space. Currently many meth-ods are available to analyze this type of data. So far, proposedautomatic approaches include dimensionality reduction and clusteranalysis, whereby visual-interactive methods aim to provide effec-tive visual mappings to show, relate, and navigate HD data. Fur-thermore, almost all of these methods conduct the analysis from asingular perspective, meaning that they consider the data in eitherthe original HD data space, or a reduced version thereof. Addi-tionally, HD data spaces often consist of combined features thatmeasure different properties, in which case the particular relation-ships between the various properties may not be clear to the an-alysts a priori since it can only be revealed if appropriate featurecombinations (subspaces) of the data are taken into consideration.Considering just a single subspace is, however, often not suf\\xef\\xac\\x81cientsince different subspaces may show complementary, conjointly, orcontradicting relations between data items. Useful information mayconsequently remain embedded in sets of subspaces of a given HDinput data space.Relying on the notion of subspaces, we propose a novel methodfor the visual analysis of HD data in which we employ aninterestingness-guided subspace search algorithm to detect a can-didate set of subspaces. Based on appropriately de\\xef\\xac\\x81ned subspacesimilarity functions, we visualize the subspaces and provide navi-gation facilities to interactively explore large sets of subspaces. Ourapproach allows users to effectively compare and relate subspaceswith respect to involved dimensions and clusters of objects. We ap-ply our approach to synthetic and real data sets. We thereby demon-strate its support for understanding HD data from different perspec-tives, effectively yielding a more complete view on HD data.Index Terms: H.2.8 [Database Applications]: Data mining; H.3.3[Information Search and Retrieval]: Selection process; I.3.3 [Pic-ture/Image Generation]: Display algorith',\n",
       " 'Perceptualization: Techniques for Effective Image Generation,Visualization, and Communication of InformationDavid S. EbertSchool of Electrical and Computer EngineeringPurdue University1285 EE BuildingWest Lafayette, IN 47907 USAEmail: ebertd@purdue.eduAbstractMost scientists, doctors, analysts, and even com-puter animators are faced with a data deluge. Theymust analyze, extract meaningful information, andcreate solutions from huge quantities of data whosesize is increasing at an enormous rate. However,screen resolution, image generation techniques, andvisualization techniques are only making modestimprovements. This has led us to take a differentapproach to image generation and visualization thatwe call perceptualization. We describe our initialwork in perceptualization, the main challenges, andour current research directions.1 IntroductionThroughout history, man has tried to effectivelyconvey important information through the use ofimages, using techniques such as illustrations, pho-tographs, and detailed technical drawings. Thesetechniques harness the enormous bandwidth andpre-attentive processing of the human visual sys-tem. Many disciplines of study have evolved toto further these techniques, including photography,technical and medical illustration, and now visual-ization. While illustration and photography bothare successful at capturing and conveying informa-tion, they utilize different techniques and character-istics of the human visual system to convey infor-mation. Photography concentrates on conveying in-formation with light and color variation, while illus-trations additionally tries to effectively convey in-formation by omitting unimportant details, enhanc-ing the most signi\\xef\\xac\\x81cant components of the image,simplifying complex features, and exposing hiddenfeatures [8]. Scienti\\xef\\xac\\x81c illustrations have been usedfor centuries because of their effective communica-tive ability [4].The effectiveness of illustration techniques, theamazing power of the human perceptual system,and the enormous data deluge facing informationanalysts, medical and scienti\\xef\\xac\\x81c researchers havemotivated our work on extending visualization tech-niques to perceptualization. The goal of this re-search is to concisely convey information to the userthrough the creation of effective perceptual humaninputs (visual, proprioceptive, and haptic).2 Overview of Perceptualization Re-searchWe are currently exploring the following three as-pects of perceptualization research:\\x00 PerceptuallyThi',\n",
       " \"Reprinted with permission.(RR-81-26)Ann. Rev. Psychol. 1981. 32:191-241Copyrighl \\xe2\\x82\\xacI 1981. by Annual Reviews Inc. All righls reservedGRAPHICAL DATA ANALYSIS+344Howard Wainer)Bureau of Social Science Research, Washington, D.C. 20036, and EducationalTesting Service, Princeton, New Jersey 08540David ThissenDepartment of Psychology, University of Kansas, Lawrence, Kansas 66044CONTENTSINTRODUCTIONLimits 01this ChapterHISTORYGRAPHICS FOR DATA ANALYSISOne-Way Displays 01One-Way DataTwo- Way Displays of One- Way DataTwo-Way Displays of (Mostly) Two-Way DataTwo-Way Displays ofMultivariate DataStem-and-leaf diagramsBox plotsSuspendedrootogramsp.p and Q-Q plotsDiagnoslic plotsEnhanced scatterplotsTablesGlyphsInside-outplotsFacesOther suggesrionsA multivariate example,;...................................192192194196196199199203204207211213214219220221221222223223231233233234234236Three-and-More-Way Displays of Multivariate DataEYERYTHING ELSEf~n;~::d;y.~~..~:.'::~~~~.~t:.Experimental Evidence::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::,,SUMMARY,,'Research for this chapter was supported in part by a grant from the National ScienceFoundation (SOC-76-17768), Alben D. Biderman and Howard Wainer, principal investiga(cid:173)tors.0066-4308/81/0201-0191$01.00191\\x0c\",\n",
       " '.   .srehsilbupdeilla sti fo eno yldaorbdetanimessid ebot ton   ronoitaicossA lacigolohcysPnaciremA eht   ybdethgirypoc si tnemucod sihT si dna resu laudividni eht fo esu lanosrep eht rof ylelos dednetni si elcitra sihTJournal of Experimental Psychology: Applied2002, Vol. 8, No. 4, 211\\xe2\\x80\\x93221Copyright 2002 by the American Psychological Association, Inc.1076-898X/02/$5.00 DOI: 10.1037/1076-898X.8.4.211Magnitude Estimation of Conceptual Data Dimensionsfor Use in SonificationBruce N. WalkerRice UniversitySonifications must match listener expectancies about representing data with sound. Three experimentsshowed the utility of magnitude estimation for this. In Experiment 1, 67 undergraduates judged the sizesof visual stimuli and the temperature, pressure, velocity, size, or dollars they represented. Similarly, inExperiment 2, 132 listeners judged the pitch or tempo of sounds and the data they represented. In bothexperiments, polarity and scaling preference depended on the conceptual data dimension. In Experi-ment 3, 60 listeners matched auditory graphs to data created with the results of Experiment 2, providinginitial validation of scaling slopes. Magnitude estimation is proposed as a design tool in the developmentof data sonifications, with the level of polarity preference agreement predicting mapping effectiveness.In virtually every science classroom and laboratory, researchersgather, analyze, and attempt to determine patterns in data. In manycases, the data sets are not only huge but also multidimensionaland rapidly changing. Therefore, researchers must use all of theresources available, both technical and perceptual, to display andinterpret their scientific results. However, most data explorationtools are exclusively visual in nature. These tools fail to exploitthe excellent pattern recognition capabilities of the humanauditory system and exclude students and researchers withvisual disabilities.Sonification is the use of nonspeech audio to convey informa-tion such as that used in the interpretation of scientific results.Specifically, data sonification is \\xe2\\x80\\x9cthe transformation of data rela-tions into perceived relations in an acoustic signal for the purposesof facilitating communication or interpretation\\xe2\\x80\\x9d (Kramer et al.,1999, p. 3). That is, scientific data, of any sort, are used to changethe parameters of a synthesized tone. The many real and potentialbenefits of sonification have been detailed elsewhere (e.g., Krameret al., 1999; Walker, 2000). However, al',\n",
       " 'Proceedings of ICAD 04-Tenth Meeting of the International Conference on Auditory Display, Sydney, Australia, July 6-9, 2004 SONIFICATION OF GEO-REFERENCED DATA FOR AUDITORY INFORMATION SEEKING: DESIGN PRINCIPLE AND PILOT STUDY Haixia Zhao1, Catherine Plaisant, Ben Shneiderman1 Ramani Duraiswami Department of Computer Science1  & Human Computer Interaction Laboratory,  University of Maryland,  College Park, MD 20742, USA Perceptual Interfaces and Reality Laboratory, UMIACS,  University of Maryland,  College Park, MD 20742, USA {haixia,plaisant,ben}@cs.umd.edu {ramani}@umiacs.umd.edu   ABSTRACT We  present  an  Auditory  Information  Seeking  Principle  (AISP) (gist, navigate, filter, and details-on-demand) modeled after the visual  information  seeking  mantra  [1].  We  propose  that  data sonification  designs  should  conform  to  this  principle.  We  also present  some  design  challenges  imposed  by  human  auditory perception  characteristics.  To  improve  blind  access  to  geo-referenced  statistical  data,  we  developed  two  preliminary sonifications adhering to the above AISP, an enhanced table and a  spatial  choropleth  map.  Our  pilot  study  shows  people  can recognize  geographic  data  distribution  patterns  on  a  real  map with  51  geographic  regions,  in  both  designs.  The  study  also shows  evidence  that  AISP  conforms  to  people\\xe2\\x80\\x99s  information seeking  strategies.  Future  work  is  discussed,  including  the improvement of the choropleth map design.  1. INTRODUCTION is For  people  with  vision-impairment,  auditory  information  is  an important  alternative  or  supplementary  information  channel. Sonification to  convey information  [2].    Effective  data  sonification  can  help  vision-impaired  users  to  explore  data  collections  for  problem  solving and  decision  making.  As  a  result,  it  promotes  equal  working opportunities for people with vision-impairment. the  use  of  nonspeech  audio One of the guiding principles for the contemporary research on  visual  information  seeking  has  been  \\xe2\\x80\\x9coverview  first,  zoom and filter, then details-on-demand\\xe2\\x80\\x9d [1]. If information seeking in the  auditory  mode  follows the collaboration  between  visual  users  and  auditory  users  might become  easier.  In this  paper  we  propose  an  Auditory Information Seeking Principle (AISP): the  same  pattern then Gist: quick grasp of the overall data trends and patterns from a short auditory message. examine p',\n",
       " 'Eurographics/ IEEE-VGTC Symposium on Visualization 2008A. Vilanova, A. Telea, G. Scheuermann, and T. M\\xc3\\xb6ller(Guest Editors)Volume 27 (2008), Number 3Visual Clustering in Parallel CoordinatesHong Zhou1, Xiaoru Yuan2, Huamin Qu1, Weiwei Cui1, Baoquan Chen31Computer Science & Engineering Department, The Hong Kong University of Science and Technology, Hong Kong2School of EECS & Key Laboratory of Machine Perception (Ministry of Education), Peking University, China3Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, ChinaAbstractParallel coordinates have been widely applied to visualize high-dimensional and multivariate data, discerningpatterns within the data through visual clustering. However, the effectiveness of this technique on large data isreduced by edge clutter. In this paper, we present a novel framework to reduce edge clutter, consequently improvingthe effectiveness of visual clustering. We exploit curved edges and optimize the arrangement of these curved edgesby minimizing their curvature and maximizing the parallelism of adjacent edges. The overall visual clusteringis improved by adjusting the shape of the edges while keeping their relative order. The experiments on severalrepresentative datasets demonstrate the effectiveness of our approach.Keywords: Parallel coordinates, visual clustering, multi-variate data visualization, clutter reduction.1. IntroductionUnderstanding complex high-dimensional datasets is an im-portant yet challenging problem. Among various techniquesdeveloped, parallel coordinates [ID90] have been widelyadopted for the visualization of high-dimensional and mul-tivariate datasets. By using parallel axes for dimensions, theparallel coordinates technique can represent N-dimensionaldata in a 2-dimensional space. Parallel coordinates can beconsidered as special node link diagrams, in which the nodesare on the parallel axes and the edges are those polylineslinking the nodes on two neighboring axes.Although parallel coordinates have been proven to be aneffective tool, edge clutter prevents effective revealing of un-derlying patterns in large datasets. Many enhancements ofparallel coordinates have been developed [ED06, AdL04,HLD02, JLJC05]. Clustering is one of the most frequentlyused methods to reduce the visual clutter and improve theperceptibility of the patterns in multivariate datasets. Themain cause of the visual clutter comes from too manypolylines. Most of the existing clutter reduction efforts aremainly data ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
